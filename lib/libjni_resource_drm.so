ddr;
		info->ui32CurrOp = get_sync_value(kernel->fence_sync);
		info->ui32NextOp = kernel->fence_sync->next_value;
	} else {
		info->id         = 0;
		info->ui32FWAddr = 0;
		info->ui32CurrOp = 0;
		info->ui32NextOp = 0;
	}

	return sizeof(*info);
}

/* foreign sync handling */

static void pvr_sync_foreign_sync_pt_signaled(struct sync_fence *fence,
					      struct sync_fence_waiter *_waiter)
{
	struct pvr_sync_fence_waiter *waiter =
		(struct pvr_sync_fence_waiter *)_waiter;
	unsigned long flags;

	/* Complete the SW operation and free the sync if we can. If we can't,
	 * it will be checked by a later workqueue kick.
	 */
	complete_sync(waiter->kernel->fence_sync);

	MTKPP_LOG(MTKPP_ID_SYNC, "[%p] sigl tid:%d", fence, MTKGetCurrentProcessIDKM());

	/* We can 'put' the fence now, but this function might be called in
	 * irq context so we must defer to WQ.
	 * This WQ is triggered in pvr_sync_defer_free, so adding it to the
	 * put list before that should guarantee it's cleaned up on the next
	 * wq run.
	 */
	spin_lock_irqsave(&sync_fence_put_list_spinlock, flags);
	list_add_tail(&waiter->sync_fence->list, &sync_fence_put_list);
	spin_unlock_irqrestore(&sync_fence_put_list_spinlock, flags);

	pvr_sync_defer_free(waiter->kernel);

	/* The completed sw-sync may allow other tasks to complete,
	 * so we need to allow them to progress.
	 */
	queue_work(pvr_sync_data.check_status_wq,
		&pvr_sync_data.check_status_work);

	kfree(waiter);
}

static struct pvr_sync_kernel_pair *
pvr_sync_create_waiter_for_foreign_sync(int fd)
{
	struct pvr_sync_native_sync_prim *cleanup_sync = NULL;
	struct pvr_sync_kernel_pair *kernel = NULL;
	struct pvr_sync_fence_waiter *waiter;
	struct pvr_sync_fence *sync_fence;
	struct sync_fence *fence;
	enum PVRSRV_ERROR error;
	int err;

	fence = sync_fence_fdget(fd);
	if (!fence) {
		pr_err("pvr_sync: %s: Failed to take reference on fence\n",
		       __func__);
		goto err_out;
	}

	kernel = kmalloc(sizeof(*kernel), GFP_KERNEL);
	if (!kernel) {
		pr_err("pvr_sync: %s: Failed to allocate sync kernel\n",
		       __func__);
		goto err_put_fence;
	}

	INIT_LIST_HEAD(&kernel->cleanup_sync_list);

	sync_fence = kmalloc(sizeof(*sync_fence), GFP_KERNEL);
	if (!sync_fence) {
		pr_err("pvr_sync: %s: Failed to allocate pvr sync fence\n",
		       __func__);
		goto err_free_kernel;
	}

	sync_fence->fence = fence;

	error = sync_pool_get(&kernel->fence_sync,
			      fence->name, SYNC_PT_FOREIGN_FENCE_TYPE);
	if (error != PVRSRV_OK) {
		pr_err("pvr_sync: %s: Failed to allocate sync prim (%s)\n",
		       __func__, PVRSRVGetErrorStringKM(error));
		goto err_free_sync_fence;
	}

	kernel->fence_sync->next_value++;

	error = sync_pool_get(&cleanup_sync, fence->name,
		SYNC_PT_FOREIGN_CLEANUP_TYPE);
	if (error != PVRSRV_OK) {
		pr_err("pvr_sync: %s: Failed to allocate cleanup sync prim (%s)\n",
		       __func__, PVRSRVGetErrorStringKM(error));
		goto err_free_sync;
	}

	cleanup_sync->next_value++;

	list_add(&cleanup_sync->cleanup_list, &kernel->cleanup_sync_list);

	/* The custom waiter structure is freed in the waiter callback */
	waiter = kmalloc(sizeof(*waiter), GFP_KERNEL);
	if (!waiter) {
		pr_err("pvr_sync: %s: Failed to allocate waiter\n", __func__);
		goto err_free_cleanup_sync;
	}

	waiter->kernel = kernel;
	waiter->sync_fence = sync_fence;

	sync_fence_waiter_init(&waiter->waiter,
			       pvr_sync_foreign_sync_pt_signaled);
                   
    MTKPP_LOG(MTKPP_ID_SYNC, "[%p] wait tid:%d", fence, MTKGetCurrentProcessIDKM());

	err = sync_fence_wait_async(fence, &waiter->waiter);
	if (err) {
		if (err < 0) {
            MTKPP_LOG(MTKPP_ID_SYNC, "[%p] erro tid:%d err %d", fence, MTKGetCurrentProcessIDKM(), err);
			pr_err("pvr_sync: %s: Fence was in error state (%d)\n",
			       __func__, err);
			/* Fall-thru */
		}
        else
		{
			MTKPP_LOG(MTKPP_ID_SYNC, "[%p] sigled tid:%d", fence, MTKGetCurrentProcessIDKM());
		}

		/* -1 means the fence was broken, 1 means the fence already
		 * signalled. In either case, roll back what we've done and
		 * skip using this sync_pt for synchronization.
		 */
		goto err_free_waiter;
	}
#ifdef MTK_DEBUG_PROC_PRINT
	else
	{
		/*retrieve the sync info */
		struct list_head *pos;

		//MTKPP_LOG(MTKPP_ID_SYNC, "[%p] %s: status(%d)", fence, fence->name, fence->status);

		list_for_each(pos, &fence->pt_list_head) {
			struct sync_pt *pt =
				container_of(pos, struct sync_pt, pt_list);

			struct timeval tv = ktime_to_timeval(pt->timestamp);

			IMG_UINT32 d_data[1] = {};

			if (pt->parent->ops->fill_driver_data)
				pt->parent->ops->fill_driver_data(pt, d_data, sizeof(d_data));
/*
			MTKPP_LOG(MTKPP_ID_SYNC, "[%p] %s %s_pt status(%d) sync_drv(%u) @%ld.%06ld",
				fence, pt->parent->ops->driver_name,
				pt->parent->name, pt->status, d_data[0],
				tv.tv_sec, tv.tv_usec);*/
		}
#if 0
		spin_lock_irqsave(&psFence->waiter_list_lock, flags);
		list_for_each(pos, &psFence->waiter_list_head)
		{
			struct sync_fence_waiter *waiter =
				container_of(pos, struct sync_fence_waiter,
				 waiter_list);
			MTKPP_LOG(MTKPP_ID_SYNC,"waiter %pF\n", waiter->callback);
		}
		spin_unlock_irqrestore(&psFence->waiter_list_lock, flags);
#endif
	}
#endif

	kernel->current_cleanup_sync = cleanup_sync;

err_out:
	return kernel;
err_free_waiter:
	kfree(waiter);
err_free_cleanup_sync:
	list_del(&cleanup_sync->cleanup_list);
	sync_pool_put(cleanup_sync);
err_free_sync:
	sync_pool_put(kernel->fence_sync);
err_free_sync_fence:
	kfree(sync_fence);
err_free_kernel:
	kfree(kernel);
	kernel = NULL;
err_put_fence:
	sync_fence_put(fence);
	goto err_out;
}

static
struct pvr_sync_pt *pvr_sync_create_pt(struct pvr_sync_timeline *timeline)
{
	struct pvr_sync_data *sync_data;
	struct pvr_sync_pt *pvr_pt = NULL;

	sync_data = pvr_sync_create_sync_data(timeline->obj);
	if (!sync_data) {
		pr_err("pvr_sync: %s: Failed to create sync data\n", __func__);
		goto err_out;
	}

	sync_data->kernel->fence_sync->next_value++;

	pvr_pt = (struct pvr_sync_pt *)
		sync_pt_create(timeline->obj, sizeof(*pvr_pt));

	if (!pvr_pt) {
		pr_err("pvr_sync: %s: Failed to create sync pt\n", __func__);
		goto err_rollback_fence;
	}

	pvr_pt->sync_data = sync_data;

	/* Increment the timeline next value */
	pvr_pt->sync_data->timeline_update_value =
		timeline->kernel->fence_sync->next_value++;

	return pvr_pt;

err_rollback_fence:
	sync_data->kernel->fence_sync->next_value--;
	kref_put(&sync_data->kref, pvr_sync_free_sync_data);
err_out:
	return NULL;
}

/* Predeclare the pvr_sync_fops as it's used for comparison to ensure the
 * update_timeline_fd passed in to pvr_sync_append_fences() is a pvr_sync
 * timeline.
 */
static const struct file_operations pvr_sync_fops;

enum PVRSRV_ERROR pvr_sync_append_fences(
	const char                  		*name,
	const s32                   		check_fence_fd,
	const s32                   		update_timeline_fd,
	const u32                   		nr_updates,
	const struct _RGXFWIF_DEV_VIRTADDR_     *update_ufo_addresses,
	const u32                   		*update_values,
	const u32                   		nr_checks,
	const struct _RGXFWIF_DEV_VIRTADDR_     *check_ufo_addresses,
	const u32                   		*check_values,
	struct pvr_sync_append_data 		**append_sync_data)
{
	struct pvr_sync_native_sync_prim **cleanup_sync_pos;
	struct pvr_sync_pt *update_point = NULL;
	struct sync_fence *update_fence = NULL;
	struct pvr_sync_append_data *sync_data;
	struct _RGXFWIF_DEV_VIRTADDR_ *update_address_pos;
	struct _RGXFWIF_DEV_VIRTADDR_ *check_address_pos;
	struct pvr_sync_timeline *timeline;
	unsigned int num_used_sync_updates;
	unsigned int num_used_sync_checks;
	enum PVRSRV_ERROR err = PVRSRV_OK;
	u32 *update_value_pos;
	u32 *check_value_pos;

	if ((nr_updates && (!update_ufo_addresses || !update_values)) ||
	    (nr_checks && (!check_ufo_addresses || !check_values))) {
		err =  PVRSRV_ERROR_INVALID_PARAMS;
		goto err_out;
	}

	sync_data =
		kzalloc(sizeof(*sync_data), GFP_KERNEL);
	if (!sync_data) {
		err = PVRSRV_ERROR_OUT_OF_MEMORY;
		goto err_out;
	}

	sync_data->update_fence_fd = -1;

	if (update_timeline_fd >= 0) {
		struct file *timeline_file;

		/* We reserve the update fence FD before taking any operations
		 * as we do not want to fail (e.g. run out of FDs) after the
		 * kick operation has been submitted to the hw.
		 */
		sync_data->update_fence_fd = get_unused_fd();
		if (sync_data->update_fence_fd < 0) {
			err = PVRSRV_ERROR_OUT_OF_MEMORY;
			goto err_free_append_data;
		}

		timeline_file = fget(update_timeline_fd);
		if (!timeline_file) {
			pr_err("pvr_sync: %s: Failed to open supplied timeline fd (%d)\n",
				__func__, update_timeline_fd);
			err = PVRSRV_ERROR_HANDLE_NOT_FOUND;
			goto err_free_append_data;
		}

		if (timeline_file->f_op != &pvr_sync_fops) {
			pr_err("pvr_sync: %s: Supplied timeline not pvr_sync timeline\n",
				__func__);
			fput(timeline_file);
			err = PVRSRV_ERROR_INVALID_PARAMS;
			goto err_free_append_data;
		}

		timeline = get_timeline(timeline_file->private_data);

		/* We know this will not free the timeline as the user still
		 * has the fd referencing it.
		 */
		fput(timeline_file);

		if (!timeline) {
			pr_err("pvr_sync: %s: Supplied timeline has no private data\n",
				__func__);
			err = PVRSRV_ERROR_HANDLE_NOT_FOUND;
			goto err_free_append_data;
		}

		update_point = pvr_sync_create_pt(timeline);
		if (!update_point) {
			pr_err("pvr_sync: %s: Failed to create sync point\n",
				__func__);
			err = PVRSRV_ERROR_OUT_OF_MEMORY;
			goto err_free_append_data;
		}

		update_fence = sync_fence_create(name, &update_point->pt);
		if (!update_fence) {
			struct pvr_sync_native_sync_prim *fence_prim =
				update_point->sync_data->kernel->fence_sync;
			struct pvr_sync_native_sync_prim *timeline_prim =
				timeline->kernel->fence_sync;

			pr_err("pvr_sync: %s: Failed to create sync fence\n",
				__func__);
			err = PVRSRV_ERROR_OUT_OF_MEMORY;

			/* If the point was created but the fence failed to be
			 * created, the point must be manually free'd as a
			 * fence has not yet taken ownership.
			 */

			/* First rollback the point's taken operations */
			timeline_prim->next_value--;
			fence_prim->next_value--;
			pvr_sync_free_sync(&update_point->pt);
			goto err_free_append_data;
		}

		sync_data->update_fence = update_fence;
		sync_data->update_sync =
			update_point->sync_data->kernel->fence_sync;
		sync_data->update_timeline_sync =
			timeline->kernel->fence_sync;
	}

	sync_data->nr_checks = nr_checks;
	sync_data->nr_updates = nr_updates;

	if (check_fence_fd >= 0) {
		struct sync_fence *fence = sync_fence_fdget(check_fence_fd);
		struct pvr_sync_kernel_pair *sync_kernel;
		unsigned int points_on_fence = 0;
		bool has_foreign_point = false;
		struct sync_pt *sync_pt;
		int j;

		if (!fence) {
			pr_err("pvr_sync: %s: Failed to read sync private data for fd %d\n",
				__func__, check_fence_fd);
			err = PVRSRV_ERROR_HANDLE_NOT_FOUND;
			goto err_free_fence;
		}

		sync_data->check_fence = fence;

		(void)j;
		for_each_sync_pt(sync_pt, fence, j) {
			struct pvr_sync_native_sync_prim *cleanup_sync = NULL;
			struct pvr_sync_pt *pvr_pt;

			if (!is_pvr_timeline_pt(sync_pt)) {
				if (!sync_pt_get_status(sync_pt))
					has_foreign_point = true;
				continue;
			}

			pvr_pt = (struct pvr_sync_pt *)sync_pt;
			sync_kernel = pvr_pt->sync_data->kernel;

			if (!sync_kernel ||
			    is_sync_met(sync_kernel->fence_sync)) {
				continue;
			}

			/* We will use the above sync for "check" only. In this
			 * case also insert a "cleanup" update command into the
			 * opengl stream. This can later be used for checking
			 * if the sync prim could be freed.
			 */
			err = sync_pool_get(&cleanup_sync,
				sync_pt_parent(&pvr_pt->pt)->name,
				SYNC_PT_CLEANUP_TYPE);
			if (err != PVRSRV_OK) {
				pr_err("pvr_sync: %s: Failed to allocate cleanup sync prim (%s)\n",
				       __func__,
				       PVRSRVGetErrorStringKM(err));
				goto err_free_append_data;
			}
			list_add(&cleanup_sync->cleanup_list,
				&sync_kernel->cleanup_sync_list);
			sync_kernel->current_cleanup_sync = cleanup_sync;
			points_on_fence++;
		}

		if (has_foreign_point)
			points_on_fence++;

		/* Each point has 1 check value, and 1 update value (for the
		 * cleanup fence).
		 */
		sync_data->nr_checks += points_on_fence;
		sync_data->nr_updates += points_on_fence;
		sync_data->nr_cleanup_syncs += points_on_fence;
	}

	if (update_point) {
		/* A fence update requires 2 update values (fence and timeline)
		 */
		 sync_data->nr_updates += 2;
	}

	if (sync_data->nr_updates > 0) {
		sync_data->update_ufo_addresses =
			kzalloc(sizeof(*sync_data->update_ufo_addresses) *
					sync_data->nr_updates,
				GFP_KERNEL);
		if (!sync_data->update_ufo_addresses) {
			pr_err("pvr_sync: %s: Failed to allocate update UFO address list\n",
				__func__);
			err = PVRSRV_ERROR_OUT_OF_MEMORY;
			goto err_free_fence;
		}

		sync_data->update_values =
			kzalloc(sizeof(*sync_data->update_values) * sync_data->nr_updates,
				GFP_KERNEL);
		if (!sync_data->update_values) {
			pr_err("pvr_sync: %s: Failed to allocate update value list\n",
				__func__);
			err = PVRSRV_ERROR_OUT_OF_MEMORY;
			goto err_free_fence;
		}
	}

	if (sync_data->nr_checks > 0) {

		sync_data->check_ufo_addresses =
			kzalloc(sizeof(*sync_data->check_ufo_addresses) *
					sync_data->nr_checks,
				GFP_KERNEL);
		if (!sync_data->check_ufo_addresses) {
			pr_err("pvr_sync: %s: Failed to allocate check UFO address list\n",
				__func__);
			err = PVRSRV_ERROR_OUT_OF_MEMORY;
			goto err_free_fence;
		}

		sync_data->check_values =
			kzalloc(sizeof(*sync_data->check_values) * sync_data->nr_checks,
				GFP_KERNEL);
		if (!sync_data->check_values) {
			pr_err("pvr_sync: %s: Failed to allocate check value list\n",
				__func__);
			err = PVRSRV_ERROR_OUT_OF_MEMORY;
			goto err_free_fence;
		}
	}

	if (sync_data->nr_cleanup_syncs > 0) {
		sync_data->cleanup_syncs =
			kzalloc(sizeof(*sync_data->cleanup_syncs) *
				sync_data->nr_cleanup_syncs, GFP_KERNEL);
		if (!sync_data->cleanup_syncs) {
			pr_err("pvr_sync: %s: Failed to allocate cleanup rollback list\n",
				__func__);
			err = PVRSRV_ERROR_OUT_OF_MEMORY;
			goto err_free_fence;
		}
	}

	update_address_pos = sync_data->update_ufo_addresses;
	update_value_pos = sync_data->update_values;
	check_address_pos = sync_data->check_ufo_addresses;
	check_value_pos = sync_data->check_values;
	cleanup_sync_pos = sync_data->cleanup_syncs;


	/* Everything should be allocated/sanity checked. No errors are
	 * possible after this point.
	 */

	/* Append any check syncs */
	if (sync_data->check_fence) {
		struct sync_fence *fence = sync_data->check_fence;
		bool has_foreign_point = false;
		struct sync_pt *sync_pt;
		int j;

		(void)j;
		for_each_sync_pt(sync_pt, fence, j) {
			struct pvr_sync_pt *pvr_pt;
			struct pvr_sync_kernel_pair *sync_kernel;

			if (!is_pvr_timeline_pt(sync_pt)) {
				if (!sync_pt_get_status(sync_pt))
					has_foreign_point = true;
				continue;
			}

			pvr_pt = (struct pvr_sync_pt *)sync_pt;
			sync_kernel = pvr_pt->sync_data->kernel;

			if (!sync_kernel ||
			    is_sync_met(sync_kernel->fence_sync)) {
				continue;
			}

			(*check_address_pos++).ui32Addr =
				sync_kernel->fence_sync->vaddr;
			*check_value_pos++ =
				sync_kernel->fence_sync->next_value;

			(*update_address_pos++).ui32Addr =
				sync_kernel->current_cleanup_sync->vaddr;
			*update_value_pos++ =
				++sync_kernel->current_cleanup_sync->next_value;
			*cleanup_sync_pos++ = sync_kernel->current_cleanup_sync;

			sync_kernel->current_cleanup_sync = NULL;
		}

		if (has_foreign_point) {
			struct pvr_sync_kernel_pair *foreign_sync_kernel =
				pvr_sync_create_waiter_for_foreign_sync(
					check_fence_fd);

			if (foreign_sync_kernel) {
				struct pvr_sync_native_sync_prim *fence_sync =
					foreign_sync_kernel->fence_sync;
				struct pvr_sync_native_sync_prim *cleanup_sync =
					foreign_sync_kernel->
						current_cleanup_sync;


				(*check_address_pos++).ui32Addr =
					fence_sync->vaddr;
				*check_value_pos++ =
					fence_sync->next_value;

				(*update_address_pos++).ui32Addr =
					cleanup_sync->vaddr;
				*update_value_pos++ =
					++cleanup_sync->next_value;
				*cleanup_sync_pos++ = cleanup_sync;
				foreign_sync_kernel->current_cleanup_sync =
					NULL;
			}
		}
	}

	/* Append the update sync (if requested) */
	if (update_point) {
		struct pvr_sync_data *sync_data =
			update_point->sync_data;
		struct pvr_sync_kernel_pair *sync_kernel =
			sync_data->kernel;

		(*update_address_pos++).ui32Addr =
			sync_kernel->fence_sync->vaddr;
		*update_value_pos++ =
			sync_kernel->fence_sync->next_value;

		(*update_address_pos++).ui32Addr =
			timeline->kernel->fence_sync->vaddr;

		/* Copy in the timeline next value (which was incremented
		 * when this point was created).
		 */
		sync_data->timeline_update_value =
			timeline->kernel->fence_sync->next_value;

		/* ...and set that to be updated when this kick is completed */
		*update_value_pos++ =
			sync_data->timeline_update_value;
	}

	/* We count the total number of sync points we attach, as it's possible
	 * some have become complete since the first loop through, or a waiter
	 * for a foreign point skipped (But they can never become un-complete,
	 * so it will only ever be the same or less, so the allocated arrays
	 * should still be sufficiently sized).
	 */
	num_used_sync_updates =
		update_address_pos - sync_data->update_ufo_addresses;
	num_used_sync_checks =
		check_address_pos - sync_data->check_ufo_addresses;

	sync_data->nr_checks = nr_checks + num_used_sync_checks;
	sync_data->nr_updates = nr_updates + num_used_sync_updates;

	/* Append original check and update sync values/addresses */
	if (update_ufo_addresses)
		memcpy(update_address_pos, update_ufo_addresses,
			   sizeof(*update_ufo_addresses) * nr_updates);
	if (update_values)
		memcpy(update_value_pos, update_values,
			   sizeof(*update_values) * nr_updates);

	if (check_ufo_addresses)
		memcpy(check_address_pos, check_ufo_addresses,
			   sizeof(*check_ufo_addresses) * nr_checks);
	if (check_values)
		memcpy(check_value_pos, check_values,
			   sizeof(*check_values) * nr_checks);

	*append_sync_data = sync_data;

	return PVRSRV_OK;

err_free_fence:
	if (update_point) {
		/* First rollback the taken operations */
		timeline->kernel->fence_sync->next_value--;
		update_point->sync_data->kernel->fence_sync->next_value--;
	}
err_free_append_data:
	pvr_sync_free_append_fences_data(sync_data);
err_out:
	return err;
}

void pvr_sync_get_updates(const struct pvr_sync_append_data *sync_data,
	u32 *nr_fences, struct _RGXFWIF_DEV_VIRTADDR_ **ufo_addrs, u32 **values)
{
	*nr_fences = sync_data->nr_updates;
	*ufo_addrs = sync_data->update_ufo_addresses;
	*values = sync_data->update_values;
}

void pvr_sync_get_checks(const struct pvr_sync_append_data *sync_data,
	u32 *nr_fences, struct _RGXFWIF_DEV_VIRTADDR_ **ufo_addrs, u32 **values)
{
	*nr_fences = sync_data->nr_checks;
	*ufo_addrs = sync_data->check_ufo_addresses;
	*values = sync_data->check_values;
}

void pvr_sync_rollback_append_fences(struct pvr_sync_append_data *sync_data)
{
	u32 i;

	if (!sync_data)
		return;

	for (i = 0; i < sync_data->nr_cleanup_syncs; i++) {
		struct pvr_sync_native_sync_prim *cleanup_sync =
			sync_data->cleanup_syncs[i];

		/* If this cleanup was called on a partially-created data set
		 * it's possible to have NULL cleanup sync pointers.
		 */
		if (!cleanup_sync)
			continue;
		cleanup_sync->next_value--;
	}

	/* If there was an update, rollback the next values taken on the
	 * fence and timeline. This must be done before the sync_fence_put()
	 * as that may free the corresponding fence.
	 */

	if (sync_data->update_sync) {
		BUG_ON(sync_data->update_sync->next_value != 1);
		sync_data->update_sync->next_value = 0;
		sync_data->update_sync = NULL;
	}

	if (sync_data->update_timeline_sync) {
		BUG_ON(sync_data->update_timeline_sync->next_value == 0);
		sync_data->update_timeline_sync->next_value--;
		sync_data->update_timeline_sync = NULL;
	}
}

int pvr_sync_get_update_fd(struct pvr_sync_append_data *sync_data)
{
	int fd = -EINVAL;

	if (!sync_data || !sync_data->update_fence ||
		sync_data->update_fence_fd < 0)
		goto err_out;

	fd = sync_data->update_fence_fd;
	sync_data->update_fence_fd = -1;

	sync_fence_install(sync_data->update_fence, fd);

	/* Note: It is invalid for an FD to have been installed on the update
	 * fence then fput called - as this would leave a dangling reference
	 * in the FD table. Set it to NULL so the free_append_fences_data()
	 * call doesn't fput it.
	 */
	sync_data->update_fence = NULL;

err_out:
	return fd;
}

void pvr_sync_free_append_fences_data(struct pvr_sync_append_data *sync_data)
{
	if (!sync_data)
		return;

	if (sync_data->check_fence)
		sync_fence_put(sync_data->check_fence);

	if (sync_data->update_fence)
		sync_fence_put(sync_data->update_fence);

	if (sync_data->update_fence_fd >= 0)
		put_unused_fd(sync_data->update_fence_fd);

	kfree(sync_data->update_ufo_addresses);
	kfree(sync_data->update_values);
	kfree(sync_data->check_ufo_addresses);
	kfree(sync_data->check_values);
	kfree(sync_data->cleanup_syncs);
	kfree(sync_data);
}

void pvr_sync_nohw_complete_fences(struct pvr_sync_append_data *sync_data)
{
	u32 i;

	if (!sync_data)
		return;

	for (i = 0; i < sync_data->nr_cleanup_syncs; i++) {
		struct pvr_sync_native_sync_prim *cleanup_sync =
			sync_data->cleanup_syncs[i];

		if (!cleanup_sync)
			continue;

		complete_sync(cleanup_sync);
	}

	if (sync_data->update_sync)
		complete_sync(sync_data->update_sync);
	if (sync_data->update_timeline_sync)
		complete_sync(sync_data->update_timeline_sync);

	pvr_sync_update_all_timelines(NULL);
}

/* ioctl and fops handling */

static int pvr_sync_open(struct inode *inode, struct file *file)
{
	struct pvr_sync_timeline_wrapper *timeline_wrapper;
	struct pvr_sync_timeline *timeline;
	char task_comm[TASK_COMM_LEN];
	enum PVRSRV_ERROR error;
	int err = -ENOMEM;

	get_task_comm(task_comm, current);

	timeline_wrapper = (struct pvr_sync_timeline_wrapper *)
		sync_timeline_create(&pvr_sync_timeline_ops,
			sizeof(*timeline_wrapper), task_comm);
	if (!timeline_wrapper) {
		pr_err("pvr_sync: %s: sync_timeline_create failed\n", __func__);
		goto err_out;
	}

	timeline = kmalloc(sizeof(*timeline), GFP_KERNEL);
	if (!timeline) {
		pr_err("pvr_sync: %s: Out of memory\n", __func__);
		goto err_free_timeline_wrapper;
	}

	timeline->kernel = kzalloc(sizeof(*timeline->kernel),
				   GFP_KERNEL);
	if (!timeline->kernel) {
		pr_err("pvr_sync: %s: Out of memory\n", __func__);
		goto err_free_timeline;
	}

	INIT_LIST_HEAD(&timeline->kernel->cleanup_sync_list);

	OSAcquireBridgeLock();
	error = sync_pool_get(&timeline->kernel->fence_sync,
			      task_comm, SYNC_TL_TYPE);
	OSReleaseBridgeLock();

	if (error != PVRSRV_OK) {
		pr_err("pvr_sync: %s: Failed to allocate sync prim (%s)\n",
			__func__, PVRSRVGetErrorStringKM(error));
		goto err_free_timeline_kernel;
	}

	timeline_wrapper->timeline = timeline;

	timeline->obj = &timeline_wrapper->obj;
	kref_init(&timeline->kref);

	mutex_lock(&timeline_list_mutex);
	list_add_tail(&timeline->list, &timeline_list);
	mutex_unlock(&timeline_list_mutex);

	DPF("%s: # %s", __func__, debug_info_timeline(timeline));

	file->private_data = timeline_wrapper;
	err = 0;
err_out:
	return err;

err_free_timeline_kernel:
	kfree(timeline->kernel);
err_free_timeline:
	kfree(timeline);

	/* Use a NULL timeline to detect this partially-setup timeline in the
	 * timeline release function (called by sync_timeline_destroy) and
	 * handle it appropriately.
	 */
	timeline_wrapper->timeline = NULL;
err_free_timeline_wrapper:
	sync_timeline_destroy(&timeline_wrapper->obj);
	goto err_out;
}

static int pvr_sync_close(struct inode *inode, struct file *file)
{
	struct sync_timeline *obj = file->private_data;

	if (is_pvr_timeline(obj)) {
		DPF("%s: # %s", __func__,
		    debug_info_timeline(get_timeline(obj)));
	}

	sync_timeline_destroy(obj);
	return 0;
}

static long pvr_sync_ioctl_rename(struct pvr_sync_timeline *timeline,
	void __user *user_data)
{
	int err = 0;
	struct pvr_sync_rename_ioctl_data data;

	if (!access_ok(VERIFY_READ, user_data, sizeof(data))) {
		err = -EFAULT;
		goto err;
	}

	if (copy_from_user(&data, user_data, sizeof(data))) {
		err = -EFAULT;
		goto err;
	}

	data.szName[sizeof(data.szName) - 1] = '\0';
	strlcpy(timeline->obj->name, data.szName, sizeof(timeline->obj->name));

	mutex_lock(&sync_pool_mutex);
	strlcpy(timeline->kernel->fence_sync->class, data.szName,
	        sizeof(timeline->kernel->fence_sync->class));
	mutex_unlock(&sync_pool_mutex);
err:
	return err;
}

#ifndef CONFIG_SW_SYNC_USER

static long pvr_sync_ioctl_force_sw_only(struct pvr_sync_timeline *timeline,
	void **private_data)
{
	struct sw_sync_timeline *sw_sync_timeline;

	/* We can only convert an empty GPU timeline */
	if (timeline->kernel->fence_sync->next_value)
		return -EFAULT;

	/* Create a sw_sync timeline with the old GPU timeline's name */
	sw_sync_timeline = sw_sync_timeline_create(timeline->obj->name);
	if (!sw_sync_timeline)
		return -ENOMEM;

	/* Destroy the old GPU timeline and update the struct file */
	DPF("%s: # %s", __func__, debug_info_timeline(timeline));

	sync_timeline_destroy(timeline->obj);
	*private_data = sw_sync_timeline;
	return 0;
}

static long pvr_sync_ioctl_sw_create_fence(struct sw_sync_timeline *timeline,
	void __user *user_data)
{
	struct sw_sync_create_fence_data data;
	struct sync_fence *fence;
	int fd = get_unused_fd();
	struct sync_pt *sync_pt;
	int err = -EFAULT;

	if (fd < 0) {
		pr_err("pvr_sync: %s: Failed to find unused fd (%d)\n",
		       __func__, fd);
		goto err_out;
	}

	if (copy_from_user(&data, user_data, sizeof(data)))
		goto err_put_fd;

	sync_pt = sw_sync_pt_create(timeline, data.value);
	if (!sync_pt) {
		pr_err("pvr_sync: %s: Failed to create a sync point (%d)\n",
		       __func__, fd);
		err = -ENOMEM;
		goto err_put_fd;
	}

	data.name[sizeof(data.name) - 1] = '\0';
	fence = sync_fence_create(data.name, sync_pt);
	if (!fence) {
		pr_err("pvr_sync: %s: Failed to create a fence (%d)\n",
		       __func__, fd);
		sync_pt_free(sync_pt);
		err = -ENOMEM;
		goto err_put_fd;
	}

	data.fence = fd;

	if (copy_to_user(user_data, &data, sizeof(data)))
		goto err_put_fence;

	sync_fence_install(fence, fd);
	err = 0;
err_out:
	return err;
err_put_fence:
	sync_fence_put(fence);
err_put_fd:
	put_unused_fd(fd);
	goto err_out;
}

static long pvr_sync_ioctl_sw_inc(struct sw_sync_timeline *timeline,
	void __user *user_data)
{
	u32 value;

	if (copy_from_user(&value, user_data, sizeof(value)))
		return -EFAULT;

	sw_sync_timeline_inc(timeline, value);
	return 0;
}

#endif /* !CONFIG_SW_SYNC_USER */

static long
pvr_sync_ioctl(struct file *file, unsigned int cmd, unsigned long __user arg)
{
	struct sync_timeline *obj = file->private_data;
	void __user *user_data = (void __user *)arg;
	long err = -ENOTTY;

	if (is_pvr_timeline(obj)) {
		struct pvr_sync_timeline *pvr = get_timeline(obj);

		switch (cmd) {
		case PVR_SYNC_IOC_RENAME:
			err = pvr_sync_ioctl_rename(pvr, user_data);
			break;
#ifndef CONFIG_SW_SYNC_USER
		case PVR_SYNC_IOC_FORCE_SW_ONLY:
			err = pvr_sync_ioctl_force_sw_only(pvr,
				&file->private_data);
			break;
#endif /* !CONFIG_SW_SYNC_USER */
		default:
			break;
		}
	} else {
#ifndef CONFIG_SW_SYNC_USER
		struct sw_sync_timeline *sw = file->private_data;

		switch (cmd) {
		case SW_SYNC_IOC_CREATE_FENCE:
			err = pvr_sync_ioctl_sw_create_fence(sw, user_data);
			break;
		case SW_SYNC_IOC_INC:
			err = pvr_sync_ioctl_sw_inc(sw, user_data);
			break;
		default:
			break;
		}
#endif /* !CONFIG_SW_SYNC_USER */
	}

	return err;
}

static void
pvr_sync_check_status_work_queue_function(struct work_struct *data)
{
	/* A completed SW operation may un-block the GPU */
	PVRSRVCheckStatus(NULL);
}

/* Returns true if the freelist still has entries, else false if empty */
static bool
pvr_sync_clean_freelist(void)
{
	struct pvr_sync_kernel_pair *kernel, *k;
	struct pvr_sync_fence *sync_fence, *f;
	LIST_HEAD(unlocked_free_list);
	unsigned long flags;
	bool freelist_empty;

	/* We can't call PVRSRVServerSyncFreeKM directly in this loop because
	 * that will take the mmap mutex. We can't take mutexes while we have
	 * this list locked with a spinlock. So move all the items we want to
	 * free to another, local list (no locking required) and process it
	 * in a second loop.
	 */

	spin_lock_irqsave(&sync_prim_free_list_spinlock, flags);
	list_for_each_entry_safe(kernel, k, &sync_prim_free_list, list) {
		bool in_use = false;
		struct list_head *pos;

		/* Check if this sync is not used anymore. */
		if (!is_sync_met(kernel->fence_sync))
			continue;
		list_for_each(pos, &kernel->cleanup_sync_list) {
			struct pvr_sync_native_sync_prim *cleanup_sync =
				list_entry(pos,
					struct pvr_sync_native_sync_prim,
					cleanup_list);

			if (!is_sync_met(cleanup_sync)) {
				in_use = true;
				break;
			}
		}

		if (in_use)
			continue;

		/* Remove the entry from the free list. */
		list_move_tail(&kernel->list, &unlocked_free_list);
	}

	/* Wait and loop if there are still syncs on the free list (IE
	 * are still in use by the HW).
	 */
	freelist_empty = list_empty(&sync_prim_free_list);

	spin_unlock_irqrestore(&sync_prim_free_list_spinlock, flags);

	OSAcquireBridgeLock();

	list_for_each_entry_safe(kernel, k, &unlocked_free_list, list) {
		struct list_head *pos, *n;

		list_del(&kernel->list);

		sync_pool_put(kernel->fence_sync);

		list_for_each_safe(pos, n, &kernel->cleanup_sync_list) {
			struct pvr_sync_native_sync_prim *cleanup_sync =
				list_entry(pos,
					struct pvr_sync_native_sync_prim,
					 cleanup_list);
			list_del(&cleanup_sync->cleanup_list);
			sync_pool_put(cleanup_sync);
		}
		kfree(kernel);
	}

	OSReleaseBridgeLock();

	/* sync_fence_put() must be called from process/WQ context
	 * because it uses fput(), which is not allowed to be called
	 * from interrupt context in kernels <3.6.
	 */
	INIT_LIST_HEAD(&unlocked_free_list);

	spin_lock_irqsave(&sync_fence_put_list_spinlock, flags);
	list_for_each_entry_safe(sync_fence, f, &sync_fence_put_list, list) {
		list_move_tail(&sync_fence->list, &unlocked_free_list);
	}
	spin_unlock_irqrestore(&sync_fence_put_list_spinlock, flags);

	list_for_each_entry_safe(sync_fence, f, &unlocked_free_list, list) {
		list_del(&sync_fence->list);
		sync_fence_put(sync_fence->fence);
		kfree(sync_fence);
	}

	return !freelist_empty;
}

static void
pvr_sync_defer_free_work_queue_function(struct work_struct *data)
{
	enum PVRSRV_ERROR error = PVRSRV_OK;
	void *event_object;

	error = OSEventObjectOpen(pvr_sync_data.event_object_handle,
		&event_object);
	if (error != PVRSRV_OK) {
		pr_err("pvr_sync: %s: Error opening event object (%s)\n",
			__func__, PVRSRVGetErrorStringKM(error));
		return;

	}

	while (pvr_sync_clean_freelist()) {

		error = OSEventObjectWait(event_object);

		switch (error) {

		case PVRSRV_OK:
		case PVRSRV_ERROR_TIMEOUT:
			/* Timeout is normal behaviour */
			continue;
		default:
			pr_err("pvr_sync: %s: Error waiting for event object (%s)\n",
				__func__, PVRSRVGetErrorStringKM(error));
			break;
		}
	}
	error = OSEventObjectClose(event_object);
	if (error != PVRSRV_OK) {
		pr_err("pvr_sync: %s: Error closing event object (%s)\n",
			__func__, PVRSRVGetErrorStringKM(error));
	}
}

static const struct file_operations pvr_sync_fops = {
	.owner          = THIS_MODULE,
	.open           = pvr_sync_open,
	.release        = pvr_sync_close,
	.unlocked_ioctl = pvr_sync_ioctl,
	.compat_ioctl   = pvr_sync_ioctl,
};

static struct miscdevice pvr_sync_device = {
	.minor          = MISC_DYNAMIC_MINOR,
	.name           = PVRSYNC_MODNAME,
	.fops           = &pvr_sync_fops,
};

static
void pvr_sync_update_all_timelines(void *command_complete_handle)
{
	struct pvr_sync_timeline *timeline, *n;

	mutex_lock(&timeline_list_mutex);

	list_for_each_entry(timeline, &timeline_list, list) {
		/* If a timeline is destroyed via pvr_sync_release_timeline()
		 * in parallel with a call to pvr_sync_update_all_timelines(),
		 * the timeline_list_mutex will block destruction of the
		 * 'timeline' pointer. Use kref_get_unless_zero() to detect
		 * and handle this race. Skip the timeline if it's being
		 * destroyed, blocked only on the timeline_list_mutex.
		 */
		timeline->valid =
			kref_get_unless_zero(&timeline->kref) ? true : false;
	}

	list_for_each_entry_safe(timeline, n, &timeline_list, list) {
		/* We know timeline is valid at this point because we're
		 * holding the list lock (so pvr_sync_destroy_timeline() has
		 * to wait).
		 */
		void *obj = timeline->obj;

		/* If we're racing with pvr_sync_release_timeline(), ignore */
		if (!timeline->valid)
			continue;

		/* If syncs have signaled on the GPU, echo this in pvr_sync.
		 *
		 * At this point we know the timeline is valid, but obj might
		 * have raced and been set to NULL. It's only important that
		 * we use NULL / non-NULL consistently with the if() and call
		 * to sync_timeline_signal() -- the timeline->obj can't be
		 * freed (pvr_sync_release_timeline() will be stuck waiting
		 * for the timeline_list_mutex) but it might have been made
		 * invalid by the base sync driver, in which case this call
		 * will bounce harmlessly.
		 */
		if (obj)
			sync_timeline_signal(obj);

		/* We're already holding the timeline_list_mutex */
		kref_put(&timeline->kref, pvr_sync_destroy_timeline_locked);
	}

	mutex_unlock(&timeline_list_mutex);
}

enum PVRSRV_ERROR pvr_sync_init(void *device_cookie)
{
	enum PVRSRV_ERROR error;
	int err;

	DPF("%s", __func__);

	atomic_set(&pvr_sync_data.sync_id, 0);

	error = PVRSRVAcquireGlobalEventObjectKM(
		&pvr_sync_data.event_object_handle);
	if (error != PVRSRV_OK) {
		pr_err("pvr_sync: %s: Failed to acquire global event object (%s)\n",
			__func__, PVRSRVGetErrorStringKM(error));
		goto err_out;
	}

	OSAcquireBridgeLock();

	error = SyncPrimContextCreate(device_cookie,
				      &pvr_sync_data.sync_prim_context);
	if (error != PVRSRV_OK) {
		pr_err("pvr_sync: %s: Failed to create sync prim context (%s)\n",
		       __func__, PVRSRVGetErrorStringKM(error));
		OSReleaseBridgeLock();
		goto err_release_event_object;
	}

	OSReleaseBridgeLock();

	pvr_sync_data.defer_free_wq =
		create_freezable_workqueue("pvr_sync_defer_free_workqueue");
	if (!pvr_sync_data.defer_free_wq) {
		pr_err("pvr_sync: %s: Failed to create pvr_sync defer_free workqueue\n",
		       __func__);
		goto err_free_sync_context;
	}

	INIT_WORK(&pvr_sync_data.defer_free_work,
		pvr_sync_defer_free_work_queue_function);

	pvr_sync_data.check_status_wq =
		create_freezable_workqueue("pvr_sync_check_status_workqueue");
	if (!pvr_sync_data.check_status_wq) {
		pr_err("pvr_sync: %s: Failed to create pvr_sync check_status workqueue\n",
		       __func__);
		goto err_destroy_defer_free_wq;
	}

	INIT_WORK(&pvr_sync_data.check_status_work,
		pvr_sync_check_status_work_queue_function);
	error = PVRSRVRegisterCmdCompleteNotify(
			&pvr_sync_data.command_complete_handle,
			&pvr_sync_update_all_timelines,
			&device_cookie);
	if (error != PVRSRV_OK) {
		pr_err("pvr_sync: %s: Failed to register MISR notification (%s)\n",
		       __func__, PVRSRVGetErrorStringKM(error));
		goto err_destroy_status_wq;
	}

	error = PVRSRVRegisterDbgRequestNotify(
			&pvr_sync_data.debug_notify_handle,
			device_cookie,
			pvr_sync_debug_request,
			DEBUG_REQUEST_ANDROIDSYNC,
			NULL);
	if (error != PVRSRV_OK) {
		pr_err("pvr_sync: %s: Failed to register debug notifier (%s)\n",
			__func__, PVRSRVGetErrorStringKM(error));
		goto err_unregister_cmd_complete;
	}

	err = misc_register(&pvr_sync_device);
	if (err) {
		pr_err("pvr_sync: %s: Failed to register pvr_sync device (%d)\n",
		       __func__, err);
		error = PVRSRV_ERROR_RESOURCE_UNAVAILABLE;
		goto err_unregister_dbg;
	}

	error = PVRSRV_OK;
	return error;

err_unregister_dbg:
	PVRSRVUnregisterDbgRequestNotify(pvr_sync_data.debug_notify_handle);
err_unregister_cmd_complete:
	PVRSRVUnregisterCmdCompleteNotify(
		pvr_sync_data.command_complete_handle);
err_destroy_status_wq:
	destroy_workqueue(pvr_sync_data.check_status_wq);
err_destroy_defer_free_wq:
	destroy_workqueue(pvr_sync_data.defer_free_wq);
err_free_sync_context:
	OSAcquireBridgeLock();
	SyncPrimContextDestroy(pvr_sync_data.sync_prim_context);
	OSReleaseBridgeLock();
err_release_event_object:
	PVRSRVReleaseGlobalEventObjectKM(pvr_sync_data.event_object_handle);
err_out:

	return error;
}

void pvr_sync_deinit(void)
{
	DPF("%s", __func__);

	misc_deregister(&pvr_sync_device);

	PVRSRVUnregisterDbgRequestNotify(pvr_sync_data.debug_notify_handle);

	PVRSRVUnregisterCmdCompleteNotify(
		pvr_sync_data.command_complete_handle);

	/* This will drain the workqueue, so we guarantee that all deferred
	 * syncs are free'd before returning.
	 */
	destroy_workqueue(pvr_sync_data.defer_free_wq);
	destroy_workqueue(pvr_sync_data.check_status_wq);

	OSAcquireBridgeLock();

	sync_pool_clear();

	SyncPrimContextDestroy(pvr_sync_data.sync_prim_context);

	OSReleaseBridgeLock();

	PVRSRVReleaseGlobalEventObjectKM(pvr_sync_data.event_object_handle);
}
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            /* SCP sensor hub driver
 *
 *
 * This software program is licensed subject to the GNU General Public License
 * (GPL).Version 2,June 1991, available at http://www.fsf.org/copyleft/gpl.html

 * (C) Copyright 2011 Bosch Sensortec GmbH
 * All Rights Reserved
 */

#include <linux/interrupt.h>
#include <linux/slab.h>
#include <linux/irq.h>
#include <linux/miscdevice.h>
#include <asm/uaccess.h>
#include <linux/delay.h>
#include <linux/input.h>
#include <linux/workqueue.h>
#include <linux/kobject.h>
#include <linux/platform_device.h>
#include <linux/dma-mapping.h>
#include <asm/atomic.h>
#include <linux/types.h>
#include <batch.h>
#include <scp_ipi.h>
#include "scp_helper.h"
#include "scp_excep.h"
#include <linux/time.h>
#include "cust_sensorHub.h"
#include "hwmsensor.h"
#include "hwmsen_dev.h"
#include "sensors_io.h"
#include "SCP_sensorHub.h"
#include "hwmsen_helper.h"

#define SENSOR_DATA_SIZE 48
/*
 * experience number for delay_count per DELAY_COUNT sensor input delay 10ms
 * msleep(20) system will schedule to hal process then read input node
 */
#define DELAY_COUNT			32
#define SCP_sensorHub_DEV_NAME        "SCP_sensorHub"
static int SCP_sensorHub_local_remove(void);
static int SCP_sensorHub_local_init(void);
static int scp_sensorHub_power_adjust(void);
static int sensor_send_ap_timetamp(void);
static int SCP_sensorHub_server_dispatch_data(void);
static int SCP_sensorHub_report_data(struct data_unit_t *data_t);
static void clean_up_deactivate_ringbuffer(int handle);

typedef enum {
	SCP_TRC_FUN = 0x01,
	SCP_TRC_IPI = 0x02,
	SCP_TRC_BATCH = 0x04,
	SCP_TRC_BATCH_DETAIL = 0x08,
} SCP_TRC;
SCP_sensorHub_handler sensor_handler[ID_SENSOR_MAX_HANDLE + 1];
static DEFINE_MUTEX(SCP_sensorHub_op_mutex);
static DEFINE_MUTEX(SCP_sensorHub_req_mutex);
static DEFINE_MUTEX(SCP_sensorHub_report_data_mutex);
static DECLARE_WAIT_QUEUE_HEAD(SCP_sensorHub_req_wq);

static int SCP_sensorHub_init_flag = -1;

static struct batch_init_info SCP_sensorHub_init_info = {
	.name = "SCP_sensorHub",
	.init = SCP_sensorHub_local_init,
	.uninit = SCP_sensorHub_local_remove,
	.platform_diver_addr = NULL,
};

struct sensor_client {
	char name[16];
	spinlock_t buffer_lock;
	unsigned int head;
	unsigned int tail;
	unsigned int bufsize;
	struct data_unit_t *ringbuffer;
	struct work_struct worker;
	struct workqueue_struct *single_thread;
	atomic_t delay_count;
};
struct SCP_sensorHub_data {
	struct sensorHub_hw *hw;
	struct work_struct ipi_work;
	struct work_struct fifo_full_work;

	struct work_struct batch_timeout_work;
	struct work_struct direct_push_work;
	struct work_struct power_notify_work;
	struct timer_list timer;
	struct timer_list notify_timer;
	/*misc */
	atomic_t trace;
	atomic_t suspend;
	atomic_t wait_rsp;
	atomic_t ipi_handler_running;
	atomic_t disable_fifo_full_notify;
	unsigned long sensor_activate_bitmap;
	unsigned long flush_remain_data_after_disable;

	volatile struct sensorFIFO *volatile SCP_sensorFIFO;
	volatile struct sensorFIFO *volatile SCP_directPush_FIFO;
	struct sensor_client client[ID_SENSOR_MAX_HANDLE];
	phys_addr_t shub_dram_phys;
	phys_addr_t shub_dram_virt;
	phys_addr_t shub_direct_push_dram_phys;
	phys_addr_t shub_direct_push_dram_virt;
};

static struct device SCP_sensorHub_dev = {
	.init_name = "SCPdmadev",
	.coherent_dma_mask = ~0,	/* dma_alloc_coherent(): allow any address */
	.dma_mask = &SCP_sensorHub_dev.coherent_dma_mask,	/* other APIs: use the same mask as coherent */
};

static struct SCP_sensorHub_data *obj_data;
static SCP_SENSOR_HUB_DATA_P userData;
static uint *userDataLen;
#define SCP_TAG                  "[sensorHub] "
#define SCP_FUN(f)               pr_debug(SCP_TAG"%s\n", __func__)
#define SCP_ERR(fmt, args...)    pr_err(SCP_TAG"%s %d : "fmt, __func__, __LINE__, ##args)
#define SCP_LOG(fmt, args...)    pr_debug(SCP_TAG fmt, ##args)

#define SENSOR_SCP_AP_TIME_SYNC

#ifdef SENSOR_SCP_AP_TIME_SYNC

#define SYNC_CYCLC 10		/*600s */

struct timer_list sync_timer;
struct work_struct syncwork;

static void syncwork_fun(struct work_struct *work)
{
	sensor_send_ap_timetamp();
	mod_timer(&sync_timer, jiffies + SYNC_CYCLC * HZ);
}

static void sync_timeout(unsigned long data)
{
	schedule_work(&syncwork);
}

#endif

static unsigned long long SCP_sensorHub_GetCurNS(void)
{
/*
    int64_t  nt;
    struct timespec time;

    time.tv_sec = 0;
    time.tv_nsec = 0;
    get_monotonic_boottime(&time);
    nt = time.tv_sec*1000000000LL+time.tv_nsec;
*/

	return sched_clock();
}

static int SCP_sensorHub_get_scp_semaphore(void)
{
	int64_t start_nt, cur_nt;
	struct timespec time;
	int err;

	time.tv_sec = 0;
	time.tv_nsec = 0;
	get_monotonic_boottime(&time);
	start_nt = time.tv_sec * 1000000000LL + time.tv_nsec;

	do {
		err = get_scp_semaphore(SEMAPHORE_SENSOR);
		if (err < 0) {
			time.tv_sec = 0;
			time.tv_nsec = 0;
			get_monotonic_boottime(&time);
			cur_nt = time.tv_sec * 1000000000LL + time.tv_nsec;
			SCP_ERR("get_scp_semaphore fail : %d, %lld, %lld\n", err, start_nt, cur_nt);
		} else {
			return err;
		}
	} while ((cur_nt - start_nt) < 20000000);	/* try 10 ms to get hw semaphore */

	SCP_ERR("get_scp_semaphore timeout : %d, %lld, %lld\n", err, start_nt, cur_nt);
	return err;
}

#if 0
static int SCP_sensorHub_init_client(void)
{				/* call by init done workqueue */
	struct SCP_sensorHub_data *obj = obj_data;
	SCP_SENSOR_HUB_DATA data;
	unsigned int len = 0;

	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();
	obj->mapping =
	    dma_map_single(&SCP_sensorHub_dev, (void *)obj->SCP_sensorFIFO,
			   obj->SCP_sensorFIFO->FIFOSize, DMA_BIDIRECTIONAL);
	SCP_ERR("obj->mapping = %p\n", (void *)obj->mapping);
	dma_sync_single_for_device(&SCP_sensorHub_dev, obj->mapping, obj->SCP_sensorFIFO->FIFOSize,
				   DMA_TO_DEVICE);

	data.set_config_req.sensorType = 0;
	data.set_config_req.action = SENSOR_HUB_SET_CONFIG;
	data.set_config_req.bufferBase = (int)(obj->mapping & 0xFFFFFFFF);
	SCP_ERR("data.set_config_req.bufferBase = %d\n", data.set_config_req.bufferBase);
/* SCP_ERR("obj->SCP_sensorFIFO = %p, wp = %p, rp = %p, size = %d\n", obj->SCP_sensorFIFO, */
/* obj->SCP_sensorFIFO->wp, obj->SCP_sensorFIFO->rp, obj->SCP_sensorFIFO->FIFOSize); */
	data.set_config_req.bufferSize = obj->SCP_sensorFIFO->FIFOSize;
	len = sizeof(data.set_config_req);

	SCP_sensorHub_req_send(&data, &len, 1);

	SCP_ERR("fwq SCP_sensorHub_init_client done\n");

	return SCP_SENSOR_HUB_SUCCESS;
}

#endif

static int SCP_sensorHub_init_client(void)
{				/* call by init done workqueue */
	struct SCP_sensorHub_data *obj = obj_data;
	SCP_SENSOR_HUB_DATA data;
	unsigned int len = 0;

	obj->shub_dram_phys = get_reserve_mem_phys(SENS_MEM_ID);
	obj->shub_dram_virt = get_reserve_mem_virt(SENS_MEM_ID);
	obj->shub_direct_push_dram_phys = get_reserve_mem_phys(SENS_MEM_DIRECT_ID);
	obj->shub_direct_push_dram_virt = get_reserve_mem_virt(SENS_MEM_DIRECT_ID);

	data.set_config_req.sensorType = 0;
	data.set_config_req.action = SENSOR_HUB_SET_CONFIG;
	data.set_config_req.bufferBase = (unsigned int)(obj->shub_dram_phys & 0xFFFFFFFF);
	data.set_config_req.bufferSize = get_reserve_mem_size(SENS_MEM_ID);

	data.set_config_req.directPushbufferBase =
	    (unsigned int)(obj->shub_direct_push_dram_phys & 0xFFFFFFFF);
	data.set_config_req.directPushbufferSize = SCP_DIRECT_PUSH_FIFO_SIZE;
	len = sizeof(data.set_config_req);

	SCP_sensorHub_req_send(&data, &len, 1);
	sensor_send_ap_timetamp();
	SCP_ERR("fwq SCP_sensorHub_init_client done\n");

	return SCP_SENSOR_HUB_SUCCESS;
}

static int SCP_sensorHub_extract_data(struct hwm_sensor_data *data, struct data_unit_t *data_t)
{
	int err = 0;

	switch (data_t->sensor_type) {
	case ID_ACCELEROMETER:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->accelerometer_t.x;
		data->values[1] = data_t->accelerometer_t.y;
		data->values[2] = data_t->accelerometer_t.z;
		data->values[3] = data_t->accelerometer_t.x_bias;
		data->values[4] = data_t->accelerometer_t.y_bias;
		data->values[5] = data_t->accelerometer_t.z_bias;
		data->status = (int8_t) data_t->accelerometer_t.status;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_GRAVITY:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->accelerometer_t.x;
		data->values[1] = data_t->accelerometer_t.y;
		data->values[2] = data_t->accelerometer_t.z;
		data->status = (int8_t) data_t->accelerometer_t.status;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_LINEAR_ACCELERATION:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->accelerometer_t.x;
		data->values[1] = data_t->accelerometer_t.y;
		data->values[2] = data_t->accelerometer_t.z;
		data->status = (int8_t) data_t->accelerometer_t.status;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_LIGHT:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->light;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_PROXIMITY:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->proximity_t.oneshot;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_PRESSURE:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->pressure_t.pressure;
		data->status = (int8_t) data_t->pressure_t.status;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_GYROSCOPE:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->gyroscope_t.x;
		data->values[1] = data_t->gyroscope_t.y;
		data->values[2] = data_t->gyroscope_t.z;
		data->values[3] = data_t->gyroscope_t.x_bias;
		data->values[4] = data_t->gyroscope_t.y_bias;
		data->values[5] = data_t->gyroscope_t.z_bias;
		data->status = (int8_t) data_t->gyroscope_t.status;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_GYROSCOPE_UNCALIBRATED:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->uncalibrated_gyro_t.x;
		data->values[1] = data_t->uncalibrated_gyro_t.y;
		data->values[2] = data_t->uncalibrated_gyro_t.z;
		data->values[3] = data_t->uncalibrated_gyro_t.x_bias;
		data->values[4] = data_t->uncalibrated_gyro_t.y_bias;
		data->values[5] = data_t->uncalibrated_gyro_t.z_bias;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_RELATIVE_HUMIDITY:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->relative_humidity_t.relative_humidity;
		data->status = (int8_t) data_t->relative_humidity_t.status;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_MAGNETIC:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->magnetic_t.x;
		data->values[1] = data_t->magnetic_t.y;
		data->values[2] = data_t->magnetic_t.z;
		data->values[3] = data_t->magnetic_t.x_bias;
		data->values[4] = data_t->magnetic_t.y_bias;
		data->values[5] = data_t->magnetic_t.z_bias;
		data->status = (int8_t) data_t->magnetic_t.status;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_MAGNETIC_UNCALIBRATED:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->uncalibrated_mag_t.x;
		data->values[1] = data_t->uncalibrated_mag_t.y;
		data->values[2] = data_t->uncalibrated_mag_t.z;
		data->values[3] = data_t->uncalibrated_mag_t.x_bias;
		data->values[4] = data_t->uncalibrated_mag_t.y_bias;
		data->values[5] = data_t->uncalibrated_mag_t.z_bias;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_GEOMAGNETIC_ROTATION_VECTOR:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->magnetic_t.x;
		data->values[1] = data_t->magnetic_t.y;
		data->values[2] = data_t->magnetic_t.z;
		data->values[3] = data_t->magnetic_t.scalar;
		data->status = (int8_t) data_t->magnetic_t.status;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_ORIENTATION:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->orientation_t.x;
		data->values[1] = data_t->orientation_t.y;
		data->values[2] = data_t->orientation_t.z;
		data->status = (int8_t) data_t->orientation_t.status;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_ROTATION_VECTOR:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->orientation_t.azimuth;
		data->values[1] = data_t->orientation_t.pitch;
		data->values[2] = data_t->orientation_t.roll;
		data->values[3] = data_t->orientation_t.scalar;
		data->status = (int8_t) data_t->orientation_t.status;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_GAME_ROTATION_VECTOR:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->orientation_t.azimuth;
		data->values[1] = data_t->orientation_t.pitch;
		data->values[2] = data_t->orientation_t.roll;
		data->values[3] = data_t->orientation_t.scalar;
		data->status = (int8_t) data_t->orientation_t.status;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_STEP_COUNTER:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->step_counter_t.accumulated_step_count;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_STEP_DETECTOR:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->step_detector_t.step_detect;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_TILT_DETECTOR:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->tilt_event.state;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_PEDOMETER:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->pedometer_t.accumulated_step_count;
		data->values[1] = data_t->pedometer_t.accumulated_step_length;
		data->values[2] = data_t->pedometer_t.step_frequency;
		data->values[3] = data_t->pedometer_t.step_length;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_PDR:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->pdr_event.x;
		data->values[1] = data_t->pdr_event.y;
		data->values[2] = data_t->pdr_event.z;
		data->status = (int8_t) data_t->pdr_event.status;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_SIGNIFICANT_MOTION:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->smd_t.state;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_GLANCE_GESTURE:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->gesture_data_t.probability;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_WAKE_GESTURE:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->gesture_data_t.probability;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_PICK_UP_GESTURE:
		data->sensor = data_t->sensor_type;
		data->values[0] = data_t->gesture_data_t.probability;
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_ACTIVITY:
		data->sensor = data_t->sensor_type;
		data->probability[STILL] = data_t->activity_data_t.probability[STILL];
		data->probability[STANDING] = data_t->activity_data_t.probability[STANDING];
		data->probability[SITTING] = data_t->activity_data_t.probability[SITTING];
		data->probability[LYING] = data_t->activity_data_t.probability[LYING];
		data->probability[ON_FOOT] = data_t->activity_data_t.probability[ON_FOOT];
		data->probability[WALKING] = data_t->activity_data_t.probability[WALKING];
		data->probability[RUNNING] = data_t->activity_data_t.probability[RUNNING];
		data->probability[CLIMBING] = data_t->activity_data_t.probability[CLIMBING];
		data->probability[ON_BICYCLE] = data_t->activity_data_t.probability[ON_BICYCLE];
		data->probability[IN_VEHICLE] = data_t->activity_data_t.probability[IN_VEHICLE];
		data->probability[TILTING] = data_t->activity_data_t.probability[TILTING];
		data->probability[UNKNOWN] = data_t->activity_data_t.probability[UNKNOWN];
		data->time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	default:
		err = -1;
		break;
	}
	return err;
}

static int SCP_sensorHub_ReadChipInfo(char *buf, int bufsize)
{
	if ((NULL == buf) || (bufsize <= 30))
		return -1;

	sprintf(buf, "SCP_sensorHub Chip");
	return 0;
}

static int SCP_sensorHub_ReadSensorData(int handle, struct hwm_sensor_data *sensorData)
{
	struct SCP_sensorHub_data *obj = obj_data;
	char *pStart, *pEnd, *pNext;
	struct data_unit_t curData;
	char *rp, *wp;
	int offset;
	int fifo_usage;
	int err;
	int64_t ns;
	struct timespec time;

	time.tv_sec = time.tv_nsec = 0;

	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();

	if (NULL == sensorData)
		return -1;

	err = SCP_sensorHub_get_scp_semaphore();
	if (err < 0) {
		SCP_ERR("SCP_sensorHub_get_scp_semaphore fail : %d\n", err);
		return -2;
	}

	/* dma_sync_single_for_cpu(&SCP_sensorHub_dev, obj->mapping, obj->SCP_sensorFIFO->FIFOSize,
	   DMA_FROM_DEVICE); */
	pStart = (char *)obj->SCP_sensorFIFO + offsetof(struct sensorFIFO, data);
	pEnd = pStart + obj->SCP_sensorFIFO->FIFOSize;
	rp = pStart + obj->SCP_sensorFIFO->rp;
	wp = pStart + obj->SCP_sensorFIFO->wp;

	if (rp < pStart || pEnd <= rp) {
		SCP_ERR("FIFO rp invalid : %p, %p, %p\n", pStart, pEnd, rp);
		err = release_scp_semaphore(SEMAPHORE_SENSOR);
		if (err < 0) {
			SCP_ERR("release_scp_semaphore fail : %d\n", err);
			return -3;
		}
		return -4;
	}

	if (wp < pStart || pEnd <= wp) {
		SCP_ERR("FIFO wp invalid : %p, %p, %p\n", pStart, pEnd, wp);
		err = release_scp_semaphore(SEMAPHORE_SENSOR);
		if (err < 0) {
			SCP_ERR("release_scp_semaphore fail : %d\n", err);
			return -3;
		}
		return -5;
	}

	if (rp == wp) {
		SCP_ERR("FIFO empty\n");
		err = release_scp_semaphore(SEMAPHORE_SENSOR);
		if (err < 0) {
			SCP_ERR("release_scp_semaphore fail : %d\n", err);
			return -3;
		}
		return -6;
	}
	pNext = rp + SENSOR_DATA_SIZE;

	if (SCP_TRC_BATCH_DETAIL & atomic_read(&(obj_data->trace)))
		SCP_LOG("sensor_type = %d, pNext = %p, rp = %p, wp = %p\n",
			((struct data_unit_t *)rp)->sensor_type, pNext, rp, wp);


	if (((struct data_unit_t *)rp)->sensor_type < 0
	    || ((struct data_unit_t *)rp)->sensor_type > 58) {
		SCP_ERR("Wrong data, sensor_type = %d .\n",
			((struct data_unit_t *)rp)->sensor_type);
		return -7;
	}

	if (pNext < pEnd) {
		memcpy((char *)&curData, rp, pNext - rp);
		rp = pNext;
	} else {
		memcpy(&curData, rp, pEnd - rp);
		offset = (int)(pEnd - rp);
		memcpy((char *)&curData + offset, pStart, pNext - pEnd);
		offset = (int)(pNext - pEnd);
		rp = pStart + offset;
	}

	obj->SCP_sensorFIFO->rp = (int)(rp - pStart);
	/* dma_sync_single_for_device(&SCP_sensorHub_dev,
		obj->mapping, obj->SCP_sensorFIFO->FIFOSize, DMA_TO_DEVICE); */
	err = release_scp_semaphore(SEMAPHORE_SENSOR);
	if (err < 0)
		SCP_ERR("release_scp_semaphore fail : %d\n", err);
	get_monotonic_boottime(&time);
	ns = time.tv_sec * 1000000000LL + time.tv_nsec;
	err = SCP_sensorHub_extract_data(sensorData, &curData);
	/*SCP_LOG("type:%d,now time:%lld scp time: %lld, %d, %d, %d, %d, %d, %d\n",
	   sensorData->sensor, ns, sensorData->time,
	   sensorData->values[0], sensorData->values[1], sensorData->values[2],
	   sensorData->values[3], sensorData->values[4], sensorData->values[5]); */
	if (rp <= wp)
		fifo_usage = (int)(wp - rp);
	else
		fifo_usage = obj->SCP_sensorFIFO->FIFOSize - (int)(rp - wp);

	fifo_usage = (fifo_usage * 100) / obj->SCP_sensorFIFO->FIFOSize;

	if (SCP_TRC_BATCH_DETAIL & atomic_read(&(obj_data->trace)))
		SCP_LOG("rp = %p, wp = %p, fifo_usage = %d%%\n", rp, wp, fifo_usage);

	if (fifo_usage < 50)
		atomic_set(&obj->disable_fifo_full_notify, 0);

	return 0;
}

static ssize_t show_chipinfo_value(struct device_driver *ddri, char *buf)
{
	char strbuf[SCP_SENSOR_HUB_TEMP_BUFSIZE];

	SCP_sensorHub_ReadChipInfo(strbuf, SCP_SENSOR_HUB_TEMP_BUFSIZE);
	return snprintf(buf, PAGE_SIZE, "%s\n", strbuf);
}

static ssize_t show_trace_value(struct device_driver *ddri, char *buf)
{
	ssize_t res;
	struct SCP_sensorHub_data *obj = obj_data;

	if (obj == NULL) {
		SCP_ERR("SCP_sensorHub_data obj is null!!\n");
		return 0;
	}

	res = snprintf(buf, PAGE_SIZE, "0x%04X\n", atomic_read(&obj->trace));
	return res;
}

static ssize_t store_trace_value(struct device_driver *ddri, const char *buf, size_t count)
{
	struct SCP_sensorHub_data *obj = obj_data;
	int trace;

	if (obj == NULL) {
		SCP_ERR("SCP_sensorHub_data obj is null!!\n");
		return 0;
	}

	if (1 == sscanf(buf, "0x%x", &trace))
		atomic_set(&obj->trace, trace);
	else
		SCP_ERR("invalid content: '%s', length = %d\n", buf, (int)count);

	return count;
}

static DRIVER_ATTR(chipinfo, S_IWUSR | S_IRUGO, show_chipinfo_value, NULL);
static DRIVER_ATTR(trace, S_IWUSR | S_IRUGO, show_trace_value, store_trace_value);
static struct driver_attribute *SCP_sensorHub_attr_list[] = {
	&driver_attr_chipinfo,	/*chip information */
	&driver_attr_trace,	/*trace log */
};

static int SCP_sensorHub_create_attr(struct device_driver *driver)
{
	int idx, err = 0;
	int num = (int)(sizeof(SCP_sensorHub_attr_list) / sizeof(SCP_sensorHub_attr_list[0]));

	if (driver == NULL)
		return -EINVAL;

	for (idx = 0; idx < num; idx++) {
		err = driver_create_file(driver, SCP_sensorHub_attr_list[idx]);
		if (err) {
			SCP_ERR("driver_create_file (%s) = %d\n",
				SCP_sensorHub_attr_list[idx]->attr.name, err);
			break;
		}
	}
	return err;
}

static int SCP_sensorHub_delete_attr(struct device_driver *driver)
{
	int idx, err = 0;
	int num = (int)(sizeof(SCP_sensorHub_attr_list) / sizeof(SCP_sensorHub_attr_list[0]));

	if (driver == NULL)
		return -EINVAL;

	for (idx = 0; idx < num; idx++)
		driver_remove_file(driver, SCP_sensorHub_attr_list[idx]);

	return err;
}

static int SCP_sensorHub_open(struct inode *inode, struct file *file)
{
	file->private_data = obj_data;

	if (file->private_data == NULL) {
		SCP_ERR("null pointer!!\n");
		return -EINVAL;
	}
	return nonseekable_open(inode, file);
}

static int SCP_sensorHub_release(struct inode *inode, struct file *file)
{
	file->private_data = NULL;
	return 0;
}

static long SCP_sensorHub_unlocked_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
{
	char strbuf[SCP_SENSOR_HUB_TEMP_BUFSIZE];
	void __user *data;
	long err = 0;

	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();

	if (_IOC_DIR(cmd) & _IOC_READ)
		err = !access_ok(VERIFY_WRITE, (void __user *)arg, _IOC_SIZE(cmd));
	else if (_IOC_DIR(cmd) & _IOC_WRITE)
		err = !access_ok(VERIFY_READ, (void __user *)arg, _IOC_SIZE(cmd));

	if (err) {
		SCP_ERR("access error: %08X, (%2d, %2d)\n", cmd, _IOC_DIR(cmd), _IOC_SIZE(cmd));
		return -EFAULT;
	}

	switch (cmd) {
	case GSENSOR_IOCTL_INIT:
		SCP_sensorHub_init_client();
		break;

	case GSENSOR_IOCTL_READ_CHIPINFO:
		data = (void __user *)arg;
		if (data == NULL) {
			err = -EINVAL;
			break;
		}

		SCP_sensorHub_ReadChipInfo(strbuf, SCP_SENSOR_HUB_TEMP_BUFSIZE);
		if (copy_to_user(data, strbuf, strlen(strbuf) + 1)) {
			err = -EFAULT;
			break;
		}
		break;

	case GSENSOR_IOCTL_READ_SENSORDATA:
		err = -EINVAL;
		break;

	case GSENSOR_IOCTL_READ_GAIN:
		err = -EINVAL;
		break;

	case GSENSOR_IOCTL_READ_RAW_DATA:
		err = -EFAULT;
		break;

	case GSENSOR_IOCTL_SET_CALI:
		err = -EINVAL;
		break;

	case GSENSOR_IOCTL_CLR_CALI:
		err = -EINVAL;
		break;

	case GSENSOR_IOCTL_GET_CALI:
		err = -EINVAL;
		break;


	default:
		SCP_ERR("unknown IOCTL: 0x%08x\n", cmd);
		err = -ENOIOCTLCMD;
		break;

	}

	return err;
}


static const struct file_operations SCP_sensorHub_fops = {
	/* .owner = THIS_MODULE, */
	.open = SCP_sensorHub_open,
	.release = SCP_sensorHub_release,
	.unlocked_ioctl = SCP_sensorHub_unlocked_ioctl,
};

static struct miscdevice SCP_sensorHub_device = {
	.minor = MISC_DYNAMIC_MINOR,
	.name = "SCP_sensorHub",
	.fops = &SCP_sensorHub_fops,
};

static unsigned long long t1, t2, t3, t4, t5, t6;
int SCP_sensorHub_req_send(SCP_SENSOR_HUB_DATA_P data, uint *len, unsigned int wait)
{
	ipi_status status;
	int err = 0;
	int retry = 0;

	if (SCP_TRC_IPI & atomic_read(&(obj_data->trace)))
		SCP_ERR("len = %d, type = %d, action = %d\n", *len, data->req.sensorType,
			data->req.action);

	if (*len > 48) {
		SCP_ERR("!!\n");
		return -1;
	}

	if (in_interrupt()) {
		SCP_ERR("Can't do %s in interrupt context!!\n", __func__);
		return -1;
	}

	if (ID_SENSOR_MAX_HANDLE < data->rsp.sensorType) {
		SCP_ERR("SCP_sensorHub_IPI_handler invalid sensor type %d\n", data->rsp.sensorType);
		return -1;
	}
	mutex_lock(&SCP_sensorHub_req_mutex);

	userData = data;
	userDataLen = len;

	switch (data->req.action) {
	case SENSOR_HUB_ACTIVATE:
		break;
	case SENSOR_HUB_SET_DELAY:
		break;
	case SENSOR_HUB_GET_DATA:
		break;
	case SENSOR_HUB_BATCH:
		break;
	case SENSOR_HUB_SET_CONFIG:
		break;
	case SENSOR_HUB_SET_TIMESTAMP:
		break;
	case SENSOR_HUB_MASK_NOTIFY:
		break;
	case SENSOR_HUB_BATCH_TIMEOUT:
		break;
	case SENSOR_HUB_SET_CUST:
		break;
	default:
		break;
	}

	if (1 == wait) {
		if (atomic_read(&(obj_data->wait_rsp)) == 1)
			SCP_ERR("SCP_sensorHub_req_send reentry\n");
		atomic_set(&(obj_data->wait_rsp), 1);
	}
	mod_timer(&obj_data->timer, jiffies + 500 * HZ / 1000);

	do {
		status = scp_ipi_send(IPI_SENSOR, data, *len, 0);
		if (ERROR == status) {
			SCP_ERR("scp_ipi_send ERROR\n");
			goto SCP_FAIL;
		}
		if (BUSY == status) {
			if (retry++ == 1000)
				goto SCP_FAIL;
			if (retry % 100 == 0) {
				SCP_ERR("scp_ipi_send retry time is %d\n", retry);
				udelay(10);
			}
		}
	} while (BUSY == status);
	if (SCP_TRC_IPI & atomic_read(&(obj_data->trace)))
		SCP_ERR("scp_ipi_send DONE\n");
	wait_event(SCP_sensorHub_req_wq, (atomic_read(&(obj_data->wait_rsp)) == 0));
	del_timer_sync(&obj_data->timer);
	atomic_set(&(obj_data->wait_rsp), 0);
	err = userData->rsp.errCode;
/*
	if (t6 - t1 > 3000000LL)
		SCP_ERR("%llu, %llu, %llu, %llu, %llu, %llu\n", t1, t2, t3, t4, t5, t6);
	*/
	mutex_unlock(&SCP_sensorHub_req_mutex);

	if (SCP_TRC_IPI & atomic_read(&(obj_data->trace)))
		SCP_ERR("SCP_sensorHub_req_send end\n");
	return err;

SCP_FAIL:
	del_timer_sync(&obj_data->timer);
	mutex_unlock(&SCP_sensorHub_req_mutex);
	atomic_set(&(obj_data->wait_rsp), 0);
	return -1;
}

int SCP_sensorHub_rsp_registration(uint8_t sensor, SCP_sensorHub_handler handler)
{
	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();

	if (ID_SENSOR_MAX_HANDLE < sensor)
		SCP_ERR("SCP_sensorHub_rsp_registration invalid sensor %d\n", sensor);

	if (NULL == handler)
		SCP_ERR("SCP_sensorHub_rsp_registration null handler\n");

	sensor_handler[sensor] = handler;

	return 0;
}

static void SCP_power_notify_work(struct work_struct *work)
{
	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();
	scp_sensorHub_power_adjust();
}

static void sensor_client_read_ringbuffer_data(int handle)
{
	struct SCP_sensorHub_data *obj = obj_data;
	unsigned int head = 0, tail = 0;

	clean_up_deactivate_ringbuffer(handle);
	while (1) {
		spin_lock(&obj->client[handle].buffer_lock);
		head = obj->client[handle].head;
		tail = obj->client[handle].tail;
		spin_unlock(&obj->client[handle].buffer_lock);
		if (tail == head)
			break;
		for (; tail != head;) {
			SCP_sensorHub_report_data(&obj->client[handle].ringbuffer[tail]);
			tail++;
			tail &= obj->client[handle].bufsize - 1;
			obj->client[handle].tail++;
			obj->client[handle].tail &= obj->client[handle].bufsize - 1;
		}
	}
}

static void sensor_server_write_ringbuffer_data(struct data_unit_t *event, int handle)
{
	struct SCP_sensorHub_data *obj = obj_data;
	struct sensor_client *client = obj->client;

	switch (handle) {
	case ID_ACCELEROMETER:
	case ID_MAGNETIC:
	case ID_MAGNETIC_UNCALIBRATED:
	case ID_GYROSCOPE:
	case ID_GYROSCOPE_UNCALIBRATED:
	case ID_ORIENTATION:
	case ID_ROTATION_VECTOR:
	case ID_GAME_ROTATION_VECTOR:
	case ID_GEOMAGNETIC_ROTATION_VECTOR:
	case ID_GRAVITY:
	case ID_LINEAR_ACCELERATION:
	case ID_PEDOMETER:
	case ID_ACTIVITY:
		spin_lock(&client[handle].buffer_lock);
		client[handle].ringbuffer[client[handle].head++] = *event;
		client[handle].head &= client[handle].bufsize - 1;
		if (unlikely(client[handle].head == client[handle].tail))
			SCP_ERR("handle(%d) dropped data due to ringbuffer is full\n", handle);
		spin_unlock(&client[handle].buffer_lock);
		break;
	default:
		break;
	}
}

static void accelerometer_report_data_work(struct work_struct *work)
{
	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();
	sensor_client_read_ringbuffer_data(ID_ACCELEROMETER);
}

static void magnetic_report_data_work(struct work_struct *work)
{
	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();
	sensor_client_read_ringbuffer_data(ID_MAGNETIC);
}

static void unmagnetic_report_data_work(struct work_struct *work)
{
	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();
	sensor_client_read_ringbuffer_data(ID_MAGNETIC_UNCALIBRATED);
}

static void gyroscope_report_data_work(struct work_struct *work)
{
	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();
	sensor_client_read_ringbuffer_data(ID_GYROSCOPE);
}

static void ungyroscope_report_data_work(struct work_struct *work)
{
	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();
	sensor_client_read_ringbuffer_data(ID_GYROSCOPE_UNCALIBRATED);
}

static void orientation_report_data_work(struct work_struct *work)
{
	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();
	sensor_client_read_ringbuffer_data(ID_ORIENTATION);
}

static void rotvec_report_data_work(struct work_struct *work)
{
	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();
	sensor_client_read_ringbuffer_data(ID_ROTATION_VECTOR);
}

static void gamerotvec_report_data_work(struct work_struct *work)
{
	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();
	sensor_client_read_ringbuffer_data(ID_GAME_ROTATION_VECTOR);
}

static void geomagnetic_report_data_work(struct work_struct *work)
{
	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();
	sensor_client_read_ringbuffer_data(ID_GEOMAGNETIC_ROTATION_VECTOR);
}

static void gravity_report_data_work(struct work_struct *work)
{
	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();
	sensor_client_read_ringbuffer_data(ID_GRAVITY);
}

static void linearaccel_report_data_work(struct work_struct *work)
{
	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();
	sensor_client_read_ringbuffer_data(ID_LINEAR_ACCELERATION);
}

static void pedometer_report_data_work(struct work_struct *work)
{
	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();
	sensor_client_read_ringbuffer_data(ID_PEDOMETER);
}

static void activity_report_data_work(struct work_struct *work)
{
	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();
	sensor_client_read_ringbuffer_data(ID_ACTIVITY);
}

static void SCP_ipi_work(struct work_struct *work)
{
	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();

	SCP_sensorHub_init_client();
}

static void SCP_fifo_full_work(struct work_struct *work)
{
	if (SCP_TRC_FUN & atomic_read(&(obj_data->trace)))
		SCP_FUN();

	mutex_lock(&SCP_sensorHub_report_data_mutex);
	SCP_sensorHub_server_dispatch_data();
	mutex_unlock(&SCP_sensorHub_report_data_mutex);
}

static void SCP_batch_timeout_work(struct work_struct *work)
{
	if (SCP_TRC_FUN & atomic_read(&(obj_data->trace)))
		SCP_FUN();

	mutex_lock(&SCP_sensorHub_report_data_mutex);
	SCP_sensorHub_server_dispatch_data();
	mutex_unlock(&SCP_sensorHub_report_data_mutex);
}

static void SCP_direct_push_work(struct work_struct *work)
{
	if (SCP_TRC_FUN & atomic_read(&(obj_data->trace)))
		SCP_FUN();

	mutex_lock(&SCP_sensorHub_report_data_mutex);
	SCP_sensorHub_server_dispatch_data();
	mutex_unlock(&SCP_sensorHub_report_data_mutex);
}

static void SCP_sensorHub_req_send_timeout(unsigned long data)
{
	if (atomic_read(&(obj_data->wait_rsp)) == 1) {
		if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
			SCP_FUN();

		if (NULL != userData && NULL != userDataLen) {
			userData->rsp.errCode = -1;
			*userDataLen = sizeof(userData->rsp);
		}
		SCP_ERR("SCP_sensorHub_req_send_timeout\n");
		atomic_set(&(obj_data->wait_rsp), 0);
		wake_up(&SCP_sensorHub_req_wq);
	}
}

static void SCP_sensorHub_IPI_handler(int id, void *data, unsigned int len)
{
	struct SCP_sensorHub_data *obj = obj_data;
	SCP_SENSOR_HUB_DATA_P rsp = (SCP_SENSOR_HUB_DATA_P) data;
	bool wake_up_req = false;
	bool do_registed_handler = false;
	static int first_init_done;

	t1 = SCP_sensorHub_GetCurNS();

	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();

	if (SCP_TRC_IPI & atomic_read(&(obj_data->trace)))
		SCP_ERR("len = %d, type = %d, action = %d, errCode = %d\n", len,
			rsp->rsp.sensorType, rsp->rsp.action, rsp->rsp.errCode);

	if (len > 48) {
		SCP_ERR("SCP_sensorHub_IPI_handler len=%d error\n", len);
		return;
	}
	switch (rsp->rsp.action) {
	case SENSOR_HUB_ACTIVATE:
	case SENSOR_HUB_SET_DELAY:
	case SENSOR_HUB_GET_DATA:
	case SENSOR_HUB_BATCH:
	case SENSOR_HUB_SET_CONFIG:
	case SENSOR_HUB_SET_CUST:
	case SENSOR_HUB_BATCH_TIMEOUT:
	case SENSOR_HUB_SET_TIMESTAMP:
	case SENSOR_HUB_MASK_NOTIFY:
		wake_up_req = true;
		break;
	case SENSOR_HUB_NOTIFY:
		switch (rsp->notify_rsp.event) {
		case SCP_INIT_DONE:
			if (0 == first_init_done) {
				schedule_work(&obj->ipi_work);
				first_init_done = 1;
			}
			do_registed_handler = true;
			break;
		case SCP_FIFO_FULL:
			schedule_work(&obj->fifo_full_work);
			break;
		case SCP_BATCH_TIMEOUT:
			schedule_work(&obj->batch_timeout_work);
			break;
		case SCP_DIRECT_PUSH:
			schedule_work(&obj->direct_push_work);
			break;
		case SCP_NOTIFY:
			do_registed_handler = true;
			break;
		default:
			break;
		}
		break;
	case SENSOR_HUB_POWER_NOTIFY:
		schedule_work(&obj->power_notify_work);
		break;
	default:
		SCP_ERR("SCP_sensorHub_IPI_handler unknown action=%d error\n", rsp->rsp.action);
		return;
	}

	t2 = SCP_sensorHub_GetCurNS();

	if (ID_SENSOR_MAX_HANDLE < rsp->rsp.sensorType) {
		if (rsp->rsp.sensorType != ID_SCP_MAX_SENSOR_TYPE) {
			SCP_ERR("SCP_sensorHub_IPI_handler invalid sensor type %d\n",
				rsp->rsp.sensorType);
			return;
		}
	} else if (true == do_registed_handler) {
		if (NULL != sensor_handler[rsp->rsp.sensorType])
			sensor_handler[rsp->rsp.sensorType] (data, len);
		if (rsp->rsp.sensorType == ID_TILT_DETECTOR)
			sensor_handler[ID_WAKE_GESTURE] (data, len);
	}

	t3 = SCP_sensorHub_GetCurNS();

	if (atomic_read(&(obj_data->wait_rsp)) == 1 && true == wake_up_req) {
		if (NULL == userData || NULL == userDataLen) {
			SCP_ERR("SCP_sensorHub_IPI_handler null pointer\n");
		} else {
			if (userData->req.sensorType != rsp->rsp.sensorType)
				SCP_ERR("SCP_sensorHub_IPI_handler sensor type %d != %d\n",
					userData->req.sensorType, rsp->rsp.sensorType);
			if (userData->req.action != rsp->rsp.action)
				SCP_ERR("SCP_sensorHub_IPI_handler action %d != %d\n",
					userData->req.action, rsp->rsp.action);
			memcpy(userData, rsp, len);
			*userDataLen = len;
		}
		t4 = SCP_sensorHub_GetCurNS();
		atomic_set(&(obj_data->wait_rsp), 0);
		t5 = SCP_sensorHub_GetCurNS();
		wake_up(&SCP_sensorHub_req_wq);
		t6 = SCP_sensorHub_GetCurNS();
	}

}

int SCP_sensorHub_enable_hw_batch(int handle, int enable, int flag, long long samplingPeriodNs,
				  long long maxBatchReportLatencyNs)
{
	SCP_SENSOR_HUB_DATA req;
	int len;
	int err = 0;

	if (samplingPeriodNs == 0)
		return 0;
	if (SCP_TRC_FUN & atomic_read(&(obj_data->trace)))
		SCP_FUN();

	do_div(maxBatchReportLatencyNs, 1000000);
	do_div(samplingPeriodNs, 1000000);
	req.batch_req.sensorType = handle;
	req.batch_req.action = SENSOR_HUB_BATCH;
	req.batch_req.flag = flag;
	req.batch_req.period_ms = (unsigned int)samplingPeriodNs;
	req.batch_req.timeout_ms = (enable == 0) ? 0 : (unsigned int)maxBatchReportLatencyNs;
	if (SCP_TRC_BATCH & atomic_read(&(obj_data->trace))) {
		SCP_ERR("handle = %d, flag = %d, period_ms = %d, timeout_ms = %d!\n",
			req.batch_req.sensorType, req.batch_req.flag, req.batch_req.period_ms,
			req.batch_req.timeout_ms);
	}
	len = sizeof(req.batch_req);
	err = SCP_sensorHub_req_send(&req, &len, 1);
	if (err)
		SCP_ERR("SCP_sensorHub_req_send fail!\n");

	return err;
}

static int SCP_sensorHub_flush(int handle)
{
	return 0;
}

static int SCP_sensorHub_get_data(int handle, struct hwm_sensor_data *sensorData)
{
	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();

	return SCP_sensorHub_ReadSensorData(handle, sensorData);
}

static int SCP_sensorHub_batch_timeout(int handle, int cmd)
{
	SCP_SENSOR_HUB_DATA req;
	int len;
	int err = 0;

	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();

	req.get_data_req.sensorType = handle;
	req.get_data_req.action = SENSOR_HUB_BATCH_TIMEOUT;
	req.get_data_req.reserve[0] = (uint8_t) cmd;
	len = sizeof(req.get_data_req);

	err = SCP_sensorHub_req_send(&req, &len, 1);
	return err;
}

static int SCP_sensorHub_report_data(struct data_unit_t *data_t)
{
	struct SCP_sensorHub_data *obj = obj_data;
	int err = 0;
	int value[6] = { 0 };
	struct hwm_sensor_data data;
	int64_t timestamp_ms = 0;
	static int64_t last_timestamp_ms_acc = 0, last_enter_timestamp_acc;
	static int64_t last_timestamp_ms_gravity = 0, last_enter_timestamp_gravity;
	static int64_t last_timestamp_ms_linearaccel = 0, last_enter_timestamp_linearaccel;
	static int64_t last_timestamp_ms_gyro = 0, last_enter_timestamp_gyro;
	static int64_t last_timestamp_ms_gyro_uncali = 0, last_enter_timestamp_gyro_uncali;
	static int64_t last_timestamp_ms_mag = 0, last_enter_timestamp_mag;
	static int64_t last_timestamp_ms_mag_uncali = 0, last_enter_timestamp_mag_uncali;
	static int64_t last_timestamp_ms_grv = 0, last_enter_timestamp_grv;
	static int64_t last_timestamp_ms_gmrv = 0, last_enter_timestamp_gmrv;
	static int64_t last_timestamp_ms_orientation = 0, last_enter_timestamp_orientation;
	static int64_t last_timestamp_ms_rv = 0, last_enter_timestamp_rv;
	static int64_t last_timestamp_ms_pedo = 0, last_enter_timestamp_pedo;
	static int64_t last_timestamp_ms_act = 0, last_enter_timestamp_act;

	int64_t now_enter_timestamp;
	struct timespec time;

	time.tv_sec = time.tv_nsec = 0;
	get_monotonic_boottime(&time);
	now_enter_timestamp = time.tv_sec * 1000000000LL + time.tv_nsec;

	timestamp_ms = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt) / 1000000;
	switch (data_t->sensor_type) {
	case ID_ACCELEROMETER:
#ifdef CONFIG_CUSTOM_KERNEL_ACCELEROMETER
		if ((now_enter_timestamp - last_enter_timestamp_acc) > 10000000)
			atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
		last_enter_timestamp_acc = now_enter_timestamp;
		if (last_timestamp_ms_acc != timestamp_ms) {
			last_timestamp_ms_acc = timestamp_ms;
			acc_data_report(data_t->accelerometer_t.x, data_t->accelerometer_t.y,
					data_t->accelerometer_t.z, data_t->accelerometer_t.status,
					(int64_t) (data_t->time_stamp + data_t->time_stamp_gpt));
			atomic_inc(&obj->client[data_t->sensor_type].delay_count);
			if (atomic_read(&obj->client[data_t->sensor_type].delay_count) ==
			    DELAY_COUNT) {
				/* SCP_ERR("handle(%d) sleep 10ms\n", data_t->sensor_type); */
				atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
				msleep(20);
			}
		}
#endif
		break;
	case ID_GRAVITY:
#ifdef CONFIG_CUSTOM_KERNEL_GRAVITY_SENSOR
		if ((now_enter_timestamp - last_enter_timestamp_gravity) > 10000000)
			atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
		last_enter_timestamp_gravity = now_enter_timestamp;
		if (last_timestamp_ms_gravity != timestamp_ms) {
			last_timestamp_ms_gravity = timestamp_ms;
			grav_data_report(data_t->accelerometer_t.x, data_t->accelerometer_t.y,
					 data_t->accelerometer_t.z, data_t->accelerometer_t.status,
					 (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt));
			atomic_inc(&obj->client[data_t->sensor_type].delay_count);
			if (atomic_read(&obj->client[data_t->sensor_type].delay_count) ==
			    DELAY_COUNT) {
				atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
				msleep(20);
			}
		}
#endif
		break;
	case ID_LINEAR_ACCELERATION:
#ifdef CONFIG_CUSTOM_KERNEL_LINEARACCEL_SENSOR
		if ((now_enter_timestamp - last_enter_timestamp_linearaccel) > 10000000)
			atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
		last_enter_timestamp_linearaccel = now_enter_timestamp;
		if (last_timestamp_ms_linearaccel != timestamp_ms) {
			last_timestamp_ms_linearaccel = timestamp_ms;
			la_data_report(data_t->accelerometer_t.x, data_t->accelerometer_t.y,
				       data_t->accelerometer_t.z, data_t->accelerometer_t.status,
				       (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt));
			atomic_inc(&obj->client[data_t->sensor_type].delay_count);
			if (atomic_read(&obj->client[data_t->sensor_type].delay_count) ==
			    DELAY_COUNT) {
				atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
				msleep(20);
			}
		}
#endif
		break;
	case ID_LIGHT:
		break;
	case ID_PRESSURE:
		break;
	case ID_GYROSCOPE:
#ifdef CONFIG_CUSTOM_KERNEL_GYROSCOPE
		if ((now_enter_timestamp - last_enter_timestamp_gyro) > 10000000)
			atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
		last_enter_timestamp_gyro = now_enter_timestamp;
		if (last_timestamp_ms_gyro != timestamp_ms) {
			last_timestamp_ms_gyro = timestamp_ms;
			gyro_data_report(data_t->gyroscope_t.x, data_t->gyroscope_t.y,
					 data_t->gyroscope_t.z, data_t->gyroscope_t.status,
					 (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt));
			atomic_inc(&obj->client[data_t->sensor_type].delay_count);
			if (atomic_read(&obj->client[data_t->sensor_type].delay_count) ==
			    DELAY_COUNT) {
				atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
				msleep(20);
			}
		}
#endif
		break;
	case ID_GYROSCOPE_UNCALIBRATED:
		value[0] = data_t->uncalibrated_gyro_t.x;
		value[1] = data_t->uncalibrated_gyro_t.y;
		value[2] = data_t->uncalibrated_gyro_t.z;
		value[3] = data_t->uncalibrated_gyro_t.x_bias;
		value[4] = data_t->uncalibrated_gyro_t.y_bias;
		value[5] = data_t->uncalibrated_gyro_t.z_bias;
#ifdef CONFIG_CUSTOM_KERNEL_UNCALI_GYRO_SENSOR
		if ((now_enter_timestamp - last_enter_timestamp_gyro_uncali) > 10000000)
			atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
		last_enter_timestamp_gyro_uncali = now_enter_timestamp;
		if (last_timestamp_ms_gyro_uncali != timestamp_ms) {
			last_timestamp_ms_gyro_uncali = timestamp_ms;
			uncali_gyro_data_report(value, data_t->uncalibrated_gyro_t.status,
						(int64_t) (data_t->time_stamp +
							   data_t->time_stamp_gpt));
			atomic_inc(&obj->client[data_t->sensor_type].delay_count);
			if (atomic_read(&obj->client[data_t->sensor_type].delay_count) ==
			    DELAY_COUNT / 2) {
				atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
				msleep(20);
			}
		}
#endif
		break;
	case ID_RELATIVE_HUMIDITY:
		break;
	case ID_MAGNETIC:
#ifdef CONFIG_CUSTOM_KERNEL_MAGNETOMETER
		if ((now_enter_timestamp - last_enter_timestamp_mag) > 10000000)
			atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
		last_enter_timestamp_mag = now_enter_timestamp;
		if (last_timestamp_ms_mag != timestamp_ms) {
			last_timestamp_ms_mag = timestamp_ms;
			magnetic_data_report(data_t->magnetic_t.x, data_t->magnetic_t.y,
					     data_t->magnetic_t.z, data_t->magnetic_t.status,
					     (int64_t) (data_t->time_stamp +
							data_t->time_stamp_gpt));
			atomic_inc(&obj->client[data_t->sensor_type].delay_count);
			if (atomic_read(&obj->client[data_t->sensor_type].delay_count) ==
			    DELAY_COUNT) {
				atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
				msleep(20);
			}
		}
#endif
		break;
	case ID_MAGNETIC_UNCALIBRATED:
		value[0] = data_t->uncalibrated_mag_t.x;
		value[1] = data_t->uncalibrated_mag_t.y;
		value[2] = data_t->uncalibrated_mag_t.z;
		value[3] = data_t->uncalibrated_mag_t.x_bias;
		value[4] = data_t->uncalibrated_mag_t.y_bias;
		value[5] = data_t->uncalibrated_mag_t.z_bias;
#ifdef CONFIG_CUSTOM_KERNEL_UNCALI_MAG_SENSOR
		if ((now_enter_timestamp - last_enter_timestamp_mag_uncali) > 10000000)
			atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
		last_enter_timestamp_mag_uncali = now_enter_timestamp;
		if (last_timestamp_ms_mag_uncali != timestamp_ms) {
			last_timestamp_ms_mag_uncali = timestamp_ms;
			uncali_mag_data_report(value, data_t->uncalibrated_mag_t.status,
					       (int64_t) (data_t->time_stamp +
							  data_t->time_stamp_gpt));
			atomic_inc(&obj->client[data_t->sensor_type].delay_count);
			if (atomic_read(&obj->client[data_t->sensor_type].delay_count) ==
			    DELAY_COUNT / 2) {
				atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
				msleep(20);
			}
		}
#endif
		break;
	case ID_GEOMAGNETIC_ROTATION_VECTOR:
#ifdef CONFIG_CUSTOM_KERNEL_GMRV_SENSOR
		if ((now_enter_timestamp - last_enter_timestamp_gmrv) > 10000000)
			atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
		last_enter_timestamp_gmrv = now_enter_timestamp;
		if (last_timestamp_ms_gmrv != timestamp_ms) {
			last_timestamp_ms_gmrv = timestamp_ms;
			gmrv_data_report(data_t->magnetic_t.x, data_t->magnetic_t.y,
					 data_t->magnetic_t.z, data_t->magnetic_t.scalar,
					 data_t->magnetic_t.status,
					 (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt));
			atomic_inc(&obj->client[data_t->sensor_type].delay_count);
			if (atomic_read(&obj->client[data_t->sensor_type].delay_count) ==
			    DELAY_COUNT) {
				atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
				msleep(20);
			}
		}
#endif
		break;
	case ID_ORIENTATION:
#ifdef CONFIG_CUSTOM_KERNEL_MAGNETOMETER
		if ((now_enter_timestamp - last_enter_timestamp_orientation) > 10000000)
			atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
		last_enter_timestamp_orientation = now_enter_timestamp;
		if (last_timestamp_ms_orientation != timestamp_ms) {
			last_timestamp_ms_orientation = timestamp_ms;
			orientation_data_report(data_t->orientation_t.azimuth,
						data_t->orientation_t.pitch,
						data_t->orientation_t.roll,
						data_t->orientation_t.status,
						(int64_t) (data_t->time_stamp +
							   data_t->time_stamp_gpt));
			atomic_inc(&obj->client[data_t->sensor_type].delay_count);
			if (atomic_read(&obj->client[data_t->sensor_type].delay_count) ==
			    DELAY_COUNT) {
				atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
				msleep(20);
			}
		}
#endif
		break;
	case ID_ROTATION_VECTOR:
#ifdef CONFIG_CUSTOM_KERNEL_RV_SENSOR
		if ((now_enter_timestamp - last_enter_timestamp_rv) > 10000000)
			atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
		last_enter_timestamp_rv = now_enter_timestamp;
		if (last_timestamp_ms_rv != timestamp_ms) {
			last_timestamp_ms_rv = timestamp_ms;
			rotationvector_data_report(data_t->orientation_t.azimuth,
						   data_t->orientation_t.pitch,
						   data_t->orientation_t.roll,
						   data_t->orientation_t.scalar,
						   data_t->orientation_t.status,
						   (int64_t) (data_t->time_stamp +
							      data_t->time_stamp_gpt));
			atomic_inc(&obj->client[data_t->sensor_type].delay_count);
			if (atomic_read(&obj->client[data_t->sensor_type].delay_count) ==
			    DELAY_COUNT) {
				atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
				msleep(20);
			}
		}
#endif
		break;
	case ID_GAME_ROTATION_VECTOR:
#ifdef CONFIG_CUSTOM_KERNEL_GRV_SENSOR
		if ((now_enter_timestamp - last_enter_timestamp_grv) > 10000000)
			atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
		last_enter_timestamp_grv = now_enter_timestamp;
		if (last_timestamp_ms_grv != timestamp_ms) {
			last_timestamp_ms_grv = timestamp_ms;
			grv_data_report(data_t->orientation_t.azimuth, data_t->orientation_t.pitch,
					data_t->orientation_t.roll, data_t->orientation_t.scalar,
					data_t->orientation_t.status,
					(int64_t) (data_t->time_stamp + data_t->time_stamp_gpt));
			atomic_inc(&obj->client[data_t->sensor_type].delay_count);
			if (atomic_read(&obj->client[data_t->sensor_type].delay_count) ==
			    DELAY_COUNT) {
				atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
				msleep(20);
			}
		}
#endif
		break;
	case ID_STEP_COUNTER:
		data.sensor = data_t->sensor_type;
		data.values[0] = data_t->step_counter_t.accumulated_step_count;
		data.time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_STEP_DETECTOR:
		data.sensor = data_t->sensor_type;
		data.values[0] = data_t->step_detector_t.step_detect;
		data.time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_TILT_DETECTOR:
		data.sensor = data_t->sensor_type;
		data.values[0] = data_t->tilt_event.state;
		data.time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_PEDOMETER:
		data.sensor = data_t->sensor_type;
		data.values[0] = data_t->pedometer_t.accumulated_step_count;
		data.values[1] = data_t->pedometer_t.accumulated_step_length;
		data.values[2] = data_t->pedometer_t.step_frequency;
		data.values[3] = data_t->pedometer_t.step_length;
		data.time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
#ifdef CONFIG_CUSTOM_KERNEL_PEDOMETER
		if ((now_enter_timestamp - last_enter_timestamp_pedo) > 10000000)
			atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
		last_enter_timestamp_pedo = now_enter_timestamp;
		if (last_timestamp_ms_pedo != timestamp_ms) {
			last_timestamp_ms_pedo = timestamp_ms;
			pedo_data_report(&data, 2);
			atomic_inc(&obj->client[data_t->sensor_type].delay_count);
			if (atomic_read(&obj->client[data_t->sensor_type].delay_count) ==
			    DELAY_COUNT) {
				atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
				msleep(20);
			}
		}
#endif
		break;
	case ID_PDR:
		data.sensor = data_t->sensor_type;
		data.values[0] = data_t->pdr_event.x;
		data.values[1] = data_t->pdr_event.y;
		data.values[2] = data_t->pdr_event.z;
		data.status = (int8_t) data_t->pdr_event.status;
		data.time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
		break;
	case ID_ACTIVITY:
		data.sensor = data_t->sensor_type;
		data.probability[STILL] = data_t->activity_data_t.probability[STILL];
		data.probability[STANDING] = data_t->activity_data_t.probability[STANDING];
		data.probability[SITTING] = data_t->activity_data_t.probability[SITTING];
		data.probability[LYING] = data_t->activity_data_t.probability[LYING];
		data.probability[ON_FOOT] = data_t->activity_data_t.probability[ON_FOOT];
		data.probability[WALKING] = data_t->activity_data_t.probability[WALKING];
		data.probability[RUNNING] = data_t->activity_data_t.probability[RUNNING];
		data.probability[CLIMBING] = data_t->activity_data_t.probability[CLIMBING];
		data.probability[ON_BICYCLE] = data_t->activity_data_t.probability[ON_BICYCLE];
		data.probability[IN_VEHICLE] = data_t->activity_data_t.probability[IN_VEHICLE];
		data.probability[TILTING] = data_t->activity_data_t.probability[TILTING];
		data.probability[UNKNOWN] = data_t->activity_data_t.probability[UNKNOWN];
		data.time = (int64_t) (data_t->time_stamp + data_t->time_stamp_gpt);
#ifdef CONFIG_CUSTOM_KERNEL_ACTIVITY_SENSOR
		if ((now_enter_timestamp - last_enter_timestamp_act) > 10000000)
			atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
		last_enter_timestamp_act = now_enter_timestamp;
		if (last_timestamp_ms_act != timestamp_ms) {
			last_timestamp_ms_act = timestamp_ms;
			act_data_report(&data, 2);
			atomic_inc(&obj->client[data_t->sensor_type].delay_count);
			if (atomic_read(&obj->client[data_t->sensor_type].delay_count) ==
			    DELAY_COUNT / 2) {
				atomic_set(&obj->client[data_t->sensor_type].delay_count, 0);
				msleep(20);
			}
		}
#endif
		break;
	default:
		err = -1;
		break;
	}
	return err;

}

static void clean_up_deactivate_ringbuffer(int handle)
{
	struct SCP_sensorHub_data *obj = obj_data;
	struct sensor_client *client = obj->client;

	if (test_bit(handle, &obj->flush_remain_data_after_disable) != 0) {
		clear_bit(handle, &obj->flush_remain_data_after_disable);
		switch (handle) {
		case ID_ACCELEROMETER:
		case ID_MAGNETIC:
		case ID_MAGNETIC_UNCALIBRATED:
		case ID_GYROSCOPE:
		case ID_GYROSCOPE_UNCALIBRATED:
		case ID_ORIENTATION:
		case ID_ROTATION_VECTOR:
		case ID_GAME_ROTATION_VECTOR:
		case ID_GEOMAGNETIC_ROTATION_VECTOR:
		case ID_GRAVITY:
		case ID_LINEAR_ACCELERATION:
		case ID_PEDOMETER:
		case ID_ACTIVITY:
			spin_lock(&client[handle].buffer_lock);
			client[handle].head = 0;
			client[handle].tail = 0;
			spin_unlock(&client[handle].buffer_lock);
			break;
		default:
			break;
		}
	}
}

static void wake_up_activate_thread(void)
{
	struct SCP_sensorHub_data *obj = obj_data;
	int handle = 0;
	struct sensor_client *client = obj->client;

	for (handle = ID_ACCELEROMETER; handle < ID_SENSOR_MAX_HANDLE; ++handle) {
		if (test_bit(handle, &obj->sensor_activate_bitmap) != 0 ||
		    test_bit(handle, &obj->flush_remain_data_after_disable) != 0) {
			switch (handle) {
			case ID_ACCELEROMETER:
			case ID_MAGNETIC:
			case ID_MAGNETIC_UNCALIBRATED:
			case ID_GYROSCOPE:
			case ID_GYROSCOPE_UNCALIBRATED:
			case ID_ORIENTATION:
			case ID_ROTATION_VECTOR:
			case ID_GAME_ROTATION_VECTOR:
			case ID_GEOMAGNETIC_ROTATION_VECTOR:
			case ID_GRAVITY:
			case ID_LINEAR_ACCELERATION:
			case ID_PEDOMETER:
			case ID_ACTIVITY:
				queue_work(client[handle].single_thread, &client[handle].worker);
				break;
			default:
				break;
			}
		}
	}
}

static int SCP_sensorHub_server_dispatch_data(void)
{
	struct SCP_sensorHub_data *obj = obj_data;
	char *pStart, *pEnd, *rp, *wp;
	struct data_unit_t *event;
	int err = 0, handle = 0;

	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();

	wake_up_activate_thread();
	/* To prevent get fifo status during scp wrapper around dram fifo. */
	err = SCP_sensorHub_get_scp_semaphore();
	if (err < 0) {
		SCP_ERR("SCP_sensorHub_get_scp_semaphore fail : %d\n", err);
		return -2;
	}

	pStart = (char *)obj->SCP_sensorFIFO + offsetof(struct sensorFIFO, data);
	pEnd = pStart + obj->SCP_sensorFIFO->FIFOSize;

	rp = pStart + obj->SCP_sensorFIFO->rp;
	wp = pStart + obj->SCP_sensorFIFO->wp;


	if (wp < pStart || pEnd < wp) {
		SCP_ERR("FIFO wp invalid : %p, %p, %p\n", pStart, pEnd, wp);
		err = release_scp_semaphore(SEMAPHORE_SENSOR);
		if (err < 0) {
			SCP_ERR("release_scp_semaphore fail : %d\n", err);
			return -3;
		}
		return -5;
	}

	if (rp == wp) {
		SCP_ERR("FIFO empty\n");
		err = release_scp_semaphore(SEMAPHORE_SENSOR);
		if (err < 0) {
			SCP_ERR("release_scp_semaphore fail : %d\n", err);
			return -3;
		}
		return 0;
	}

	if (rp < wp) {
		while (rp < wp) {
			event = (struct data_unit_t *)rp;
			handle = event->sensor_type;
			sensor_server_write_ringbuffer_data(event, handle);
			rp += SENSOR_DATA_SIZE;
		}
	} else if (rp > wp) {
		while (rp < pEnd) {
			event = (struct data_unit_t *)rp;
			handle = event->sensor_type;
			sensor_server_write_ringbuffer_data(event, handle);
			rp += SENSOR_DATA_SIZE;
		}
		rp = pStart;
		while (rp < wp) {
			event = (struct data_unit_t *)rp;
			handle = event->sensor_type;
			sensor_server_write_ringbuffer_data(event, handle);
			rp += SENSOR_DATA_SIZE;
		}
	}
	obj->SCP_sensorFIFO->rp = obj->SCP_sensorFIFO->wp;

	if (SCP_TRC_BATCH & atomic_read(&(obj_data->trace))) {
		SCP_ERR("FIFO pStart = %p, rp = %x, wp = %x, pEnd = %p\n", pStart,
			obj->SCP_sensorFIFO->rp, obj->SCP_sensorFIFO->wp, pEnd);
	}
	err = release_scp_semaphore(SEMAPHORE_SENSOR);
	if (err < 0) {
		SCP_ERR("release_scp_semaphore fail : %d\n", err);
		return -3;
	}
	wake_up_activate_thread();
	return 0;
}

static int SCP_sensorHub_get_fifo_status(int *dataLen, int *status, char *reserved,
					 struct batch_timestamp_info *p_batch_timestampe_info)
{
	struct SCP_sensorHub_data *obj = obj_data;
	int err = 0;
	/*SCP_SENSOR_HUB_DATA data; */
	char *pStart, *pEnd, *pNext;
	/*unsigned int len = 0; */
	char *rp, *wp;
	struct batch_timestamp_info *pt = p_batch_timestampe_info;
	int i, offset;

	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();
	for (i = 0; i <= ID_SENSOR_MAX_HANDLE; i++)
		pt[i].total_count = 0;

	*dataLen = 0;
	*status = 1;

	/* To prevent get fifo status during scp wrapper around dram fifo. */
	err = SCP_sensorHub_get_scp_semaphore();
	if (err < 0) {
		SCP_ERR("SCP_sensorHub_get_scp_semaphore fail : %d\n", err);
		return -2;
	}

	pStart = (char *)obj->SCP_sensorFIFO + offsetof(struct sensorFIFO, data);
	pEnd = pStart + obj->SCP_sensorFIFO->FIFOSize;
	rp = pStart + obj->SCP_sensorFIFO->rp;
	wp = pStart + obj->SCP_sensorFIFO->wp;

	err = release_scp_semaphore(SEMAPHORE_SENSOR);
	if (err < 0) {
		SCP_ERR("release_scp_semaphore fail : %d\n", err);
		return -3;
	}

	if (SCP_TRC_BATCH & atomic_read(&(obj_data->trace)))
		SCP_ERR("FIFO pStart = %p, rp = %p, wp = %p, pEnd = %p\n", pStart, rp, wp, pEnd);

	if (rp < pStart || pEnd <= rp) {
		SCP_ERR("FIFO rp invalid : %p, %p, %p\n", pStart, pEnd, rp);
		return -4;
	}

	if (wp < pStart || pEnd < wp) {
		SCP_ERR("FIFO wp invalid : %p, %p, %p\n", pStart, pEnd, wp);
		return -5;
	}

	if (rp == wp) {
		SCP_ERR("FIFO empty\n");
		return -6;
	}


	while (rp != wp) {
		struct data_unit_t *pdata = (struct data_unit_t *)rp;

		pNext = rp + SENSOR_DATA_SIZE;

		if (SCP_TRC_BATCH_DETAIL & atomic_read(&(obj_data->trace)))
			SCP_LOG("rp = %p, sensor_type = %d, pNext = %p\n", rp,
				pdata->sensor_type, pNext);

		if (pdata->sensor_type < 0 || pdata->sensor_type > 58) {
			SCP_ERR("Wrong data, sensor_type = %d .\n", pdata->sensor_type);
			return -7;
		}

		pt[pdata->sensor_type].total_count++;

		if (pNext < pEnd)
			rp = pNext;
		else {
			offset = (int)(pNext - pEnd);
			rp = pStart + offset;
		}
		(*dataLen)++;
	}
	if (SCP_TRC_BATCH & atomic_read(&(obj_data->trace)))
		SCP_ERR("dataLen = %d, status = %d\n", *dataLen, *status);
	pStart = (char *)obj->SCP_sensorFIFO + offsetof(struct sensorFIFO, data);
	pEnd = (char *)pStart + obj->SCP_sensorFIFO->FIFOSize;
	rp = pStart + (int)obj->SCP_sensorFIFO->rp;
	wp = pStart + (int)obj->SCP_sensorFIFO->wp;
	return 0;
}

/* when all sensor don't enable, we adjust scp lower power */
int sensor_send_ap_timetamp(void)
{
	SCP_SENSOR_HUB_DATA req;
	int len;
	int err = 0;
	uint64_t ns;
	struct timespec time;

	time.tv_sec = time.tv_nsec = 0;
	get_monotonic_boottime(&time);
	ns = time.tv_sec * 1000000000LL + time.tv_nsec;
	req.set_config_req.sensorType = 0;
	req.set_config_req.action = SENSOR_HUB_SET_TIMESTAMP;
	req.set_config_req.ap_timestamp = ns;
	len = sizeof(req.set_config_req);
	err = SCP_sensorHub_req_send(&req, &len, 1);
	if (err < 0)
		SCP_ERR("SCP_sensorHub_req_send fail!\n");
	return err;
}

static int scp_sensorHub_power_adjust(void)
{
	deregister_feature(SENS_FEATURE_ID);

	return 0;
}

int sensor_enable_to_hub(uint8_t sensorType, int enabledisable)
{
	SCP_SENSOR_HUB_DATA req;
	int len;
	int err = 0;
	struct SCP_sensorHub_data *obj = obj_data;

	if (enabledisable == 1) {
		set_bit(sensorType, &obj->sensor_activate_bitmap);
		clear_bit(sensorType, &obj->flush_remain_data_after_disable);
		register_feature(SENS_FEATURE_ID);
	} else {
		clear_bit(sensorType, &obj->sensor_activate_bitmap);
		set_bit(sensorType, &obj->flush_remain_data_after_disable);
	}
	req.activate_req.sensorType = sensorType;
	req.activate_req.action = SENSOR_HUB_ACTIVATE;
	req.activate_req.enable = enabledisable;
	len = sizeof(req.activate_req);
	err = SCP_sensorHub_req_send(&req, &len, 1);
	if (err < 0)
		SCP_ERR("SCP_sensorHub_req_send fail!\n");

	return err;
}

int sensor_set_delay_to_hub(uint8_t sensorType, unsigned int delayms)
{
	SCP_SENSOR_HUB_DATA req;
	int len;
	int err = 0;

	req.set_delay_req.sensorType = sensorType;
	req.set_delay_req.action = SENSOR_HUB_SET_DELAY;
	req.set_delay_req.delay = delayms;
	len = sizeof(req.set_delay_req);
	err = SCP_sensorHub_req_send(&req, &len, 1);
	if (err < 0)
		SCP_ERR("SCP_sensorHub_req_send fail!\n");

	return err;
}

int sensor_get_data_from_hub(uint8_t sensorType, struct data_unit_t *data)
{
	SCP_SENSOR_HUB_DATA req;
	struct data_unit_t *data_t;
	int len = 0, err = 0;

	req.get_data_req.sensorType = sensorType;
	req.get_data_req.action = SENSOR_HUB_GET_DATA;
	len = sizeof(req.get_data_req);
	err = SCP_sensorHub_req_send(&req, &len, 1);
	if (err < 0) {
		SCP_ERR("SCP_sensorHub_req_send fail!\n");
		return -1;
	}
	if (sensorType != req.get_data_rsp.sensorType ||
	    SENSOR_HUB_GET_DATA != req.get_data_rsp.action || 0 != req.get_data_rsp.errCode) {
		SCP_ERR("error : %d\n", req.get_data_rsp.errCode);
		return req.get_data_rsp.errCode;
	}

	data_t = (struct data_unit_t *)req.get_data_rsp.data.int8_Data;
	switch (sensorType) {
	case ID_ACCELEROMETER:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->accelerometer_t.x = data_t->accelerometer_t.x;
		data->accelerometer_t.y = data_t->accelerometer_t.y;
		data->accelerometer_t.z = data_t->accelerometer_t.z;
		data->accelerometer_t.x_bias = data_t->accelerometer_t.x_bias;
		data->accelerometer_t.y_bias = data_t->accelerometer_t.y_bias;
		data->accelerometer_t.z_bias = data_t->accelerometer_t.z_bias;
		data->accelerometer_t.status = data_t->accelerometer_t.status;
		break;
	case ID_GRAVITY:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->accelerometer_t.x = data_t->accelerometer_t.x;
		data->accelerometer_t.y = data_t->accelerometer_t.y;
		data->accelerometer_t.z = data_t->accelerometer_t.z;
		data->accelerometer_t.status = data_t->accelerometer_t.status;
		break;
	case ID_LINEAR_ACCELERATION:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->accelerometer_t.x = data_t->accelerometer_t.x;
		data->accelerometer_t.y = data_t->accelerometer_t.y;
		data->accelerometer_t.z = data_t->accelerometer_t.z;
		data->accelerometer_t.status = data_t->accelerometer_t.status;
		break;
	case ID_LIGHT:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->light = data_t->light;
		break;
	case ID_PROXIMITY:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->proximity_t.steps = data_t->proximity_t.steps;
		data->proximity_t.oneshot = data_t->proximity_t.oneshot;
		break;
	case ID_PRESSURE:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->pressure_t.pressure = data_t->pressure_t.pressure;
		data->pressure_t.status = data_t->pressure_t.status;
		break;
	case ID_GYROSCOPE:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->gyroscope_t.x = data_t->gyroscope_t.x;
		data->gyroscope_t.y = data_t->gyroscope_t.y;
		data->gyroscope_t.z = data_t->gyroscope_t.z;
		data->gyroscope_t.x_bias = data_t->gyroscope_t.x_bias;
		data->gyroscope_t.y_bias = data_t->gyroscope_t.y_bias;
		data->gyroscope_t.z_bias = data_t->gyroscope_t.z_bias;
		data->gyroscope_t.status = data_t->gyroscope_t.status;
		break;
	case ID_GYROSCOPE_UNCALIBRATED:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->uncalibrated_gyro_t.x = data_t->uncalibrated_gyro_t.x;
		data->uncalibrated_gyro_t.y = data_t->uncalibrated_gyro_t.y;
		data->uncalibrated_gyro_t.z = data_t->uncalibrated_gyro_t.z;
		data->uncalibrated_gyro_t.x_bias = data_t->uncalibrated_gyro_t.x_bias;
		data->uncalibrated_gyro_t.y_bias = data_t->uncalibrated_gyro_t.y_bias;
		data->uncalibrated_gyro_t.z_bias = data_t->uncalibrated_gyro_t.z_bias;
		data->uncalibrated_gyro_t.status = data_t->uncalibrated_gyro_t.status;
		break;
	case ID_RELATIVE_HUMIDITY:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->relative_humidity_t.relative_humidity =
		    data_t->relative_humidity_t.relative_humidity;
		data->relative_humidity_t.status = data_t->relative_humidity_t.status;
		break;
	case ID_MAGNETIC:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->magnetic_t.x = data_t->magnetic_t.x;
		data->magnetic_t.y = data_t->magnetic_t.y;
		data->magnetic_t.z = data_t->magnetic_t.z;
		data->magnetic_t.x_bias = data_t->magnetic_t.x_bias;
		data->magnetic_t.y_bias = data_t->magnetic_t.y_bias;
		data->magnetic_t.z_bias = data_t->magnetic_t.z_bias;
		data->magnetic_t.status = data_t->magnetic_t.status;
		break;
	case ID_MAGNETIC_UNCALIBRATED:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->uncalibrated_mag_t.x = data_t->uncalibrated_mag_t.x;
		data->uncalibrated_mag_t.y = data_t->uncalibrated_mag_t.y;
		data->uncalibrated_mag_t.z = data_t->uncalibrated_mag_t.z;
		data->uncalibrated_mag_t.x_bias = data_t->uncalibrated_mag_t.x_bias;
		data->uncalibrated_mag_t.y_bias = data_t->uncalibrated_mag_t.y_bias;
		data->uncalibrated_mag_t.z_bias = data_t->uncalibrated_mag_t.z_bias;
		data->uncalibrated_mag_t.status = data_t->uncalibrated_mag_t.status;
		break;
	case ID_GEOMAGNETIC_ROTATION_VECTOR:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->magnetic_t.x = data_t->magnetic_t.x;
		data->magnetic_t.y = data_t->magnetic_t.y;
		data->magnetic_t.z = data_t->magnetic_t.z;
		data->magnetic_t.scalar = data_t->magnetic_t.scalar;
		data->magnetic_t.status = data_t->magnetic_t.status;
		break;
	case ID_ORIENTATION:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->orientation_t.azimuth = data_t->orientation_t.azimuth;
		data->orientation_t.pitch = data_t->orientation_t.pitch;
		data->orientation_t.roll = data_t->orientation_t.roll;
		data->orientation_t.status = data_t->orientation_t.status;
		break;
	case ID_ROTATION_VECTOR:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->orientation_t.azimuth = data_t->orientation_t.azimuth;
		data->orientation_t.pitch = data_t->orientation_t.pitch;
		data->orientation_t.roll = data_t->orientation_t.roll;
		data->orientation_t.scalar = data_t->orientation_t.scalar;
		data->orientation_t.status = data_t->orientation_t.status;
		break;
	case ID_GAME_ROTATION_VECTOR:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->orientation_t.azimuth = data_t->orientation_t.azimuth;
		data->orientation_t.pitch = data_t->orientation_t.pitch;
		data->orientation_t.roll = data_t->orientation_t.roll;
		data->orientation_t.scalar = data_t->orientation_t.scalar;
		data->orientation_t.status = data_t->orientation_t.status;
		break;
	case ID_STEP_COUNTER:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->step_counter_t.accumulated_step_count
		    = data_t->step_counter_t.accumulated_step_count;
		break;
	case ID_STEP_DETECTOR:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->step_detector_t.step_detect = data_t->step_detector_t.step_detect;
		break;
	case ID_SIGNIFICANT_MOTION:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->smd_t.state = data_t->smd_t.state;
		break;
	case ID_HEART_RATE:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->heart_rate_t.bpm = data_t->heart_rate_t.bpm;
		data->heart_rate_t.status = data_t->heart_rate_t.status;
		break;
	case ID_PEDOMETER:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->pedometer_t.accumulated_step_count =
		    data_t->pedometer_t.accumulated_step_count;
		data->pedometer_t.accumulated_step_length =
		    data_t->pedometer_t.accumulated_step_length;
		data->pedometer_t.step_frequency = data_t->pedometer_t.step_frequency;
		data->pedometer_t.step_length = data_t->pedometer_t.step_length;
		break;
	case ID_ACTIVITY:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->activity_data_t.probability[STILL] =
		    data_t->activity_data_t.probability[STILL];
		data->activity_data_t.probability[STANDING] =
		    data_t->activity_data_t.probability[STANDING];
		data->activity_data_t.probability[SITTING] =
		    data_t->activity_data_t.probability[SITTING];
		data->activity_data_t.probability[LYING] =
		    data_t->activity_data_t.probability[LYING];
		data->activity_data_t.probability[ON_FOOT] =
		    data_t->activity_data_t.probability[ON_FOOT];
		data->activity_data_t.probability[WALKING] =
		    data_t->activity_data_t.probability[WALKING];
		data->activity_data_t.probability[RUNNING] =
		    data_t->activity_data_t.probability[RUNNING];
		data->activity_data_t.probability[CLIMBING] =
		    data_t->activity_data_t.probability[CLIMBING];
		data->activity_data_t.probability[ON_BICYCLE] =
		    data_t->activity_data_t.probability[ON_BICYCLE];
		data->activity_data_t.probability[IN_VEHICLE] =
		    data_t->activity_data_t.probability[IN_VEHICLE];
		data->activity_data_t.probability[TILTING] =
		    data_t->activity_data_t.probability[TILTING];
		data->activity_data_t.probability[UNKNOWN] =
		    data_t->activity_data_t.probability[UNKNOWN];
		break;
	case ID_IN_POCKET:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->inpocket_event.state = data_t->inpocket_event.state;
		break;
	case ID_PICK_UP_GESTURE:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->gesture_data_t.probability = data_t->gesture_data_t.probability;
		break;
	case ID_TILT_DETECTOR:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->tilt_event.state = data_t->tilt_event.state;
		break;
	case ID_WAKE_GESTURE:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->gesture_data_t.probability = data_t->gesture_data_t.probability;
		break;
	case ID_GLANCE_GESTURE:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->gesture_data_t.probability = data_t->gesture_data_t.probability;
		break;
	case ID_PDR:
		data->time_stamp = data_t->time_stamp;
		data->time_stamp_gpt = data_t->time_stamp_gpt;
		data->pdr_event.x = data_t->pdr_event.x;
		data->pdr_event.y = data_t->pdr_event.y;
		data->pdr_event.z = data_t->pdr_event.z;
		data->pdr_event.status = data_t->pdr_event.status;
		break;
	default:
		err = -1;
		break;
	}
	return err;
}

int sensor_set_cmd_to_hub(uint8_t sensorType, CUST_ACTION action, void *data)
{
	SCP_SENSOR_HUB_DATA req;
	int len = 0, err = 0;

	req.get_data_req.sensorType = sensorType;
	req.get_data_req.action = SENSOR_HUB_SET_CUST;

	switch (sensorType) {
	case ID_ACCELEROMETER:
		req.set_cust_req.sensorType = ID_ACCELEROMETER;
		req.set_cust_req.action = SENSOR_HUB_SET_CUST;
		switch (action) {
		case CUST_ACTION_RESET_CALI:
			req.set_cust_req.resetCali.action = CUST_ACTION_RESET_CALI;
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.resetCali);
			break;
		case CUST_ACTION_SET_CALI:
			req.set_cust_req.setCali.action = CUST_ACTION_SET_CALI;
			req.set_cust_req.setCali.int32_data[SCP_SENSOR_HUB_X]
			    = *((int32_t *) data + SCP_SENSOR_HUB_X);
			req.set_cust_req.setCali.int32_data[SCP_SENSOR_HUB_Y]
			    = *((int32_t *) data + SCP_SENSOR_HUB_Y);
			req.set_cust_req.setCali.int32_data[SCP_SENSOR_HUB_Z]
			    = *((int32_t *) data + SCP_SENSOR_HUB_Z);
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.setCali);
			break;
		case CUST_ACTION_SET_TRACE:
			req.set_cust_req.setTrace.action = CUST_ACTION_SET_TRACE;
			req.set_cust_req.setTrace.trace = *((int32_t *) data);
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.setTrace);
			break;
		case CUST_ACTION_SET_DIRECTION:
			req.set_cust_req.setDirection.action = CUST_ACTION_SET_DIRECTION;
			req.set_cust_req.setDirection.direction = *((int32_t *) data);
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.setDirection);
			break;
		case CUST_ACTION_SET_FACTORY:
			req.set_cust_req.setFactory.action = CUST_ACTION_SET_FACTORY;
			req.set_cust_req.setFactory.factory = *((int32_t *) data);
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.setFactory);
			break;
		case CUST_ACTION_SHOW_REG:
			req.set_cust_req.showReg.action = CUST_ACTION_SHOW_REG;
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.showReg);
			break;
		default:
			return -1;
		}
		break;
	case ID_LIGHT:
		req.set_cust_req.sensorType = ID_LIGHT;
		req.set_cust_req.action = SENSOR_HUB_SET_CUST;
		switch (action) {
		case CUST_ACTION_GET_RAW_DATA:
			req.set_cust_req.getRawData.action = CUST_ACTION_GET_RAW_DATA;
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.getRawData);
			err = SCP_sensorHub_req_send(&req, &len, 1);
			if (0 == err) {
				if (SENSOR_HUB_SET_CUST != req.set_cust_rsp.action
				    || 0 != req.set_cust_rsp.errCode) {
					SCP_ERR("SCP_sensorHub_req_send failed!\n");
					return -1;
				}
				if (CUST_ACTION_GET_RAW_DATA != req.set_cust_rsp.getRawData.action) {
					SCP_ERR("SCP_sensorHub_req_send failed!\n");
					return -1;
				}
				*((uint8_t *) data) = req.set_cust_rsp.getRawData.uint8_data[0];
			} else {
				SCP_ERR("SCP_sensorHub_req_send failed!\n");
			}
			return 0;
		case CUST_ACTION_SHOW_ALSLV:
			req.set_cust_req.showAlslv.action = CUST_ACTION_SHOW_ALSLV;
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.showAlslv);
			break;
		case CUST_ACTION_SHOW_ALSVAL:
			req.set_cust_req.showAlsval.action = CUST_ACTION_GET_RAW_DATA;
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.showAlsval);
			break;
		default:
			return -1;
		}
		break;
	case ID_PROXIMITY:
		req.set_cust_req.sensorType = ID_PROXIMITY;
		req.set_cust_req.action = SENSOR_HUB_SET_CUST;
		switch (action) {
		case CUST_ACTION_RESET_CALI:
			req.set_cust_req.resetCali.action = CUST_ACTION_RESET_CALI;
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.resetCali);
			break;
		case CUST_ACTION_SET_CALI:
			req.set_cust_req.setCali.action = CUST_ACTION_SET_CALI;
			req.set_cust_req.setCali.int32_data[0] = *((int32_t *) data);
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.setCali);
			break;
		case CUST_ACTION_SET_TRACE:
			req.set_cust_req.setTrace.action = CUST_ACTION_SET_TRACE;
			req.set_cust_req.setTrace.trace = *((int32_t *) data);
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.setTrace);
			break;
		case CUST_ACTION_SHOW_REG:
			req.set_cust_req.showReg.action = CUST_ACTION_SHOW_REG;
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.showReg);
			break;
		case CUST_ACTION_SET_PS_THRESHOLD:
			req.set_cust_req.setPSThreshold.action = CUST_ACTION_SET_PS_THRESHOLD;
			req.set_cust_req.setPSThreshold.threshold[0]
			    = *((int32_t *) data + 0);
			req.set_cust_req.setPSThreshold.threshold[1]
			    = *((int32_t *) data + 1);
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.setPSThreshold);
			break;
		case CUST_ACTION_GET_RAW_DATA:
			req.set_cust_req.getRawData.action = CUST_ACTION_GET_RAW_DATA;
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.getRawData);
			err = SCP_sensorHub_req_send(&req, &len, 1);
			if (0 == err) {
				if (SENSOR_HUB_SET_CUST != req.set_cust_rsp.action
				    || 0 != req.set_cust_rsp.errCode) {
					SCP_ERR("SCP_sensorHub_req_send failed!\n");
					return -1;
				}
				if (CUST_ACTION_GET_RAW_DATA != req.set_cust_rsp.getRawData.action) {
					SCP_ERR("SCP_sensorHub_req_send failed!\n");
					return -1;
				}
				*((uint16_t *) data) = req.set_cust_rsp.getRawData.uint16_data[0];
			} else {
				SCP_ERR("SCP_sensorHub_req_send failed!\n");
			}
			return 0;
		default:
			return -1;
		}
		break;
	case ID_PRESSURE:
		req.set_cust_req.sensorType = ID_PRESSURE;
		req.set_cust_req.action = SENSOR_HUB_SET_CUST;
		switch (action) {
		case CUST_ACTION_SET_TRACE:
			req.set_cust_req.setTrace.action = CUST_ACTION_SET_TRACE;
			req.set_cust_req.setTrace.trace = *((int32_t *) data);
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.setTrace);
			break;
		case CUST_ACTION_SHOW_REG:
			req.set_cust_req.showReg.action = CUST_ACTION_SHOW_REG;
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.showReg);
			break;
		default:
			return -1;
		}
		break;
	case ID_GYROSCOPE:
		req.set_cust_req.sensorType = ID_GYROSCOPE;
		req.set_cust_req.action = SENSOR_HUB_SET_CUST;
		switch (action) {
		case CUST_ACTION_RESET_CALI:
			req.set_cust_req.resetCali.action = CUST_ACTION_RESET_CALI;
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.resetCali);
			break;
		case CUST_ACTION_SET_CALI:
			req.set_cust_req.setCali.action = CUST_ACTION_SET_CALI;
			req.set_cust_req.setCali.int32_data[SCP_SENSOR_HUB_X]
			    = *((int32_t *) data + SCP_SENSOR_HUB_X);
			req.set_cust_req.setCali.int32_data[SCP_SENSOR_HUB_Y]
			    = *((int32_t *) data + SCP_SENSOR_HUB_Y);
			req.set_cust_req.setCali.int32_data[SCP_SENSOR_HUB_Z]
			    = *((int32_t *) data + SCP_SENSOR_HUB_Z);
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.setCali);
			break;
		case CUST_ACTION_SET_TRACE:
			req.set_cust_req.setTrace.action = CUST_ACTION_SET_TRACE;
			req.set_cust_req.setTrace.trace = *((int32_t *) data);
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.setTrace);
			break;
		case CUST_ACTION_SET_DIRECTION:
			req.set_cust_req.setDirection.action = CUST_ACTION_SET_DIRECTION;
			req.set_cust_req.setDirection.direction = *((int32_t *) data);
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.setDirection);
			break;
		case CUST_ACTION_SET_FACTORY:
			req.set_cust_req.setFactory.action = CUST_ACTION_SET_FACTORY;
			req.set_cust_req.setFactory.factory = *((int32_t *) data);
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.setFactory);
			break;
		case CUST_ACTION_SHOW_REG:
			req.set_cust_req.showReg.action = CUST_ACTION_SHOW_REG;
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.showReg);
			break;
		default:
			return -1;
		}
		break;
	case ID_RELATIVE_HUMIDITY:
		req.set_cust_req.sensorType = ID_MAGNETIC;
		req.set_cust_req.action = SENSOR_HUB_SET_CUST;
		switch (action) {
		case CUST_ACTION_SET_TRACE:
			req.set_cust_req.setTrace.action = CUST_ACTION_SET_TRACE;
			req.set_cust_req.setTrace.trace = *((int32_t *) data);
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.setTrace);
			break;
		case CUST_ACTION_SHOW_REG:
			req.set_cust_req.showReg.action = CUST_ACTION_SHOW_REG;
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.showReg);
			break;
		default:
			return -1;
		}
		break;
	case ID_MAGNETIC:
		req.set_cust_req.sensorType = ID_MAGNETIC;
		req.set_cust_req.action = SENSOR_HUB_SET_CUST;
		switch (action) {
		case CUST_ACTION_SET_TRACE:
			req.set_cust_req.setTrace.action = CUST_ACTION_SET_TRACE;
			req.set_cust_req.setTrace.trace = *((int32_t *) data);
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.setTrace);
			break;
		case CUST_ACTION_SET_DIRECTION:
			req.set_cust_req.setDirection.action = CUST_ACTION_SET_DIRECTION;
			req.set_cust_req.setDirection.direction = *((int32_t *) data);
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.setDirection);
			break;
		case CUST_ACTION_SHOW_REG:
			req.set_cust_req.showReg.action = CUST_ACTION_SHOW_REG;
			len = offsetof(SCP_SENSOR_HUB_SET_CUST_REQ, custData)
			    + sizeof(req.set_cust_req.showReg);
			break;
		default:
			return -1;
		}
		break;
	default:
		err = -1;
		break;
	}

	err = SCP_sensorHub_req_send(&req, &len, 1);
	if (err < 0) {
		SCP_ERR("SCP_sensorHub_req_send fail!\n");
		return -1;
	}
	if (sensorType != req.get_data_rsp.sensorType ||
	    SENSOR_HUB_SET_CUST != req.get_data_rsp.action || 0 != req.get_data_rsp.errCode) {
		SCP_ERR("error : %d\n", req.get_data_rsp.errCode);
		return req.get_data_rsp.errCode;
	}

	return err;
}

static int SCP_sensorHub_mask_notify(void)
{
	SCP_SENSOR_HUB_DATA req;
	int len;
	int err = 0;

	req.mask_notify_req.sensorType = 0;
	req.mask_notify_req.action = SENSOR_HUB_MASK_NOTIFY;
	req.mask_notify_req.if_mask_or_not = 1;
	len = sizeof(req.mask_notify_req);
	err = SCP_sensorHub_req_send(&req, &len, 1);
	if (err < 0)
		SCP_ERR("SCP_sensorHub_req_send fail!\n");
	return err;
}

static int SCP_sensorHub_unmask_notify(void)
{
	SCP_SENSOR_HUB_DATA req;
	int len;
	int err = 0;

	req.mask_notify_req.sensorType = 0;
	req.mask_notify_req.action = SENSOR_HUB_MASK_NOTIFY;
	req.mask_notify_req.if_mask_or_not = 0;
	len = sizeof(req.mask_notify_req);
	err = SCP_sensorHub_req_send(&req, &len, 1);
	if (err < 0)
		SCP_ERR("SCP_sensorHub_req_send fail!\n");
	return err;
}

static int sensorHub_probe(struct platform_device *pdev)
{
	struct SCP_sensorHub_data *obj;
	int err = 0, handle = 0;
	struct batch_control_path ctl = { 0 };
	struct batch_data_path data = { 0 };

	SCP_FUN();
	obj = kzalloc(sizeof(*obj), GFP_KERNEL);
	if (!obj) {
		SCP_ERR("Allocate SCP_sensorHub_data fail\n");
		err = -ENOMEM;
		goto exit;
	}

	memset(obj, 0, sizeof(struct SCP_sensorHub_data));
	/* obj->SCP_sensorFIFO = kzalloc(SCP_SENSOR_HUB_FIFO_SIZE, GFP_KERNEL); */
	obj->SCP_sensorFIFO = (struct sensorFIFO *)get_reserve_mem_virt(SENS_MEM_ID);
	if (!obj->SCP_sensorFIFO) {
		SCP_ERR("Allocate SCP_sensorFIFO fail\n");
		err = -ENOMEM;
		goto exit;
	}
	obj->SCP_directPush_FIFO = (struct sensorFIFO *)get_reserve_mem_virt(SENS_MEM_DIRECT_ID);
	if (!obj->SCP_directPush_FIFO) {
		SCP_ERR("Allocate SCP_sensorFIFO fail\n");
		err = -ENOMEM;
		goto exit;
	}
	for (handle = ID_ACCELEROMETER; handle < ID_SENSOR_MAX_HANDLE; handle++) {
		switch (handle) {
		case ID_ACCELEROMETER:
		case ID_MAGNETIC:
		case ID_MAGNETIC_UNCALIBRATED:
		case ID_ORIENTATION:
		case ID_ROTATION_VECTOR:
		case ID_GAME_ROTATION_VECTOR:
		case ID_GEOMAGNETIC_ROTATION_VECTOR:
		case ID_GRAVITY:
		case ID_LINEAR_ACCELERATION:
		case ID_PEDOMETER:
			sprintf(obj->client[handle].name, "sensor%d", handle);
			spin_lock_init(&obj->client[handle].buffer_lock);
			atomic_set(&obj->client[handle].delay_count, 0);
			obj->client[handle].head = 0;
			obj->client[handle].tail = 0;
			obj->client[handle].bufsize = SCP_KFIFO_BUFFER_SIZE;
			obj->client[handle].ringbuffer =
			    vzalloc(obj->client[handle].bufsize * sizeof(struct data_unit_t));
			if (!obj->client[handle].ringbuffer) {
				SCP_ERR("Alloc ringbuffer error!\n");
				goto exit;
			}
			obj->client[handle].single_thread =
			    create_singlethread_workqueue(obj->client[handle].name);
			break;
		case ID_ACTIVITY:
			sprintf(obj->client[handle].name, "sensor%d", handle);
			spin_lock_init(&obj->client[handle].buffer_lock);
			atomic_set(&obj->client[handle].delay_count, 0);
			obj->client[handle].head = 0;
			obj->client[handle].tail = 0;
			obj->client[handle].bufsize = SCP_KFIFO_BUFFER_SIZE * 128;
			obj->client[handle].ringbuffer =
			    vzalloc(obj->client[handle].bufsize * sizeof(struct data_unit_t));
			if (!obj->client[handle].ringbuffer) {
				SCP_ERR("Alloc ringbuffer error!\n");
				goto exit;
			}
			obj->client[handle].single_thread =
			    create_singlethread_workqueue(obj->client[handle].name);
			break;
		case ID_GYROSCOPE:
		case ID_GYROSCOPE_UNCALIBRATED:
			sprintf(obj->client[handle].name, "sensor%d", handle);
			spin_lock_init(&obj->client[handle].buffer_lock);
			atomic_set(&obj->client[handle].delay_count, 0);
			obj->client[handle].head = 0;
			obj->client[handle].tail = 0;
			obj->client[handle].bufsize = SCP_KFIFO_BUFFER_SIZE * 2;
			obj->client[handle].ringbuffer =
			    vzalloc(obj->client[handle].bufsize * sizeof(struct data_unit_t));
			if (!obj->client[handle].ringbuffer) {
				SCP_ERR("Alloc ringbuffer error!\n");
				goto exit;
			}
			obj->client[handle].single_thread =
			    create_singlethread_workqueue(obj->client[handle].name);
			break;
		default:
			break;
		}
	}
	INIT_WORK(&obj->client[ID_ACCELEROMETER].worker, accelerometer_report_data_work);
	INIT_WORK(&obj->client[ID_MAGNETIC].worker, magnetic_report_data_work);
	INIT_WORK(&obj->client[ID_MAGNETIC_UNCALIBRATED].worker, unmagnetic_report_data_work);
	INIT_WORK(&obj->client[ID_GYROSCOPE].worker, gyroscope_report_data_work);
	INIT_WORK(&obj->client[ID_GYROSCOPE_UNCALIBRATED].worker, ungyroscope_report_data_work);
	INIT_WORK(&obj->client[ID_ORIENTATION].worker, orientation_report_data_work);
	INIT_WORK(&obj->client[ID_ROTATION_VECTOR].worker, rotvec_report_data_work);
	INIT_WORK(&obj->client[ID_GAME_ROTATION_VECTOR].worker, gamerotvec_report_data_work);
	INIT_WORK(&obj->client[ID_GEOMAGNETIC_ROTATION_VECTOR].worker,
		  geomagnetic_report_data_work);
	INIT_WORK(&obj->client[ID_GRAVITY].worker, gravity_report_data_work);
	INIT_WORK(&obj->client[ID_LINEAR_ACCELERATION].worker, linearaccel_report_data_work);
	INIT_WORK(&obj->client[ID_PEDOMETER].worker, pedometer_report_data_work);
	INIT_WORK(&obj->client[ID_ACTIVITY].worker, activity_report_data_work);

	obj->sensor_activate_bitmap = 0;
	obj->flush_remain_data_after_disable = 0;
	obj->SCP_sensorFIFO->wp = 0;
	obj->SCP_sensorFIFO->rp = 0;
	obj->SCP_sensorFIFO->FIFOSize =
	    SCP_SENSOR_HUB_FIFO_SIZE - offsetof(struct sensorFIFO, data);

	obj->SCP_directPush_FIFO->wp = 0;
	obj->SCP_directPush_FIFO->rp = 0;
	obj->SCP_directPush_FIFO->FIFOSize =
	    SCP_DIRECT_PUSH_FIFO_SIZE - offsetof(struct sensorFIFO, data);

	SCP_ERR("obj->SCP_sensorFIFO = %p, wp = %d, rp = %d, size = %d\n", obj->SCP_sensorFIFO,
		obj->SCP_sensorFIFO->wp, obj->SCP_sensorFIFO->rp, obj->SCP_sensorFIFO->FIFOSize);

	obj_data = obj;

	atomic_set(&obj->trace, 0);
	atomic_set(&obj->suspend, 0);
	atomic_set(&obj->wait_rsp, 0);
	atomic_set(&obj->ipi_handler_running, 0);
	atomic_set(&obj->disable_fifo_full_notify, 0);
	INIT_WORK(&obj->ipi_work, SCP_ipi_work);
	INIT_WORK(&obj->fifo_full_work, SCP_fifo_full_work);

	INIT_WORK(&obj->batch_timeout_work, SCP_batch_timeout_work);
	INIT_WORK(&obj->direct_push_work, SCP_direct_push_work);
	INIT_WORK(&obj->power_notify_work, SCP_power_notify_work);

	init_waitqueue_head(&SCP_sensorHub_req_wq);
	init_timer(&obj->timer);
	obj->timer.expires = 3 * HZ;
	obj->timer.function = SCP_sensorHub_req_send_timeout;
	obj->timer.data = (unsigned long)obj;

#ifdef	SENSOR_SCP_AP_TIME_SYNC
	INIT_WORK(&syncwork, syncwork_fun);
	sync_timer.expires = jiffies + 3 * HZ;
	sync_timer.function = sync_timeout;
	init_timer(&sync_timer);
	mod_timer(&sync_timer, jiffies + 3 * HZ);
#endif

	scp_ipi_registration(IPI_SENSOR, SCP_sensorHub_IPI_handler, "SCP_sensorHub");

	err = misc_register(&SCP_sensorHub_device);
	if (err) {
		SCP_ERR("SCP_sensorHub_device register failed\n");
		goto exit_misc_device_register_failed;
	}

	err = SCP_sensorHub_create_attr(&(SCP_sensorHub_init_info.platform_diver_addr->driver));
	if (err) {
		SCP_ERR("create attribute err = %d\n", err);
		goto exit_create_attr_failed;
	}

	ctl.enable_hw_batch = SCP_sensorHub_enable_hw_batch;
	ctl.flush = SCP_sensorHub_flush;
	err = batch_register_control_path(ID_SENSOR_MAX_HANDLE, &ctl);
	if (err) {
		SCP_ERR("register SCP sensor hub control path err\n");
		goto exit_kfree;
	}

	data.get_data = SCP_sensorHub_get_data;
	data.get_fifo_status = SCP_sensorHub_get_fifo_status;
	data.batch_timeout = SCP_sensorHub_batch_timeout;
	data.is_batch_supported = 1;
	err = batch_register_data_path(ID_SENSOR_MAX_HANDLE, &data);
	if (err) {
		SCP_ERR("register SCP sensor hub control data path err\n");
		goto exit_kfree;
	}
	SCP_sensorHub_init_flag = 0;
	SCP_sensorHub_init_client();
	SCP_ERR("fwq init done\n");

	return 0;

exit_create_attr_failed:
	misc_deregister(&SCP_sensorHub_device);
exit_misc_device_register_failed:
exit_kfree:
	kfree(obj);
exit:
	SCP_ERR("%s: err = %d\n", __func__, err);
	SCP_sensorHub_init_flag = -1;
	return err;
}

static int sensorHub_remove(struct platform_device *pdev)
{
	int err = 0;

	err = SCP_sensorHub_delete_attr(&(SCP_sensorHub_init_info.platform_diver_addr->driver));
	if (err)
		SCP_ERR("SCP_sensorHub_delete_attr fail: %d\n", err);

	err = misc_deregister(&SCP_sensorHub_device);
	if (err)
		SCP_ERR("misc_deregister fail: %d\n", err);
	return 0;
}

static int sensorHub_suspend(struct platform_device *pdev, pm_message_t msg)
{
	sensor_send_ap_timetamp();
	SCP_sensorHub_mask_notify();
	return 0;
}

static int sensorHub_resume(struct platform_device *pdev)
{
	sensor_send_ap_timetamp();
	SCP_sensorHub_unmask_notify();
	return 0;
}

static struct platform_device sensorHub_device = {
	.name = "sensor_hub_pl",
	.id = -1,
};

static struct platform_driver sensorHub_driver = {
	.driver = {
		   .name = "sensor_hub_pl",
		   },
	.probe = sensorHub_probe,
	.remove = sensorHub_remove,
	.suspend = sensorHub_suspend,
	.resume = sensorHub_resume,
};

static int SCP_sensorHub_local_init(void)
{
	if (platform_driver_register(&sensorHub_driver)) {
		SCP_ERR("add driver error\n");
		return -1;
	}
	if (-1 == SCP_sensorHub_init_flag)
		return -1;
	return 0;
}

static int SCP_sensorHub_local_remove(void)
{
	if (SCP_TRC_FUN == atomic_read(&(obj_data->trace)))
		SCP_FUN();

	platform_driver_unregister(&sensorHub_driver);
	return 0;
}

static int __init SCP_sensorHub_init(void)
{
	SCP_FUN();
	if (platform_device_register(&sensorHub_device)) {
		SCP_ERR("SCP_sensorHub platform device error\n");
		return -1;
	}
	batch_driver_add(&SCP_sensorHub_init_info);
	return 0;
}

static void __exit SCP_sensorHub_exit(void)
{
	SCP_FUN();
}
module_init(SCP_sensorHub_init);
module_exit(SCP_sensorHub_exit);
MODULE_LICENSE("GPL");
MODULE_DESCRIPTION("SCP sensor hub driver");
MODULE_AUTHOR("andrew.yang@mediatek.com");
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            config CAN_MSCAN
	depends on PPC
	tristate "Support for Freescale MSCAN based chips"
	---help---
	  The Motorola Scalable Controller Area Network (MSCAN) definition
	  is based on the MSCAN12 definition which is the specific
	  implementation of the Motorola Scalable CAN concept targeted for
	  the Motorola MC68HC12 Microcontroller Family.

if CAN_MSCAN

config CAN_MPC5XXX
	tristate "Freescale MPC5xxx onboard CAN controller"
	depends on (PPC_MPC52xx || PPC_MPC512x)
	---help---
	  If you say yes here you get support for Freescale's MPC5xxx
	  onboard CAN controller. Currently, the MPC5200, MPC5200B and
	  MPC5121 (Rev. 2 and later) are supported.

	  This driver can also be built as a module. If so, the module
	  will be called mscan-mpc5xxx.ko.

endif

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     /* drivers/net/pppolac.c
 *
 * Driver for PPP on L2TP Access Concentrator / PPPoLAC Socket (RFC 2661)
 *
 * Copyright (C) 2009 Google, Inc.
 *
 * This software is licensed under the terms of the GNU General Public
 * License version 2, as published by the Free Software Foundation, and
 * may be copied, distributed, and modified under those terms.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 */

/* This driver handles L2TP data packets between a UDP socket and a PPP channel.
 * The socket must keep connected, and only one session per socket is permitted.
 * Sequencing of outgoing packets is controlled by LNS. Incoming packets with
 * sequences are reordered within a sliding window of one second. Currently
 * reordering only happens when a packet is received. It is done for simplicity
 * since no additional locks or threads are required. This driver only works on
 * IPv4 due to the lack of UDP encapsulation support in IPv6. */

#include <linux/module.h>
#include <linux/jiffies.h>
#include <linux/workqueue.h>
#include <linux/skbuff.h>
#include <linux/file.h>
#include <linux/netdevice.h>
#include <linux/net.h>
#include <linux/udp.h>
#include <linux/ppp_defs.h>
#include <linux/if_ppp.h>
#include <linux/if_pppox.h>
#include <linux/ppp_channel.h>
#include <net/tcp_states.h>
#include <asm/uaccess.h>

#define L2TP_CONTROL_BIT	0x80
#define L2TP_LENGTH_BIT		0x40
#define L2TP_SEQUENCE_BIT	0x08
#define L2TP_OFFSET_BIT		0x02
#define L2TP_VERSION		0x02
#define L2TP_VERSION_MASK	0x0F

#define PPP_ADDR	0xFF
#define PPP_CTRL	0x03

union unaligned {
	__u32 u32;
} __attribute__((packed));

static inline union unaligned *unaligned(void *ptr)
{
	return (union unaligned *)ptr;
}

struct meta {
	__u32 sequence;
	__u32 timestamp;
};

static inline struct meta *skb_meta(struct sk_buff *skb)
{
	return (struct meta *)skb->cb;
}

/******************************************************************************/

static int pppolac_recv_core(struct sock *sk_udp, struct sk_buff *skb)
{
	struct sock *sk = (struct sock *)sk_udp->sk_user_data;
	struct pppolac_opt *opt = &pppox_sk(sk)->proto.lac;
	struct meta *meta = skb_meta(skb);
	__u32 now = jiffies;
	__u8 bits;
	__u8 *ptr;

	/* Drop the packet if L2TP header is missing. */
	if (skb->len < sizeof(struct udphdr) + 6)
		goto drop;

	/* Put it back if it is a control packet. */
	if (skb->data[sizeof(struct udphdr)] & L2TP_CONTROL_BIT)
		return opt->backlog_rcv(sk_udp, skb);

	/* Skip UDP header. */
	skb_pull(skb, sizeof(struct udphdr));

	/* Check the version. */
	if ((skb->data[1] & L2TP_VERSION_MASK) != L2TP_VERSION)
		goto drop;
	bits = skb->data[0];
	ptr = &skb->data[2];

	/* Check the length if it is present. */
	if (bits & L2TP_LENGTH_BIT) {
		if ((ptr[0] << 8 | ptr[1]) != skb->len)
			goto drop;
		ptr += 2;
	}

	/* Skip all fields including optional ones. */
	if (!skb_pull(skb, 6 + (bits & L2TP_SEQUENCE_BIT ? 4 : 0) +
			(bits & L2TP_LENGTH_BIT ? 2 : 0) +
			(bits & L2TP_OFFSET_BIT ? 2 : 0)))
		goto drop;

	/* Skip the offset padding if it is present. */
	if (bits & L2TP_OFFSET_BIT &&
			!skb_pull(skb, skb->data[-2] << 8 | skb->data[-1]))
		goto drop;

	/* Check the tunnel and the session. */
	if (unaligned(ptr)->u32 != opt->local)
		goto drop;

	/* Check the sequence if it is present. */
	if (bits & L2TP_SEQUENCE_BIT) {
		meta->sequence = ptr[4] << 8 | ptr[5];
		if ((__s16)(meta->sequence - opt->recv_sequence) < 0)
			goto drop;
	}

	/* Skip PPP address and control if they are present. */
	if (skb->len >= 2 && skb->data[0] == PPP_ADDR &&
			skb->data[1] == PPP_CTRL)
		skb_pull(skb, 2);

	/* Fix PPP protocol if it is compressed. */
	if (skb->len >= 1 && skb->data[0] & 1)
		skb_push(skb, 1)[0] = 0;

	/* Drop the packet if PPP protocol is missing. */
	if (skb->len < 2)
		goto drop;

	/* Perform reordering if sequencing is enabled. */
	atomic_set(&opt->sequencing, bits & L2TP_SEQUENCE_BIT);
	if (bits & L2TP_SEQUENCE_BIT) {
		struct sk_buff *skb1;

		/* Insert the packet into receive queue in order. */
		skb_set_owner_r(skb, sk);
		skb_queue_walk(&sk->sk_receive_queue, skb1) {
			struct meta *meta1 = skb_meta(skb1);
			__s16 order = meta->sequence - meta1->sequence;
			if (order == 0)
				goto drop;
			if (order < 0) {
				meta->timestamp = meta1->timestamp;
				skb_insert(skb1, skb, &sk->sk_receive_queue);
				skb = NULL;
				break;
			}
		}
		if (skb) {
			meta->timestamp = now;
			skb_queue_tail(&sk->sk_receive_queue, skb);
		}

		/* Remove packets from receive queue as long as
		 * 1. the receive buffer is full,
		 * 2. they are queued longer than one second, or
		 * 3. there are no missing packets before them. */
		skb_queue_walk_safe(&sk->sk_receive_queue, skb, skb1) {
			meta = skb_meta(skb);
			if (atomic_read(&sk->sk_rmem_alloc) < sk->sk_rcvbuf &&
					now - meta->timestamp < HZ &&
					meta->sequence != opt->recv_sequence)
				break;
			skb_unlink(skb, &sk->sk_receive_queue);
			opt->recv_sequence = (__u16)(meta->sequence + 1);
			skb_orphan(skb);
			ppp_input(&pppox_sk(sk)->chan, skb);
		}
		return NET_RX_SUCCESS;
	}

	/* Flush receive queue if sequencing is disabled. */
	skb_queue_purge(&sk->sk_receive_queue);
	skb_orphan(skb);
	ppp_input(&pppox_sk(sk)->chan, skb);
	return NET_RX_SUCCESS;
drop:
	kfree_skb(skb);
	return NET_RX_DROP;
}

static int pppolac_recv(struct sock *sk_udp, struct sk_buff *skb)
{
	sock_hold(sk_udp);
	sk_receive_skb(sk_udp, skb, 0);
	return 0;
}

static struct sk_buff_head delivery_queue;

static void pppolac_xmit_core(struct work_struct *delivery_work)
{
	mm_segment_t old_fs = get_fs();
	struct sk_buff *skb;

	set_fs(KERNEL_DS);
	while ((skb = skb_dequeue(&delivery_queue))) {
		struct sock *sk_udp = skb->sk;
		struct kvec iov = {.iov_base = skb->data, .iov_len = skb->len};
		struct msghdr msg = {
			.msg_iov = (struct iovec *)&iov,
			.msg_iovlen = 1,
			.msg_flags = MSG_NOSIGNAL | MSG_DONTWAIT,
		};
		sk_udp->sk_prot->sendmsg(NULL, sk_udp, &msg, skb->len);
		kfree_skb(skb);
	}
	set_fs(old_fs);
}

static DECLARE_WORK(delivery_work, pppolac_xmit_core);

static int pppolac_xmit(struct ppp_channel *chan, struct sk_buff *skb)
{
	struct sock *sk_udp = (struct sock *)chan->private;
	struct pppolac_opt *opt = &pppox_sk(sk_udp->sk_user_data)->proto.lac;

	/* Install PPP address and control. */
	skb_push(skb, 2);
	skb->data[0] = PPP_ADDR;
	skb->data[1] = PPP_CTRL;

	/* Install L2TP header. */
	if (atomic_read(&opt->sequencing)) {
		skb_push(skb, 10);
		skb->data[0] = L2TP_SEQUENCE_BIT;
		skb->data[6] = opt->xmit_sequence >> 8;
		skb->data[7] = opt->xmit_sequence;
		skb->data[8] = 0;
		skb->data[9] = 0;
		opt->xmit_sequence++;
	} else {
		skb_push(skb, 6);
		skb->data[0] = 0;
	}
	skb->data[1] = L2TP_VERSION;
	unaligned(&skb->data[2])->u32 = opt->remote;

	/* Now send the packet via the delivery queue. */
	skb_set_owner_w(skb, sk_udp);
	skb_queue_tail(&delivery_queue, skb);
	schedule_work(&delivery_work);
	return 1;
}

/******************************************************************************/

static struct ppp_channel_ops pppolac_channel_ops = {
	.start_xmit = pppolac_xmit,
};

static int pppolac_connect(struct socket *sock, struct sockaddr *useraddr,
	int addrlen, int flags)
{
	struct sock *sk = sock->sk;
	struct pppox_sock *po = pppox_sk(sk);
	struct sockaddr_pppolac *addr = (struct sockaddr_pppolac *)useraddr;
	struct socket *sock_udp = NULL;
	struct sock *sk_udp;
	int error;

	if (addrlen != sizeof(struct sockaddr_pppolac) ||
			!addr->local.tunnel || !addr->local.session ||
			!addr->remote.tunnel || !addr->remote.session) {
		return -EINVAL;
	}

	lock_sock(sk);
	error = -EALREADY;
	if (sk->sk_state != PPPOX_NONE)
		goto out;

	sock_udp = sockfd_lookup(addr->udp_socket, &error);
	if (!sock_udp)
		goto out;
	sk_udp = sock_udp->sk;
	lock_sock(sk_udp);

	/* Remove this check when IPv6 supports UDP encapsulation. */
	error = -EAFNOSUPPORT;
	if (sk_udp->sk_family != AF_INET)
		goto out;
	error = -EPROTONOSUPPORT;
	if (sk_udp->sk_protocol != IPPROTO_UDP)
		goto out;
	error = -EDESTADDRREQ;
	if (sk_udp->sk_state != TCP_ESTABLISHED)
		goto out;
	error = -EBUSY;
	if (udp_sk(sk_udp)->encap_type || sk_udp->sk_user_data)
		goto out;
	if (!sk_udp->sk_bound_dev_if) {
		struct dst_entry *dst = sk_dst_get(sk_udp);
		error = -ENODEV;
		if (!dst)
			goto out;
		sk_udp->sk_bound_dev_if = dst->dev->ifindex;
		dst_release(dst);
	}

	po->chan.hdrlen = 12;
	po->chan.private = sk_udp;
	po->chan.ops = &pppolac_channel_ops;
	po->chan.mtu = PPP_MRU - 80;
	po->proto.lac.local = unaligned(&addr->local)->u32;
	po->proto.lac.remote = unaligned(&addr->remote)->u32;
	atomic_set(&po->proto.lac.sequencing, 1);
	po->proto.lac.backlog_rcv = sk_udp->sk_backlog_rcv;

	error = ppp_register_channel(&po->chan);
	if (error)
		goto out;

	sk->sk_state = PPPOX_CONNECTED;
	udp_sk(sk_udp)->encap_type = UDP_ENCAP_L2TPINUDP;
	udp_sk(sk_udp)->encap_rcv = pppolac_recv;
	sk_udp->sk_backlog_rcv = pppolac_recv_core;
	sk_udp->sk_user_data = sk;
out:
	if (sock_udp) {
		release_sock(sk_udp);
		if (error)
			sockfd_put(sock_udp);
	}
	release_sock(sk);
	return error;
}

static int pppolac_release(struct socket *sock)
{
	struct sock *sk = sock->sk;

	if (!sk)
		return 0;

	lock_sock(sk);
	if (sock_flag(sk, SOCK_DEAD)) {
		release_sock(sk);
		return -EBADF;
	}

	if (sk->sk_state != PPPOX_NONE) {
		struct sock *sk_udp = (struct sock *)pppox_sk(sk)->chan.private;
		lock_sock(sk_udp);
		skb_queue_purge(&sk->sk_receive_queue);
		pppox_unbind_sock(sk);
		udp_sk(sk_udp)->encap_type = 0;
		udp_sk(sk_udp)->encap_rcv = NULL;
		sk_udp->sk_backlog_rcv = pppox_sk(sk)->proto.lac.backlog_rcv;
		sk_udp->sk_user_data = NULL;
		release_sock(sk_udp);
		sockfd_put(sk_udp->sk_socket);
	}

	sock_orphan(sk);
	sock->sk = NULL;
	release_sock(sk);
	sock_put(sk);
	return 0;
}

/******************************************************************************/

static struct proto pppolac_proto = {
	.name = "PPPOLAC",
	.owner = THIS_MODULE,
	.obj_size = sizeof(struct pppox_sock),
};

static struct proto_ops pppolac_proto_ops = {
	.family = PF_PPPOX,
	.owner = THIS_MODULE,
	.release = pppolac_release,
	.bind = sock_no_bind,
	.connect = pppolac_connect,
	.socketpair = sock_no_socketpair,
	.accept = sock_no_accept,
	.getname = sock_no_getname,
	.poll = sock_no_poll,
	.ioctl = pppox_ioctl,
	.listen = sock_no_listen,
	.shutdown = sock_no_shutdown,
	.setsockopt = sock_no_setsockopt,
	.getsockopt = sock_no_getsockopt,
	.sendmsg = sock_no_sendmsg,
	.recvmsg = sock_no_recvmsg,
	.mmap = sock_no_mmap,
};

static int pppolac_create(struct net *net, struct socket *sock)
{
	struct sock *sk;

	sk = sk_alloc(net, PF_PPPOX, GFP_KERNEL, &pppolac_proto);
	if (!sk)
		return -ENOMEM;

	sock_init_data(sock, sk);
	sock->state = SS_UNCONNECTED;
	sock->ops = &pppolac_proto_ops;
	sk->sk_protocol = PX_PROTO_OLAC;
	sk->sk_state = PPPOX_NONE;
	return 0;
}

/******************************************************************************/

static struct pppox_proto pppolac_pppox_proto = {
	.create = pppolac_create,
	.owner = THIS_MODULE,
};

static int __init pppolac_init(void)
{
	int error;

	error = proto_register(&pppolac_proto, 0);
	if (error)
		return error;

	error = register_pppox_proto(PX_PROTO_OLAC, &pppolac_pppox_proto);
	if (error)
		proto_unregister(&pppolac_proto);
	else
		skb_queue_head_init(&delivery_queue);
	return error;
}

static void __exit pppolac_exit(void)
{
	unregister_pppox_proto(PX_PROTO_OLAC);
	proto_unregister(&pppolac_proto);
}

module_init(pppolac_init);
module_exit(pppolac_exit);

MODULE_DESCRIPTION("PPP on L2TP Access Concentrator (PPPoLAC)");
MODULE_AUTHOR("Chia-chi Yeh <chiachi@android.com>");
MODULE_LICENSE("GPL");
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 /******************************************************************************
 *
 * Copyright(c) 2012  Realtek Corporation.
 *
 * This program is free software; you can redistribute it and/or modify it
 * under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation.
 *
 * This program is distributed in the hope that it will be useful, but WITHOUT
 * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
 * more details.
 *
 * The full GNU General Public License is included in this distribution in the
 * file called LICENSE.
 *
 * Contact Information:
 * wlanfae <wlanfae@realtek.com>
 * Realtek Corporation, No. 2, Innovation Road II, Hsinchu Science Park,
 * Hsinchu 300, Taiwan.
 *
 * Larry Finger <Larry.Finger@lwfinger.net>
 *
 *****************************************************************************/
/**********************************************************************
 * The following is for 8723B 1ANT BT Co-exist definition
 **********************************************************************/
#define	BT_AUTO_REPORT_ONLY_8723B_1ANT			1

#define	BT_INFO_8723B_1ANT_B_FTP			BIT7
#define	BT_INFO_8723B_1ANT_B_A2DP			BIT6
#define	BT_INFO_8723B_1ANT_B_HID			BIT5
#define	BT_INFO_8723B_1ANT_B_SCO_BUSY			BIT4
#define	BT_INFO_8723B_1ANT_B_ACL_BUSY			BIT3
#define	BT_INFO_8723B_1ANT_B_INQ_PAGE			BIT2
#define	BT_INFO_8723B_1ANT_B_SCO_ESCO			BIT1
#define	BT_INFO_8723B_1ANT_B_CONNECTION			BIT0

#define	BT_INFO_8723B_1ANT_A2DP_BASIC_RATE(_BT_INFO_EXT_)	\
		(((_BT_INFO_EXT_&BIT0)) ? true : false)

#define	BTC_RSSI_COEX_THRESH_TOL_8723B_1ANT		2

enum _BT_INFO_SRC_8723B_1ANT {
	BT_INFO_SRC_8723B_1ANT_WIFI_FW			= 0x0,
	BT_INFO_SRC_8723B_1ANT_BT_RSP			= 0x1,
	BT_INFO_SRC_8723B_1ANT_BT_ACTIVE_SEND		= 0x2,
	BT_INFO_SRC_8723B_1ANT_MAX
};

enum _BT_8723B_1ANT_BT_STATUS {
	BT_8723B_1ANT_BT_STATUS_NON_CONNECTED_IDLE	= 0x0,
	BT_8723B_1ANT_BT_STATUS_CONNECTED_IDLE		= 0x1,
	BT_8723B_1ANT_BT_STATUS_INQ_PAGE		= 0x2,
	BT_8723B_1ANT_BT_STATUS_ACL_BUSY		= 0x3,
	BT_8723B_1ANT_BT_STATUS_SCO_BUSY		= 0x4,
	BT_8723B_1ANT_BT_STATUS_ACL_SCO_BUSY		= 0x5,
	BT_8723B_1ANT_BT_STATUS_MAX
};

enum _BT_8723B_1ANT_WIFI_STATUS {
	BT_8723B_1ANT_WIFI_STATUS_NON_CONNECTED_IDLE			= 0x0,
	BT_8723B_1ANT_WIFI_STATUS_NON_CONNECTED_ASSO_AUTH_SCAN		= 0x1,
	BT_8723B_1ANT_WIFI_STATUS_CONNECTED_SCAN			= 0x2,
	BT_8723B_1ANT_WIFI_STATUS_CONNECTED_SPECIAL_PKT			= 0x3,
	BT_8723B_1ANT_WIFI_STATUS_CONNECTED_IDLE			= 0x4,
	BT_8723B_1ANT_WIFI_STATUS_CONNECTED_BUSY			= 0x5,
	BT_8723B_1ANT_WIFI_STATUS_MAX
};

enum _BT_8723B_1ANT_COEX_ALGO {
	BT_8723B_1ANT_COEX_ALGO_UNDEFINED		= 0x0,
	BT_8723B_1ANT_COEX_ALGO_SCO			= 0x1,
	BT_8723B_1ANT_COEX_ALGO_HID			= 0x2,
	BT_8723B_1ANT_COEX_ALGO_A2DP			= 0x3,
	BT_8723B_1ANT_COEX_ALGO_A2DP_PANHS		= 0x4,
	BT_8723B_1ANT_COEX_ALGO_PANEDR			= 0x5,
	BT_8723B_1ANT_COEX_ALGO_PANHS			= 0x6,
	BT_8723B_1ANT_COEX_ALGO_PANEDR_A2DP		= 0x7,
	BT_8723B_1ANT_COEX_ALGO_PANEDR_HID		= 0x8,
	BT_8723B_1ANT_COEX_ALGO_HID_A2DP_PANEDR		= 0x9,
	BT_8723B_1ANT_COEX_ALGO_HID_A2DP		= 0xa,
	BT_8723B_1ANT_COEX_ALGO_MAX			= 0xb,
};

struct coex_dm_8723b_1ant {
	/* fw mechanism */
	bool cur_ignore_wlan_act;
	bool pre_ignore_wlan_act;
	u8 pre_ps_tdma;
	u8 cur_ps_tdma;
	u8 ps_tdma_para[5];
	u8 tdma_adj_type;
	bool auto_tdma_adjust;
	bool pre_ps_tdma_on;
	bool cur_ps_tdma_on;
	bool pre_bt_auto_report;
	bool cur_bt_auto_report;
	u8 pre_lps;
	u8 cur_lps;
	u8 pre_rpwm;
	u8 cur_rpwm;

	/* sw mechanism */
	bool pre_low_penalty_ra;
	bool cur_low_penalty_ra;
	u32 pre_val0x6c0;
	u32 cur_val0x6c0;
	u32 pre_val0x6c4;
	u32 cur_val0x6c4;
	u32 pre_val0x6c8;
	u32 cur_val0x6c8;
	u8 pre_val0x6cc;
	u8 cur_val0x6cc;
	bool limited_dig;

	u32 backup_arfr_cnt1;	/* Auto Rate Fallback Retry cnt */
	u32 backup_arfr_cnt2;	/* Auto Rate Fallback Retry cnt */
	u16 backup_retry_limit;
	u8 backup_ampdu_max_time;

	/* algorithm related */
	u8 pre_algorithm;
	u8 cur_algorithm;
	u8 bt_status;
	u8 wifi_chnl_info[3];

	u32 prera_mask;
	u32 curra_mask;
	u8 pre_arfr_type;
	u8 cur_arfr_type;
	u8 pre_retry_limit_type;
	u8 cur_retry_limit_type;
	u8 pre_ampdu_time_type;
	u8 cur_ampdu_time_type;

	u8 error_condition;
};

struct coex_sta_8723b_1ant {
	bool bt_link_exist;
	bool sco_exist;
	bool a2dp_exist;
	bool hid_exist;
	bool pan_exist;

	bool under_lps;
	bool under_ips;
	u32 special_pkt_period_cnt;
	u32 high_priority_tx;
	u32 high_priority_rx;
	u32 low_priority_tx;
	u32 low_priority_rx;
	u8 bt_rssi;
	u8 pre_bt_rssi_state;
	u8 pre_wifi_rssi_state[4];
	bool c2h_bt_info_req_sent;
	u8 bt_info_c2h[BT_INFO_SRC_8723B_1ANT_MAX][10];
	u32 bt_info_c2h_cnt[BT_INFO_SRC_8723B_1ANT_MAX];
	bool c2h_bt_inquiry_page;
	u8 bt_retry_cnt;
	u8 bt_info_ext;
};

/*************************************************************************
 * The following is interface which will notify coex module.
 *************************************************************************/
void ex_halbtc8723b1ant_init_hwconfig(struct btc_coexist *btcoexist);
void ex_halbtc8723b1ant_init_coex_dm(struct btc_coexist *btcoexist);
void ex_halbtc8723b1ant_ips_notify(struct btc_coexist *btcoexist, u8 type);
void ex_halbtc8723b1ant_lps_notify(struct btc_coexist *btcoexist, u8 type);
void ex_halbtc8723b1ant_scan_notify(struct btc_coexist *btcoexist, u8 type);
void ex_halbtc8723b1ant_connect_notify(struct btc_coexist *btcoexist, u8 type);
void ex_halbtc8723b1ant_media_status_notify(struct btc_coexist *btcoexist,
					    u8 type);
void ex_halbtc8723b1ant_special_packet_notify(struct btc_coexist *btcoexist,
					      u8 type);
void ex_halbtc8723b1ant_bt_info_notify(struct btc_coexist *btcoexist,
				       u8 *tmpbuf, u8 length);
void ex_halbtc8723b1ant_halt_notify(struct btc_coexist *btcoexist);
void ex_halbtc8723b1ant_pnp_notify(struct btc_coexist *btcoexist, u8 pnpstate);
void ex_halbtc8723b1ant_coex_dm_reset(struct btc_coexist *btcoexist);
void ex_halbtc8723b1ant_periodical(struct btc_coexist *btcoexist);
void ex_halbtc8723b1ant_display_coex_info(struct btc_coexist *btcoexist);
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               /*
 * Copyright (C) 2011-2013 Freescale Semiconductor, Inc. All Rights Reserved.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program; if not, write to the Free Software
 * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
 */
#include <linux/kernel.h>
#include <linux/module.h>
#include <linux/init.h>
#include <linux/err.h>
#include <linux/of.h>
#include <linux/of_device.h>
#include <linux/regulator/of_regulator.h>
#include <linux/platform_device.h>
#include <linux/regulator/driver.h>
#include <linux/regulator/machine.h>
#include <linux/regulator/pfuze100.h>
#include <linux/i2c.h>
#include <linux/slab.h>
#include <linux/regmap.h>

#define PFUZE_NUMREGS		128
#define PFUZE100_VOL_OFFSET	0
#define PFUZE100_STANDBY_OFFSET	1
#define PFUZE100_MODE_OFFSET	3
#define PFUZE100_CONF_OFFSET	4

#define PFUZE100_DEVICEID	0x0
#define PFUZE100_REVID		0x3
#define PFUZE100_FABID		0x4

#define PFUZE100_SW1ABVOL	0x20
#define PFUZE100_SW1CVOL	0x2e
#define PFUZE100_SW2VOL		0x35
#define PFUZE100_SW3AVOL	0x3c
#define PFUZE100_SW3BVOL	0x43
#define PFUZE100_SW4VOL		0x4a
#define PFUZE100_SWBSTCON1	0x66
#define PFUZE100_VREFDDRCON	0x6a
#define PFUZE100_VSNVSVOL	0x6b
#define PFUZE100_VGEN1VOL	0x6c
#define PFUZE100_VGEN2VOL	0x6d
#define PFUZE100_VGEN3VOL	0x6e
#define PFUZE100_VGEN4VOL	0x6f
#define PFUZE100_VGEN5VOL	0x70
#define PFUZE100_VGEN6VOL	0x71

enum chips { PFUZE100, PFUZE200 };

struct pfuze_regulator {
	struct regulator_desc desc;
	unsigned char stby_reg;
	unsigned char stby_mask;
};

struct pfuze_chip {
	int	chip_id;
	struct regmap *regmap;
	struct device *dev;
	struct pfuze_regulator regulator_descs[PFUZE100_MAX_REGULATOR];
	struct regulator_dev *regulators[PFUZE100_MAX_REGULATOR];
};

static const int pfuze100_swbst[] = {
	5000000, 5050000, 5100000, 5150000,
};

static const int pfuze100_vsnvs[] = {
	1000000, 1100000, 1200000, 1300000, 1500000, 1800000, 3000000,
};

static const struct i2c_device_id pfuze_device_id[] = {
	{.name = "pfuze100", .driver_data = PFUZE100},
	{.name = "pfuze200", .driver_data = PFUZE200},
	{ }
};
MODULE_DEVICE_TABLE(i2c, pfuze_device_id);

static const struct of_device_id pfuze_dt_ids[] = {
	{ .compatible = "fsl,pfuze100", .data = (void *)PFUZE100},
	{ .compatible = "fsl,pfuze200", .data = (void *)PFUZE200},
	{ }
};
MODULE_DEVICE_TABLE(of, pfuze_dt_ids);

static int pfuze100_set_ramp_delay(struct regulator_dev *rdev, int ramp_delay)
{
	struct pfuze_chip *pfuze100 = rdev_get_drvdata(rdev);
	int id = rdev_get_id(rdev);
	unsigned int ramp_bits;
	int ret;

	if (id < PFUZE100_SWBST) {
		ramp_delay = 12500 / ramp_delay;
		ramp_bits = (ramp_delay >> 1) - (ramp_delay >> 3);
		ret = regmap_update_bits(pfuze100->regmap,
					 rdev->desc->vsel_reg + 4,
					 0xc0, ramp_bits << 6);
		if (ret < 0)
			dev_err(pfuze100->dev, "ramp failed, err %d\n", ret);
	} else
		ret = -EACCES;

	return ret;
}

static struct regulator_ops pfuze100_ldo_regulator_ops = {
	.enable = regulator_enable_regmap,
	.disable = regulator_disable_regmap,
	.is_enabled = regulator_is_enabled_regmap,
	.list_voltage = regulator_list_voltage_linear,
	.set_voltage_sel = regulator_set_voltage_sel_regmap,
	.get_voltage_sel = regulator_get_voltage_sel_regmap,
};

static struct regulator_ops pfuze100_fixed_regulator_ops = {
	.enable = regulator_enable_regmap,
	.disable = regulator_disable_regmap,
	.is_enabled = regulator_is_enabled_regmap,
	.list_voltage = regulator_list_voltage_linear,
};

static struct regulator_ops pfuze100_sw_regulator_ops = {
	.list_voltage = regulator_list_voltage_linear,
	.set_voltage_sel = regulator_set_voltage_sel_regmap,
	.get_voltage_sel = regulator_get_voltage_sel_regmap,
	.set_voltage_time_sel = regulator_set_voltage_time_sel,
	.set_ramp_delay = pfuze100_set_ramp_delay,
};

static struct regulator_ops pfuze100_swb_regulator_ops = {
	.enable = regulator_enable_regmap,
	.disable = regulator_disable_regmap,
	.is_enabled = regulator_is_enabled_regmap,
	.list_voltage = regulator_list_voltage_table,
	.map_voltage = regulator_map_voltage_ascend,
	.set_voltage_sel = regulator_set_voltage_sel_regmap,
	.get_voltage_sel = regulator_get_voltage_sel_regmap,

};

#define PFUZE100_FIXED_REG(_chip, _name, base, voltage)	\
	[_chip ## _ ## _name] = {	\
		.desc = {	\
			.name = #_name,	\
			.n_voltages = 1,	\
			.ops = &pfuze100_fixed_regulator_ops,	\
			.type = REGULATOR_VOLTAGE,	\
			.id = _chip ## _ ## _name,	\
			.owner = THIS_MODULE,	\
			.min_uV = (voltage),	\
			.enable_reg = (base),	\
			.enable_mask = 0x10,	\
		},	\
	}

#define PFUZE100_SW_REG(_chip, _name, base, min, max, step)	\
	[_chip ## _ ## _name] = {	\
		.desc = {	\
			.name = #_name,\
			.n_voltages = ((max) - (min)) / (step) + 1,	\
			.ops = &pfuze100_sw_regulator_ops,	\
			.type = REGULATOR_VOLTAGE,	\
			.id = _chip ## _ ## _name,	\
			.owner = THIS_MODULE,	\
			.min_uV = (min),	\
			.uV_step = (step),	\
			.vsel_reg = (base) + PFUZE100_VOL_OFFSET,	\
			.vsel_mask = 0x3f,	\
		},	\
		.stby_reg = (base) + PFUZE100_STANDBY_OFFSET,	\
		.stby_mask = 0x3f,	\
	}

#define PFUZE100_SWB_REG(_chip, _name, base, mask, voltages)	\
	[_chip ## _ ##  _name] = {	\
		.desc = {	\
			.name = #_name,	\
			.n_voltages = ARRAY_SIZE(voltages),	\
			.ops = &pfuze100_swb_regulator_ops,	\
			.type = REGULATOR_VOLTAGE,	\
			.id = _chip ## _ ## _name,	\
			.owner = THIS_MODULE,	\
			.volt_table = voltages,	\
			.vsel_reg = (base),	\
			.vsel_mask = (mask),	\
			.enable_reg = (base),	\
			.enable_mask = 0x48,	\
		},	\
	}

#define PFUZE100_VGEN_REG(_chip, _name, base, min, max, step)	\
	[_chip ## _ ## _name] = {	\
		.desc = {	\
			.name = #_name,	\
			.n_voltages = ((max) - (min)) / (step) + 1,	\
			.ops = &pfuze100_ldo_regulator_ops,	\
			.type = REGULATOR_VOLTAGE,	\
			.id = _chip ## _ ## _name,	\
			.owner = THIS_MODULE,	\
			.min_uV = (min),	\
			.uV_step = (step),	\
			.vsel_reg = (base),	\
			.vsel_mask = 0xf,	\
			.enable_reg = (base),	\
			.enable_mask = 0x10,	\
		},	\
		.stby_reg = (base),	\
		.stby_mask = 0x20,	\
	}

/* PFUZE100 */
static struct pfuze_regulator pfuze100_regulators[] = {
	PFUZE100_SW_REG(PFUZE100, SW1AB, PFUZE100_SW1ABVOL, 300000, 1875000, 25000),
	PFUZE100_SW_REG(PFUZE100, SW1C, PFUZE100_SW1CVOL, 300000, 1875000, 25000),
	PFUZE100_SW_REG(PFUZE100, SW2, PFUZE100_SW2VOL, 400000, 1975000, 25000),
	PFUZE100_SW_REG(PFUZE100, SW3A, PFUZE100_SW3AVOL, 400000, 1975000, 25000),
	PFUZE100_SW_REG(PFUZE100, SW3B, PFUZE100_SW3BVOL, 400000, 1975000, 25000),
	PFUZE100_SW_REG(PFUZE100, SW4, PFUZE100_SW4VOL, 400000, 1975000, 25000),
	PFUZE100_SWB_REG(PFUZE100, SWBST, PFUZE100_SWBSTCON1, 0x3 , pfuze100_swbst),
	PFUZE100_SWB_REG(PFUZE100, VSNVS, PFUZE100_VSNVSVOL, 0x7, pfuze100_vsnvs),
	PFUZE100_FIXED_REG(PFUZE100, VREFDDR, PFUZE100_VREFDDRCON, 750000),
	PFUZE100_VGEN_REG(PFUZE100, VGEN1, PFUZE100_VGEN1VOL, 800000, 1550000, 50000),
	PFUZE100_VGEN_REG(PFUZE100, VGEN2, PFUZE100_VGEN2VOL, 800000, 1550000, 50000),
	PFUZE100_VGEN_REG(PFUZE100, VGEN3, PFUZE100_VGEN3VOL, 1800000, 3300000, 100000),
	PFUZE100_VGEN_REG(PFUZE100, VGEN4, PFUZE100_VGEN4VOL, 1800000, 3300000, 100000),
	PFUZE100_VGEN_REG(PFUZE100, VGEN5, PFUZE100_VGEN5VOL, 1800000, 3300000, 100000),
	PFUZE100_VGEN_REG(PFUZE100, VGEN6, PFUZE100_VGEN6VOL, 1800000, 3300000, 100000),
};

static struct pfuze_regulator pfuze200_regulators[] = {
	PFUZE100_SW_REG(PFUZE200, SW1AB, PFUZE100_SW1ABVOL, 300000, 1875000, 25000),
	PFUZE100_SW_REG(PFUZE200, SW2, PFUZE100_SW2VOL, 400000, 1975000, 25000),
	PFUZE100_SW_REG(PFUZE200, SW3A, PFUZE100_SW3AVOL, 400000, 1975000, 25000),
	PFUZE100_SW_REG(PFUZE200, SW3B, PFUZE100_SW3BVOL, 400000, 1975000, 25000),
	PFUZE100_SWB_REG(PFUZE200, SWBST, PFUZE100_SWBSTCON1, 0x3 , pfuze100_swbst),
	PFUZE100_SWB_REG(PFUZE200, VSNVS, PFUZE100_VSNVSVOL, 0x7, pfuze100_vsnvs),
	PFUZE100_FIXED_REG(PFUZE200, VREFDDR, PFUZE100_VREFDDRCON, 750000),
	PFUZE100_VGEN_REG(PFUZE200, VGEN1, PFUZE100_VGEN1VOL, 800000, 1550000, 50000),
	PFUZE100_VGEN_REG(PFUZE200, VGEN2, PFUZE100_VGEN2VOL, 800000, 1550000, 50000),
	PFUZE100_VGEN_REG(PFUZE200, VGEN3, PFUZE100_VGEN3VOL, 1800000, 3300000, 100000),
	PFUZE100_VGEN_REG(PFUZE200, VGEN4, PFUZE100_VGEN4VOL, 1800000, 3300000, 100000),
	PFUZE100_VGEN_REG(PFUZE200, VGEN5, PFUZE100_VGEN5VOL, 1800000, 3300000, 100000),
	PFUZE100_VGEN_REG(PFUZE200, VGEN6, PFUZE100_VGEN6VOL, 1800000, 3300000, 100000),
};

static struct pfuze_regulator *pfuze_regulators;

#ifdef CONFIG_OF
/* PFUZE100 */
static struct of_regulator_match pfuze100_matches[] = {
	{ .name = "sw1ab",	},
	{ .name = "sw1c",	},
	{ .name = "sw2",	},
	{ .name = "sw3a",	},
	{ .name = "sw3b",	},
	{ .name = "sw4",	},
	{ .name = "swbst",	},
	{ .name = "vsnvs",	},
	{ .name = "vrefddr",	},
	{ .name = "vgen1",	},
	{ .name = "vgen2",	},
	{ .name = "vgen3",	},
	{ .name = "vgen4",	},
	{ .name = "vgen5",	},
	{ .name = "vgen6",	},
};

/* PFUZE200 */
static struct of_regulator_match pfuze200_matches[] = {

	{ .name = "sw1ab",	},
	{ .name = "sw2",	},
	{ .name = "sw3a",	},
	{ .name = "sw3b",	},
	{ .name = "swbst",	},
	{ .name = "vsnvs",	},
	{ .name = "vrefddr",	},
	{ .name = "vgen1",	},
	{ .name = "vgen2",	},
	{ .name = "vgen3",	},
	{ .name = "vgen4",	},
	{ .name = "vgen5",	},
	{ .name = "vgen6",	},
};

static struct of_regulator_match *pfuze_matches;

static int pfuze_parse_regulators_dt(struct pfuze_chip *chip)
{
	struct device *dev = chip->dev;
	struct device_node *np, *parent;
	int ret;

	np = of_node_get(dev->of_node);
	if (!np)
		return -EINVAL;

	parent = of_get_child_by_name(np, "regulators");
	if (!parent) {
		dev_err(dev, "regulators node not found\n");
		return -EINVAL;
	}

	switch (chip->chip_id) {
	case PFUZE200:
		pfuze_matches = pfuze200_matches;
		ret = of_regulator_match(dev, parent, pfuze200_matches,
					 ARRAY_SIZE(pfuze200_matches));
		break;

	case PFUZE100:
	default:
		pfuze_matches = pfuze100_matches;
		ret = of_regulator_match(dev, parent, pfuze100_matches,
					 ARRAY_SIZE(pfuze100_matches));
		break;
	}

	of_node_put(parent);
	if (ret < 0) {
		dev_err(dev, "Error parsing regulator init data: %d\n",
			ret);
		return ret;
	}

	return 0;
}

static inline struct regulator_init_data *match_init_data(int index)
{
	return pfuze_matches[index].init_data;
}

static inline struct device_node *match_of_node(int index)
{
	return pfuze_matches[index].of_node;
}
#else
static int pfuze_parse_regulators_dt(struct pfuze_chip *chip)
{
	return 0;
}

static inline struct regulator_init_data *match_init_data(int index)
{
	return NULL;
}

static inline struct device_node *match_of_node(int index)
{
	return NULL;
}
#endif

static int pfuze_identify(struct pfuze_chip *pfuze_chip)
{
	unsigned int value;
	int ret;

	ret = regmap_read(pfuze_chip->regmap, PFUZE100_DEVICEID, &value);
	if (ret)
		return ret;

	if (((value & 0x0f) == 0x8) && (pfuze_chip->chip_id == PFUZE100)) {
		/*
		 * Freescale misprogrammed 1-3% of parts prior to week 8 of 2013
		 * as ID=8 in PFUZE100
		 */
		dev_info(pfuze_chip->dev, "Assuming misprogrammed ID=0x8");
	} else if ((value & 0x0f) != pfuze_chip->chip_id) {
		/* device id NOT match with your setting */
		dev_warn(pfuze_chip->dev, "Illegal ID: %x\n", value);
		return -ENODEV;
	}

	ret = regmap_read(pfuze_chip->regmap, PFUZE100_REVID, &value);
	if (ret)
		return ret;
	dev_info(pfuze_chip->dev,
		 "Full layer: %x, Metal layer: %x\n",
		 (value & 0xf0) >> 4, value & 0x0f);

	ret = regmap_read(pfuze_chip->regmap, PFUZE100_FABID, &value);
	if (ret)
		return ret;
	dev_info(pfuze_chip->dev, "FAB: %x, FIN: %x\n",
		 (value & 0xc) >> 2, value & 0x3);

	return 0;
}

static const struct regmap_config pfuze_regmap_config = {
	.reg_bits = 8,
	.val_bits = 8,
	.max_register = PFUZE_NUMREGS - 1,
	.cache_type = REGCACHE_RBTREE,
};

static int pfuze100_regulator_probe(struct i2c_client *client,
				    const struct i2c_device_id *id)
{
	struct pfuze_chip *pfuze_chip;
	struct pfuze_regulator_platform_data *pdata =
	    dev_get_platdata(&client->dev);
	struct regulator_config config = { };
	int i, ret;
	const struct of_device_id *match;
	u32 regulator_num;
	u32 sw_check_start, sw_check_end;

	pfuze_chip = devm_kzalloc(&client->dev, sizeof(*pfuze_chip),
			GFP_KERNEL);
	if (!pfuze_chip)
		return -ENOMEM;

	if (client->dev.of_node) {
		match = of_match_device(of_match_ptr(pfuze_dt_ids),
				&client->dev);
		if (!match) {
			dev_err(&client->dev, "Error: No device match found\n");
			return -ENODEV;
		}
		pfuze_chip->chip_id = (int)(long)match->data;
	} else if (id) {
		pfuze_chip->chip_id = id->driver_data;
	} else {
		dev_err(&client->dev, "No dts match or id table match found\n");
		return -ENODEV;
	}

	i2c_set_clientdata(client, pfuze_chip);
	pfuze_chip->dev = &client->dev;

	pfuze_chip->regmap = devm_regmap_init_i2c(client, &pfuze_regmap_config);
	if (IS_ERR(pfuze_chip->regmap)) {
		ret = PTR_ERR(pfuze_chip->regmap);
		dev_err(&client->dev,
			"regmap allocation failed with err %d\n", ret);
		return ret;
	}

	ret = pfuze_identify(pfuze_chip);
	if (ret) {
		dev_err(&client->dev, "unrecognized pfuze chip ID!\n");
		return ret;
	}

	/* use the right regulators after identify the right device */
	switch (pfuze_chip->chip_id) {
	case PFUZE200:
		pfuze_regulators = pfuze200_regulators;
		regulator_num = ARRAY_SIZE(pfuze200_regulators);
		sw_check_start = PFUZE200_SW2;
		sw_check_end = PFUZE200_SW3B;
		break;

	case PFUZE100:
	default:
		pfuze_regulators = pfuze100_regulators;
		regulator_num = ARRAY_SIZE(pfuze100_regulators);
		sw_check_start = PFUZE100_SW2;
		sw_check_end = PFUZE100_SW4;
		break;
	}
	dev_info(&client->dev, "pfuze%s found.\n",
		(pfuze_chip->chip_id == PFUZE100) ? "100" : "200");

	memcpy(pfuze_chip->regulator_descs, pfuze_regulators,
		sizeof(pfuze_chip->regulator_descs));

	ret = pfuze_parse_regulators_dt(pfuze_chip);
	if (ret)
		return ret;

	for (i = 0; i < regulator_num; i++) {
		struct regulator_init_data *init_data;
		struct regulator_desc *desc;
		int val;

		desc = &pfuze_chip->regulator_descs[i].desc;

		if (pdata)
			init_data = pdata->init_data[i];
		else
			init_data = match_init_data(i);

		/* SW2~SW4 high bit check and modify the voltage value table */
		if (i >= sw_check_start && i <= sw_check_end) {
			regmap_read(pfuze_chip->regmap, desc->vsel_reg, &val);
			if (val & 0x40) {
				desc->min_uV = 800000;
				desc->uV_step = 50000;
				desc->n_voltages = 51;
			}
		}

		config.dev = &client->dev;
		config.init_data = init_data;
		config.driver_data = pfuze_chip;
		config.of_node = match_of_node(i);
		config.ena_gpio = -EINVAL;

		pfuze_chip->regulators[i] =
			devm_regulator_register(&client->dev, desc, &config);
		if (IS_ERR(pfuze_chip->regulators[i])) {
			dev_err(&client->dev, "register regulator%s failed\n",
				pfuze_regulators[i].desc.name);
			return PTR_ERR(pfuze_chip->regulators[i]);
		}
	}

	return 0;
}

static struct i2c_driver pfuze_driver = {
	.id_table = pfuze_device_id,
	.driver = {
		.name = "pfuze100-regulator",
		.owner = THIS_MODULE,
		.of_match_table = pfuze_dt_ids,
	},
	.probe = pfuze100_regulator_probe,
};
module_i2c_driver(pfuze_driver);

MODULE_AUTHOR("Robin Gong <b38343@freescale.com>");
MODULE_DESCRIPTION("Regulator Driver for Freescale PFUZE100/PFUZE200 PMIC");
MODULE_LICENSE("GPL v2");
MODULE_ALIAS("i2c:pfuze100-regulator");
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   /*
 * Sonics Silicon Backplane
 * Broadcom MIPS core driver
 *
 * Copyright 2005, Broadcom Corporation
 * Copyright 2006, 2007, Michael Buesch <m@bues.ch>
 *
 * Licensed under the GNU/GPL. See COPYING for details.
 */

#include <linux/ssb/ssb.h>

#include <linux/mtd/physmap.h>
#include <linux/serial.h>
#include <linux/serial_core.h>
#include <linux/serial_reg.h>
#include <linux/time.h>

#include "ssb_private.h"

static const char * const part_probes[] = { "bcm47xxpart", NULL };

static struct physmap_flash_data ssb_pflash_data = {
	.part_probe_types	= part_probes,
};

static struct resource ssb_pflash_resource = {
	.name	= "ssb_pflash",
	.flags  = IORESOURCE_MEM,
};

struct platform_device ssb_pflash_dev = {
	.name		= "physmap-flash",
	.dev		= {
		.platform_data  = &ssb_pflash_data,
	},
	.resource	= &ssb_pflash_resource,
	.num_resources	= 1,
};

static inline u32 mips_read32(struct ssb_mipscore *mcore,
			      u16 offset)
{
	return ssb_read32(mcore->dev, offset);
}

static inline void mips_write32(struct ssb_mipscore *mcore,
				u16 offset,
				u32 value)
{
	ssb_write32(mcore->dev, offset, value);
}

static const u32 ipsflag_irq_mask[] = {
	0,
	SSB_IPSFLAG_IRQ1,
	SSB_IPSFLAG_IRQ2,
	SSB_IPSFLAG_IRQ3,
	SSB_IPSFLAG_IRQ4,
};

static const u32 ipsflag_irq_shift[] = {
	0,
	SSB_IPSFLAG_IRQ1_SHIFT,
	SSB_IPSFLAG_IRQ2_SHIFT,
	SSB_IPSFLAG_IRQ3_SHIFT,
	SSB_IPSFLAG_IRQ4_SHIFT,
};

static inline u32 ssb_irqflag(struct ssb_device *dev)
{
	u32 tpsflag = ssb_read32(dev, SSB_TPSFLAG);
	if (tpsflag)
		return ssb_read32(dev, SSB_TPSFLAG) & SSB_TPSFLAG_BPFLAG;
	else
		/* not irq supported */
		return 0x3f;
}

static struct ssb_device *find_device(struct ssb_device *rdev, int irqflag)
{
	struct ssb_bus *bus = rdev->bus;
	int i;
	for (i = 0; i < bus->nr_devices; i++) {
		struct ssb_device *dev;
		dev = &(bus->devices[i]);
		if (ssb_irqflag(dev) == irqflag)
			return dev;
	}
	return NULL;
}

/* Get the MIPS IRQ assignment for a specified device.
 * If unassigned, 0 is returned.
 * If disabled, 5 is returned.
 * If not supported, 6 is returned.
 */
unsigned int ssb_mips_irq(struct ssb_device *dev)
{
	struct ssb_bus *bus = dev->bus;
	struct ssb_device *mdev = bus->mipscore.dev;
	u32 irqflag;
	u32 ipsflag;
	u32 tmp;
	unsigned int irq;

	irqflag = ssb_irqflag(dev);
	if (irqflag == 0x3f)
		return 6;
	ipsflag = ssb_read32(bus->mipscore.dev, SSB_IPSFLAG);
	for (irq = 1; irq <= 4; irq++) {
		tmp = ((ipsflag & ipsflag_irq_mask[irq]) >> ipsflag_irq_shift[irq]);
		if (tmp == irqflag)
			break;
	}
	if (irq	== 5) {
		if ((1 << irqflag) & ssb_read32(mdev, SSB_INTVEC))
			irq = 0;
	}

	return irq;
}

static void clear_irq(struct ssb_bus *bus, unsigned int irq)
{
	struct ssb_device *dev = bus->mipscore.dev;

	/* Clear the IRQ in the MIPScore backplane registers */
	if (irq == 0) {
		ssb_write32(dev, SSB_INTVEC, 0);
	} else {
		ssb_write32(dev, SSB_IPSFLAG,
			    ssb_read32(dev, SSB_IPSFLAG) |
			    ipsflag_irq_mask[irq]);
	}
}

static void set_irq(struct ssb_device *dev, unsigned int irq)
{
	unsigned int oldirq = ssb_mips_irq(dev);
	struct ssb_bus *bus = dev->bus;
	struct ssb_device *mdev = bus->mipscore.dev;
	u32 irqflag = ssb_irqflag(dev);

	BUG_ON(oldirq == 6);

	dev->irq = irq + 2;

	/* clear the old irq */
	if (oldirq == 0)
		ssb_write32(mdev, SSB_INTVEC, (~(1 << irqflag) & ssb_read32(mdev, SSB_INTVEC)));
	else if (oldirq != 5)
		clear_irq(bus, oldirq);

	/* assign the new one */
	if (irq == 0) {
		ssb_write32(mdev, SSB_INTVEC, ((1 << irqflag) | ssb_read32(mdev, SSB_INTVEC)));
	} else {
		u32 ipsflag = ssb_read32(mdev, SSB_IPSFLAG);
		if ((ipsflag & ipsflag_irq_mask[irq]) != ipsflag_irq_mask[irq]) {
			u32 oldipsflag = (ipsflag & ipsflag_irq_mask[irq]) >> ipsflag_irq_shift[irq];
			struct ssb_device *olddev = find_device(dev, oldipsflag);
			if (olddev)
				set_irq(olddev, 0);
		}
		irqflag <<= ipsflag_irq_shift[irq];
		irqflag |= (ipsflag & ~ipsflag_irq_mask[irq]);
		ssb_write32(mdev, SSB_IPSFLAG, irqflag);
	}
	ssb_dbg("set_irq: core 0x%04x, irq %d => %d\n",
		dev->id.coreid, oldirq+2, irq+2);
}

static void print_irq(struct ssb_device *dev, unsigned int irq)
{
	static const char *irq_name[] = {"2(S)", "3", "4", "5", "6", "D", "I"};
	ssb_dbg("core 0x%04x, irq : %s%s %s%s %s%s %s%s %s%s %s%s %s%s\n",
		dev->id.coreid,
		irq_name[0], irq == 0 ? "*" : " ",
		irq_name[1], irq == 1 ? "*" : " ",
		irq_name[2], irq == 2 ? "*" : " ",
		irq_name[3], irq == 3 ? "*" : " ",
		irq_name[4], irq == 4 ? "*" : " ",
		irq_name[5], irq == 5 ? "*" : " ",
		irq_name[6], irq == 6 ? "*" : " ");
}

static void dump_irq(struct ssb_bus *bus)
{
	int i;
	for (i = 0; i < bus->nr_devices; i++) {
		struct ssb_device *dev;
		dev = &(bus->devices[i]);
		print_irq(dev, ssb_mips_irq(dev));
	}
}

static void ssb_mips_serial_init(struct ssb_mipscore *mcore)
{
	struct ssb_bus *bus = mcore->dev->bus;

	if (ssb_extif_available(&bus->extif))
		mcore->nr_serial_ports = ssb_extif_serial_init(&bus->extif, mcore->serial_ports);
	else if (ssb_chipco_available(&bus->chipco))
		mcore->nr_serial_ports = ssb_chipco_serial_init(&bus->chipco, mcore->serial_ports);
	else
		mcore->nr_serial_ports = 0;
}

static void ssb_mips_flash_detect(struct ssb_mipscore *mcore)
{
	struct ssb_bus *bus = mcore->dev->bus;
	struct ssb_pflash *pflash = &mcore->pflash;

	/* When there is no chipcommon on the bus there is 4MB flash */
	if (!ssb_chipco_available(&bus->chipco)) {
		pflash->present = true;
		pflash->buswidth = 2;
		pflash->window = SSB_FLASH1;
		pflash->window_size = SSB_FLASH1_SZ;
		goto ssb_pflash;
	}

	/* There is ChipCommon, so use it to read info about flash */
	switch (bus->chipco.capabilities & SSB_CHIPCO_CAP_FLASHT) {
	case SSB_CHIPCO_FLASHT_STSER:
	case SSB_CHIPCO_FLASHT_ATSER:
		pr_debug("Found serial flash\n");
		ssb_sflash_init(&bus->chipco);
		break;
	case SSB_CHIPCO_FLASHT_PARA:
		pr_debug("Found parallel flash\n");
		pflash->present = true;
		pflash->window = SSB_FLASH2;
		pflash->window_size = SSB_FLASH2_SZ;
		if ((ssb_read32(bus->chipco.dev, SSB_CHIPCO_FLASH_CFG)
		               & SSB_CHIPCO_CFG_DS16) == 0)
			pflash->buswidth = 1;
		else
			pflash->buswidth = 2;
		break;
	}

ssb_pflash:
	if (pflash->present) {
		ssb_pflash_data.width = pflash->buswidth;
		ssb_pflash_resource.start = pflash->window;
		ssb_pflash_resource.end = pflash->window + pflash->window_size;
	}
}

u32 ssb_cpu_clock(struct ssb_mipscore *mcore)
{
	struct ssb_bus *bus = mcore->dev->bus;
	u32 pll_type, n, m, rate = 0;

	if (bus->chipco.capabilities & SSB_CHIPCO_CAP_PMU)
		return ssb_pmu_get_cpu_clock(&bus->chipco);

	if (ssb_extif_available(&bus->extif)) {
		ssb_extif_get_clockcontrol(&bus->extif, &pll_type, &n, &m);
	} else if (ssb_chipco_available(&bus->chipco)) {
		ssb_chipco_get_clockcpu(&bus->chipco, &pll_type, &n, &m);
	} else
		return 0;

	if ((pll_type == SSB_PLLTYPE_5) || (bus->chip_id == 0x5365)) {
		rate = 200000000;
	} else {
		rate = ssb_calc_clock_rate(pll_type, n, m);
	}

	if (pll_type == SSB_PLLTYPE_6) {
		rate *= 2;
	}

	return rate;
}

void ssb_mipscore_init(struct ssb_mipscore *mcore)
{
	struct ssb_bus *bus;
	struct ssb_device *dev;
	unsigned long hz, ns;
	unsigned int irq, i;

	if (!mcore->dev)
		return; /* We don't have a MIPS core */

	ssb_dbg("Initializing MIPS core...\n");

	bus = mcore->dev->bus;
	hz = ssb_clockspeed(bus);
	if (!hz)
		hz = 100000000;
	ns = 1000000000 / hz;

	if (ssb_extif_available(&bus->extif))
		ssb_extif_timing_init(&bus->extif, ns);
	else if (ssb_chipco_available(&bus->chipco))
		ssb_chipco_timing_init(&bus->chipco, ns);

	/* Assign IRQs to all cores on the bus, start with irq line 2, because serial usually takes 1 */
	for (irq = 2, i = 0; i < bus->nr_devices; i++) {
		int mips_irq;
		dev = &(bus->devices[i]);
		mips_irq = ssb_mips_irq(dev);
		if (mips_irq > 4)
			dev->irq = 0;
		else
			dev->irq = mips_irq + 2;
		if (dev->irq > 5)
			continue;
		switch (dev->id.coreid) {
		case SSB_DEV_USB11_HOST:
			/* shouldn't need a separate irq line for non-4710, most of them have a proper
			 * external usb controller on the pci */
			if ((bus->chip_id == 0x4710) && (irq <= 4)) {
				set_irq(dev, irq++);
			}
			break;
		case SSB_DEV_PCI:
		case SSB_DEV_ETHERNET:
		case SSB_DEV_ETHERNET_GBIT:
		case SSB_DEV_80211:
		case SSB_DEV_USB20_HOST:
			/* These devices get their own IRQ line if available, the rest goes on IRQ0 */
			if (irq <= 4) {
				set_irq(dev, irq++);
				break;
			}
			/* fallthrough */
		case SSB_DEV_EXTIF:
			set_irq(dev, 0);
			break;
		}
	}
	ssb_dbg("after irq reconfiguration\n");
	dump_irq(bus);

	ssb_mips_serial_init(mcore);
	ssb_mips_flash_detect(mcore);
}
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   /******************************************************************************
 * rtl8712_io.c
 *
 * Copyright(c) 2007 - 2010 Realtek Corporation. All rights reserved.
 * Linux device driver for RTL8192SU
 *
 * This program is free software; you can redistribute it and/or modify it
 * under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation.
 *
 * This program is distributed in the hope that it will be useful, but WITHOUT
 * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
 * more details.
 *
 * You should have received a copy of the GNU General Public License along with
 * this program; if not, write to the Free Software Foundation, Inc.,
 * 51 Franklin Street, Fifth Floor, Boston, MA 02110, USA
 *
 * Modifications for inclusion into the Linux staging tree are
 * Copyright(c) 2010 Larry Finger. All rights reserved.
 *
 * Contact information:
 * WLAN FAE <wlanfae@realtek.com>.
 * Larry Finger <Larry.Finger@lwfinger.net>
 *
 ******************************************************************************/

#define _RTL8712_IO_C_

#include "osdep_service.h"
#include "drv_types.h"
#include "rtl871x_io.h"
#include "osdep_intf.h"
#include "usb_ops.h"

u8 r8712_read8(struct _adapter *adapter, u32 addr)
{
	struct io_queue *pio_queue = (struct io_queue *)adapter->pio_queue;
	struct intf_hdl *pintfhdl = &(pio_queue->intf);
	u8 (*_read8)(struct intf_hdl *pintfhdl, u32 addr);

	_read8 = pintfhdl->io_ops._read8;
	return  _read8(pintfhdl, addr);
}

u16 r8712_read16(struct _adapter *adapter, u32 addr)
{
	struct io_queue *pio_queue = (struct io_queue *)adapter->pio_queue;
	struct intf_hdl *pintfhdl = &(pio_queue->intf);
	u16 (*_read16)(struct intf_hdl *pintfhdl, u32 addr);

	_read16 = pintfhdl->io_ops._read16;
	return _read16(pintfhdl, addr);
}

u32 r8712_read32(struct _adapter *adapter, u32 addr)
{
	struct io_queue *pio_queue = (struct io_queue *)adapter->pio_queue;
	struct intf_hdl *pintfhdl = &(pio_queue->intf);
	u32 (*_read32)(struct intf_hdl *pintfhdl, u32 addr);

	_read32 = pintfhdl->io_ops._read32;
	return _read32(pintfhdl, addr);
}

void r8712_write8(struct _adapter *adapter, u32 addr, u8 val)
{
	struct io_queue *pio_queue = (struct io_queue *)adapter->pio_queue;
	struct intf_hdl *pintfhdl = &(pio_queue->intf);
	void (*_write8)(struct intf_hdl *pintfhdl, u32 addr, u8 val);

	_write8 = pintfhdl->io_ops._write8;
	_write8(pintfhdl, addr, val);
}

void r8712_write16(struct _adapter *adapter, u32 addr, u16 val)
{
	struct io_queue *pio_queue = (struct io_queue *)adapter->pio_queue;
	struct intf_hdl *pintfhdl = &(pio_queue->intf);
	void (*_write16)(struct intf_hdl *pintfhdl, u32 addr, u16 val);

	_write16 = pintfhdl->io_ops._write16;
	_write16(pintfhdl, addr, val);
}

void r8712_write32(struct _adapter *adapter, u32 addr, u32 val)
{
	struct io_queue *pio_queue = (struct io_queue *)adapter->pio_queue;
	struct intf_hdl *pintfhdl = (struct intf_hdl *)(&(pio_queue->intf));

	void (*_write32)(struct intf_hdl *pintfhdl, u32 addr, u32 val);

	_write32 = pintfhdl->io_ops._write32;
	_write32(pintfhdl, addr, val);
}

void r8712_read_mem(struct _adapter *adapter, u32 addr, u32 cnt, u8 *pmem)
{
	struct io_queue *pio_queue = (struct io_queue *)adapter->pio_queue;
	struct intf_hdl *pintfhdl = &(pio_queue->intf);

	void (*_read_mem)(struct intf_hdl *pintfhdl, u32 addr, u32 cnt,
			  u8 *pmem);
	if ((adapter->bDriverStopped == true) ||
	    (adapter->bSurpriseRemoved == true))
		return;
	_read_mem = pintfhdl->io_ops._read_mem;
	_read_mem(pintfhdl, addr, cnt, pmem);
}

void r8712_write_mem(struct _adapter *adapter, u32 addr, u32 cnt, u8 *pmem)
{
	struct io_queue *pio_queue = (struct io_queue *)adapter->pio_queue;
	struct intf_hdl *pintfhdl = &(pio_queue->intf);
	void (*_write_mem)(struct intf_hdl *pintfhdl, u32 addr, u32 cnt,
			   u8 *pmem);

	_write_mem = pintfhdl->io_ops._write_mem;
	_write_mem(pintfhdl, addr, cnt, pmem);
}

void r8712_read_port(struct _adapter *adapter, u32 addr, u32 cnt, u8 *pmem)
{
	struct io_queue *pio_queue = (struct io_queue *)adapter->pio_queue;
	struct intf_hdl	*pintfhdl = &(pio_queue->intf);

	u32 (*_read_port)(struct intf_hdl *pintfhdl, u32 addr, u32 cnt,
			  u8 *pmem);
	if ((adapter->bDriverStopped == true) ||
	    (adapter->bSurpriseRemoved == true))
		return;
	_read_port = pintfhdl->io_ops._read_port;
	_read_port(pintfhdl, addr, cnt, pmem);
}

void r8712_write_port(struct _adapter *adapter, u32 addr, u32 cnt, u8 *pmem)
{
	struct io_queue *pio_queue = (struct io_queue *)adapter->pio_queue;
	struct intf_hdl *pintfhdl = &(pio_queue->intf);

	u32 (*_write_port)(struct intf_hdl *pintfhdl, u32 addr, u32 cnt,
			   u8 *pmem);
	_write_port = pintfhdl->io_ops._write_port;
	_write_port(pintfhdl, addr, cnt, pmem);
}
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 /*
 * USB 7 Segment Driver
 *
 * Copyright (C) 2008 Harrison Metzger <harrisonmetz@gmail.com>
 * Based on usbled.c by Greg Kroah-Hartman (greg@kroah.com)
 *
 *	This program is free software; you can redistribute it and/or
 *	modify it under the terms of the GNU General Public License as
 *	published by the Free Software Foundation, version 2.
 *
 */

#include <linux/kernel.h>
#include <linux/errno.h>
#include <linux/slab.h>
#include <linux/module.h>
#include <linux/string.h>
#include <linux/usb.h>


#define DRIVER_AUTHOR "Harrison Metzger <harrisonmetz@gmail.com>"
#define DRIVER_DESC "USB 7 Segment Driver"

#define VENDOR_ID	0x0fc5
#define PRODUCT_ID	0x1227
#define MAXLEN		8

/* table of devices that work with this driver */
static const struct usb_device_id id_table[] = {
	{ USB_DEVICE(VENDOR_ID, PRODUCT_ID) },
	{ },
};
MODULE_DEVICE_TABLE(usb, id_table);

/* the different text display modes the device is capable of */
static char *display_textmodes[] = {"raw", "hex", "ascii", NULL};

struct usb_sevsegdev {
	struct usb_device *udev;
	struct usb_interface *intf;

	u8 powered;
	u8 mode_msb;
	u8 mode_lsb;
	u8 decimals[MAXLEN];
	u8 textmode;
	u8 text[MAXLEN];
	u16 textlength;

	u8 shadow_power; /* for PM */
	u8 has_interface_pm;
};

/* sysfs_streq can't replace this completely
 * If the device was in hex mode, and the user wanted a 0,
 * if str commands are used, we would assume the end of string
 * so mem commands are used.
 */
static inline size_t my_memlen(const char *buf, size_t count)
{
	if (count > 0 && buf[count-1] == '\n')
		return count - 1;
	else
		return count;
}

static void update_display_powered(struct usb_sevsegdev *mydev)
{
	int rc;

	if (mydev->powered && !mydev->has_interface_pm) {
		rc = usb_autopm_get_interface(mydev->intf);
		if (rc < 0)
			return;
		mydev->has_interface_pm = 1;
	}

	if (mydev->shadow_power != 1)
		return;

	rc = usb_control_msg(mydev->udev,
			usb_sndctrlpipe(mydev->udev, 0),
			0x12,
			0x48,
			(80 * 0x100) + 10, /*  (power mode) */
			(0x00 * 0x100) + (mydev->powered ? 1 : 0),
			NULL,
			0,
			2000);
	if (rc < 0)
		dev_dbg(&mydev->udev->dev, "power retval = %d\n", rc);

	if (!mydev->powered && mydev->has_interface_pm) {
		usb_autopm_put_interface(mydev->intf);
		mydev->has_interface_pm = 0;
	}
}

static void update_display_mode(struct usb_sevsegdev *mydev)
{
	int rc;

	if(mydev->shadow_power != 1)
		return;

	rc = usb_control_msg(mydev->udev,
			usb_sndctrlpipe(mydev->udev, 0),
			0x12,
			0x48,
			(82 * 0x100) + 10, /* (set mode) */
			(mydev->mode_msb * 0x100) + mydev->mode_lsb,
			NULL,
			0,
			2000);

	if (rc < 0)
		dev_dbg(&mydev->udev->dev, "mode retval = %d\n", rc);
}

static void update_display_visual(struct usb_sevsegdev *mydev, gfp_t mf)
{
	int rc;
	int i;
	unsigned char *buffer;
	u8 decimals = 0;

	if(mydev->shadow_power != 1)
		return;

	buffer = kzalloc(MAXLEN, mf);
	if (!buffer) {
		dev_err(&mydev->udev->dev, "out of memory\n");
		return;
	}

	/* The device is right to left, where as you write left to right */
	for (i = 0; i < mydev->textlength; i++)
		buffer[i] = mydev->text[mydev->textlength-1-i];

	rc = usb_control_msg(mydev->udev,
			usb_sndctrlpipe(mydev->udev, 0),
			0x12,
			0x48,
			(85 * 0x100) + 10, /* (write text) */
			(0 * 0x100) + mydev->textmode, /* mode  */
			buffer,
			mydev->textlength,
			2000);

	if (rc < 0)
		dev_dbg(&mydev->udev->dev, "write retval = %d\n", rc);

	kfree(buffer);

	/* The device is right to left, where as you write left to right */
	for (i = 0; i < sizeof(mydev->decimals); i++)
		decimals |= mydev->decimals[i] << i;

	rc = usb_control_msg(mydev->udev,
			usb_sndctrlpipe(mydev->udev, 0),
			0x12,
			0x48,
			(86 * 0x100) + 10, /* (set decimal) */
			(0 * 0x100) + decimals, /* decimals */
			NULL,
			0,
			2000);

	if (rc < 0)
		dev_dbg(&mydev->udev->dev, "decimal retval = %d\n", rc);
}

#define MYDEV_ATTR_SIMPLE_UNSIGNED(name, update_fcn)		\
static ssize_t show_attr_##name(struct device *dev, 		\
	struct device_attribute *attr, char *buf) 		\
{								\
	struct usb_interface *intf = to_usb_interface(dev);	\
	struct usb_sevsegdev *mydev = usb_get_intfdata(intf);	\
								\
	return sprintf(buf, "%u\n", mydev->name);		\
}								\
								\
static ssize_t set_attr_##name(struct device *dev, 		\
	struct device_attribute *attr, const char *buf, size_t count) \
{								\
	struct usb_interface *intf = to_usb_interface(dev);	\
	struct usb_sevsegdev *mydev = usb_get_intfdata(intf);	\
								\
	mydev->name = simple_strtoul(buf, NULL, 10);		\
	update_fcn(mydev); 					\
								\
	return count;						\
}								\
static DEVICE_ATTR(name, S_IRUGO | S_IWUSR, show_attr_##name, set_attr_##name);

static ssize_t show_attr_text(struct device *dev,
	struct device_attribute *attr, char *buf)
{
	struct usb_interface *intf = to_usb_interface(dev);
	struct usb_sevsegdev *mydev = usb_get_intfdata(intf);

	return snprintf(buf, mydev->textlength, "%s\n", mydev->text);
}

static ssize_t set_attr_text(struct device *dev,
	struct device_attribute *attr, const char *buf, size_t count)
{
	struct usb_interface *intf = to_usb_interface(dev);
	struct usb_sevsegdev *mydev = usb_get_intfdata(intf);
	size_t end = my_memlen(buf, count);

	if (end > sizeof(mydev->text))
		return -EINVAL;

	memset(mydev->text, 0, sizeof(mydev->text));
	mydev->textlength = end;

	if (end > 0)
		memcpy(mydev->text, buf, end);

	update_display_visual(mydev, GFP_KERNEL);
	return count;
}

static DEVICE_ATTR(text, S_IRUGO | S_IWUSR, show_attr_text, set_attr_text);

static ssize_t show_attr_decimals(struct device *dev,
	struct device_attribute *attr, char *buf)
{
	struct usb_interface *intf = to_usb_interface(dev);
	struct usb_sevsegdev *mydev = usb_get_intfdata(intf);
	int i;
	int pos;

	for (i = 0; i < sizeof(mydev->decimals); i++) {
		pos = sizeof(mydev->decimals) - 1 - i;
		if (mydev->decimals[i] == 0)
			buf[pos] = '0';
		else if (mydev->decimals[i] == 1)
			buf[pos] = '1';
		else
			buf[pos] = 'x';
	}

	buf[sizeof(mydev->decimals)] = '\n';
	return sizeof(mydev->decimals) + 1;
}

static ssize_t set_attr_decimals(struct device *dev,
	struct device_attribute *attr, const char *buf, size_t count)
{
	struct usb_interface *intf = to_usb_interface(dev);
	struct usb_sevsegdev *mydev = usb_get_intfdata(intf);
	size_t end = my_memlen(buf, count);
	int i;

	if (end > sizeof(mydev->decimals))
		return -EINVAL;

	for (i = 0; i < end; i++)
		if (buf[i] != '0' && buf[i] != '1')
			return -EINVAL;

	memset(mydev->decimals, 0, sizeof(mydev->decimals));
	for (i = 0; i < end; i++)
		if (buf[i] == '1')
			mydev->decimals[end-1-i] = 1;

	update_display_visual(mydev, GFP_KERNEL);

	return count;
}

static DEVICE_ATTR(decimals, S_IRUGO | S_IWUSR, show_attr_decimals, set_attr_decimals);

static ssize_t show_attr_textmode(struct device *dev,
	struct device_attribute *attr, char *buf)
{
	struct usb_interface *intf = to_usb_interface(dev);
	struct usb_sevsegdev *mydev = usb_get_intfdata(intf);
	int i;

	buf[0] = 0;

	for (i = 0; display_textmodes[i]; i++) {
		if (mydev->textmode == i) {
			strcat(buf, " [");
			strcat(buf, display_textmodes[i]);
			strcat(buf, "] ");
		} else {
			strcat(buf, " ");
			strcat(buf, display_textmodes[i]);
			strcat(buf, " ");
		}
	}
	strcat(buf, "\n");


	return strlen(buf);
}

static ssize_t set_attr_textmode(struct device *dev,
	struct device_attribute *attr, const char *buf, size_t count)
{
	struct usb_interface *intf = to_usb_interface(dev);
	struct usb_sevsegdev *mydev = usb_get_intfdata(intf);
	int i;

	for (i = 0; display_textmodes[i]; i++) {
		if (sysfs_streq(display_textmodes[i], buf)) {
			mydev->textmode = i;
			update_display_visual(mydev, GFP_KERNEL);
			return count;
		}
	}

	return -EINVAL;
}

static DEVICE_ATTR(textmode, S_IRUGO | S_IWUSR, show_attr_textmode, set_attr_textmode);


MYDEV_ATTR_SIMPLE_UNSIGNED(powered, update_display_powered);
MYDEV_ATTR_SIMPLE_UNSIGNED(mode_msb, update_display_mode);
MYDEV_ATTR_SIMPLE_UNSIGNED(mode_lsb, update_display_mode);

static struct attribute *dev_attrs[] = {
	&dev_attr_powered.attr,
	&dev_attr_text.attr,
	&dev_attr_textmode.attr,
	&dev_attr_decimals.attr,
	&dev_attr_mode_msb.attr,
	&dev_attr_mode_lsb.attr,
	NULL
};

static struct attribute_group dev_attr_grp = {
	.attrs = dev_attrs,
};

static int sevseg_probe(struct usb_interface *interface,
	const struct usb_device_id *id)
{
	struct usb_device *udev = interface_to_usbdev(interface);
	struct usb_sevsegdev *mydev = NULL;
	int rc = -ENOMEM;

	mydev = kzalloc(sizeof(struct usb_sevsegdev), GFP_KERNEL);
	if (mydev == NULL) {
		dev_err(&interface->dev, "Out of memory\n");
		goto error_mem;
	}

	mydev->udev = usb_get_dev(udev);
	mydev->intf = interface;
	usb_set_intfdata(interface, mydev);

	/* PM */
	mydev->shadow_power = 1; /* currently active */
	mydev->has_interface_pm = 0; /* have not issued autopm_get */

	/*set defaults */
	mydev->textmode = 0x02; /* ascii mode */
	mydev->mode_msb = 0x06; /* 6 characters */
	mydev->mode_lsb = 0x3f; /* scanmode for 6 chars */

	rc = sysfs_create_group(&interface->dev.kobj, &dev_attr_grp);
	if (rc)
		goto error;

	dev_info(&interface->dev, "USB 7 Segment device now attached\n");
	return 0;

error:
	usb_set_intfdata(interface, NULL);
	usb_put_dev(mydev->udev);
	kfree(mydev);
error_mem:
	return rc;
}

static void sevseg_disconnect(struct usb_interface *interface)
{
	struct usb_sevsegdev *mydev;

	mydev = usb_get_intfdata(interface);
	sysfs_remove_group(&interface->dev.kobj, &dev_attr_grp);
	usb_set_intfdata(interface, NULL);
	usb_put_dev(mydev->udev);
	kfree(mydev);
	dev_info(&interface->dev, "USB 7 Segment now disconnected\n");
}

static int sevseg_suspend(struct usb_interface *intf, pm_message_t message)
{
	struct usb_sevsegdev *mydev;

	mydev = usb_get_intfdata(intf);
	mydev->shadow_power = 0;

	return 0;
}

static int sevseg_resume(struct usb_interface *intf)
{
	struct usb_sevsegdev *mydev;

	mydev = usb_get_intfdata(intf);
	mydev->shadow_power = 1;
	update_display_mode(mydev);
	update_display_visual(mydev, GFP_NOIO);

	return 0;
}

static int sevseg_reset_resume(struct usb_interface *intf)
{
	struct usb_sevsegdev *mydev;

	mydev = usb_get_intfdata(intf);
	mydev->shadow_power = 1;
	update_display_mode(mydev);
	update_display_visual(mydev, GFP_NOIO);

	return 0;
}

static struct usb_driver sevseg_driver = {
	.name =		"usbsevseg",
	.probe =	sevseg_probe,
	.disconnect =	sevseg_disconnect,
	.suspend =	sevseg_suspend,
	.resume =	sevseg_resume,
	.reset_resume =	sevseg_reset_resume,
	.id_table =	id_table,
	.supports_autosuspend = 1,
};

module_usb_driver(sevseg_driver);

MODULE_AUTHOR(DRIVER_AUTHOR);
MODULE_DESCRIPTION(DRIVER_DESC);
MODULE_LICENSE("GPL");
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       :100000000106000008000000000024140E00000398
:100010000000000008001B24000000001000000386
:10002000000000000000000D0000000D3C1D080055
:1000300037BD400003A0F0213C100800261000004E
:100040000E000010000000000000000D27BDFFE0C2
:100050003C04FEFEAFBF00180E0005D83484000239
:100060000E000668000000003C03080090631B6857
:10007000240200023C04080024841AAC1462000329
:10008000240500013C04080024841AA0240600066C
:1000900000003821AFA000100E00067CAFA00014B5
:1000A0008F625C5034420001AF625C508F625C90A2
:1000B00034420001AF625C902402FFFF0E00003466
:1000C000AF6254048FBF001803E0000827BD002072
:1000D00000000000000000000000000027BDFFE05D
:1000E000AFBF001CAFB20018AFB100140E00005B30
:1000F000AFB0001024120002241100018F7068209C
:100100003202010010400003000000000E0000BB9E
:10011000000000008F7068203202200010400004B0
:10012000320200010E0001F024040001320200013D
:1001300010400003000000000E0000A300000000BB
:100140003C02080090421B9814520003000000007B
:100150000E0004C0000000000A00003CAF715028EF
:100160008FBF001C8FB200188FB100148FB0001029
:1001700003E0000827BD002027BDFFE03C04080085
:1001800024841AC0000028210000302100003821FA
:10019000AFBF0018AFA000100E00067CAFA0001487
:1001A0003C040800248423D8A48000003C010800FB
:1001B000A0201B983C010800AC201B9C3C010800BF
:1001C000AC201BA03C010800AC201BA43C01080093
:1001D000AC201BAC3C010800AC201BB83C01080063
:1001E000AC201BBC8F6244343C010800AC221B884D
:1001F0008F6244383C010800AC221B8C8F62441093
:10020000AC80F7A83C010800AC201B843C0108002E
:10021000AC2023E03C010800AC2023C83C010800CE
:10022000AC2023CC3C010800AC2024003C01080099
:10023000AC221B908F6200682403000700021702A3
:1002400010430005000000008F62006800021702E2
:1002500014400004240200013C0108000A00009739
:10026000AC20240CAC8200343C04080024841ACC5A
:100270003C0508008CA5240C00003021000038212A
:10028000AFA000100E00067CAFA000148FBF0018B6
:1002900003E0000827BD002027BDFFE03C04080064
:1002A00024841AD8000028210000302100003821C1
:1002B000AFBF0018AFA000100E00067CAFA0001466
:1002C0000E00005B000000000E0000B400002021C2
:1002D0008FBF001803E0000827BD002024020001A2
:1002E0008F63682000821004000210270062182427
:1002F00003E00008AF63682027BDFFD0AFBF002C2C
:10030000AFB60028AFB50024AFB40020AFB3001CD7
:10031000AFB20018AFB10014AFB000108F675C5CD3
:100320003C03080024631BBC8C62000014470005DA
:100330003C0200FF3C02080090421B981440011947
:100340003C0200FF3442FFF800E28824AC67000062
:1003500000111902306300FF30E20003000211C0F7
:100360000062282500A04021000716023C03080077
:1003700090631B983044000F1460003600804821C1
:10038000240200013C010800A0221B980005110076
:10039000008210253C010800AC201B9C3C01080099
:1003A000AC201BA03C010800AC201BA43C010800B1
:1003B000AC201BAC3C010800AC201BB83C01080081
:1003C000AC201BB03C010800AC201BB43C01080071
:1003D000A42223D89622000C30437FFF3C01080062
:1003E000A4222410304280003C010800A4231BC634
:1003F00010400005240200013C010800AC2223F457
:100400000A0001022406003E240600363C010800D2
:10041000AC2023F49622000A3C03080094631BC618
:100420003C010800AC2023F03C010800AC2023F87C
:10043000000213020002108000C210210062182185
:100440003C010800A42223D03C0108000A00011549
:10045000A4231B969622000C3C010800A42223EC46
:100460003C04080024841B9C8C82000000021100C4
:100470003C01080000220821AC311BC88C8200001E
:10048000000211003C01080000220821AC271BCC0F
:100490008C82000025030001306601FF000211007C
:1004A0003C01080000220821AC261BD08C820000F1
:1004B000000211003C01080000220821AC291BD4D5
:1004C000962300083C0208008C421BAC0043282104
:1004D0003C010800AC251BAC9622000A3042000407
:1004E00014400018000611008F630C143063000FD5
:1004F0002C6200021440000B3C02C0008F630C14FD
:100500003C0208008C421B403063000F2442000173
:100510003C010800AC221B402C6200021040FFF797
:100520003C02C00000E21825AF635C5C8F625C5047
:100530003042000210400014000000000A00014791
:10054000000000003C0308008C631B803C04080092
:1005500094841B94012210253C010800A42223DA74
:10056000240200013C010800AC221BB824630001F6
:100570000085202A3C01080010800003AC231B806A
:100580003C010800A4251B943C06080024C61B9CC3
:100590008CC2000024420001ACC20000284200804E
:1005A00014400005000000000E000656240400025E
:1005B0000A0001E6000000003C0208008C421BB863
:1005C00010400078240200013C05080090A51B980B
:1005D00014A20072000000003C15080096B51B969E
:1005E0003C0408008C841BAC32A3FFFF0083102A5C
:1005F0001440006C000000001483000300000000A1
:100600003C010800AC2523F01060005C0000902144
:1006100024D600040060A02124D300148EC2000060
:10062000000281003C110800023088210E000625DE
:100630008E311BC80040282110A00054000000008B
:100640009628000A31020040104000052407180CCB
:100650008E22000C2407188C00021400ACA2001893
:100660003C030800007018218C631BD03C0208007A
:10067000005010218C421BD400031D000002140006
:1006800000621825ACA300148EC300049622000853
:10069000004320233242FFFF3083FFFF004310213D
:1006A0000282102A1440000202B23023008030215E
:1006B0008E62000030C4FFFF00441021AE620000D3
:1006C0008E220000ACA200008E2200048E63FFF494
:1006D00000431021ACA20004A4A6000E8E62FFF419
:1006E00000441021AE62FFF4962300080043102A54
:1006F00014400005024690218E62FFF0AE60FFF4C8
:1007000024420001AE62FFF0ACA000083242FFFFBD
:1007100014540008240203053102008054400001F3
:1007200034E7001024020905A4A2000C0A0001CB42
:1007300034E70020A4A2000C3C0208008C4223F005
:10074000104000033C024B650A0001D3344276544A
:100750003C02B49A344289ABACA2001C30E2FFFFE9
:10076000ACA200100E0005A200A020213242FFFF23
:100770000054102B1440FFA90000000024020002C6
:100780003C0108000A0001E6A0221B988EC2083C2A
:10079000244200010A0001E6AEC2083C0E0004C07B
:1007A000000000008FBF002C8FB600288FB50024FA
:1007B0008FB400208FB3001C8FB200188FB10014CB
:1007C0008FB0001003E0000827BD003027BDFFD028
:1007D000AFBF0028AFB30024AFB20020AFB1001C00
:1007E000AFB000188F725C9C3C0200FF3442FFF8EF
:1007F0003C07080024E71BB4024288249623000E1D
:100800008CE2000000431021ACE200008E220010B8
:100810003042002014400011008098210E00063B59
:10082000022020213C02C00002421825AF635C9CDC
:100830008F625C90304200021040011E00000000F8
:10084000AF635C9C8F625C903042000210400119E3
:10085000000000000A00020D000000008E240008C5
:100860008E23001400041402000231C0000315029C
:10087000304201FF2442FFFF3042007F0003194253
:1008800030637800000211002442400000624821D9
:100890009522000A3084FFFF30420008104000B06B
:1008A000000429C03C0208008C42240014400024AB
:1008B00024C5000894C200143C010800A42223D0DF
:1008C0008CC40010000414023C010800A42223D2AE
:1008D0003C010800A42423D494C2000E3083FFFFFF
:1008E000004310233C010800AC22240894C2001AE3
:1008F0003C010800AC2624003C010800AC32240472
:100900003C010800AC2223FC3C02C0000242182536
:10091000AF635C9C8F625C9030420002104000E547
:1009200000000000AF635C9C8F625C90304200026C
:10093000104000E0000000000A0002460000000035
:1009400094C2000E3C030800946323D40043402368
:100950003103FFFF2C6200081040001C0000000063
:1009600094C200142442002800A22821000310424F
:100970001840000B0000202124E6084800403821E0
:1009800094A300008CC200002484000100431021C5
:10099000ACC200000087102A1440FFF924A5000211
:1009A000310200011040001F3C0240003C040800DE
:1009B000248423FCA0A0000194A300008C820000EA
:1009C000004310210A000285AC8200008F6268009B
:1009D0003C030010004310241040000900000000F8
:1009E00094C2001A3C0308008C6323FC00431021CE
:1009F0003C010800AC2223FC0A0002863C024000B5
:100A000094C2001A94C4001C3C0308008C6323FCAD
:100A100000441023006218213C010800AC2323FC91
:100A20003C02400002421825AF635C9C8F625C90E0
:100A3000304200021440FFFC000000009522000A32
:100A4000304200101040009B000000003C030800F2
:100A5000946323D43C07080024E724008CE40000BE
:100A60008F62680024630030008328213C0300105B
:100A7000004310241440000A0000000094A2000467
:100A80003C0408008C8424083C0308008C6323FC8D
:100A900000441023006218213C010800AC2323FC11
:100AA0003C0408008C8423FC00041C023082FFFFFD
:100AB000006220210004140200822021000410277B
:100AC000A4A200063C0308008C6324043C0200FF3F
:100AD0003442FFF8006288249622000824050001B1
:100AE00024034000000231C000801021A4C2001A7B
:100AF000A4C0001CACE000003C010800AC251B6059
:100B0000AF635CB88F625CB03042000210400003FB
:100B1000000000003C010800AC201B608E22000891
:100B2000AF625CB88F625CB03042000210400003DC
:100B3000000000003C010800AC201B603C020800E3
:100B40008C421B601040FFEC000000003C040800D9
:100B50000E00063B8C8424040A00032A00000000D7
:100B60003C03080090631B982402000214620003F7
:100B70003C034B650A0002E1000080218E22001C2C
:100B80003463765410430002241000022410000144
:100B900000C020210E000350020030212402000377
:100BA0003C010800A0221B98240200021202000A45
:100BB000240200013C0308008C6323F0106200064D
:100BC000000000003C020800944223D800021400F8
:100BD0000A00031FAE2200143C040800248423DA18
:100BE0009482000000021400AE2200143C020800AF
:100BF0008C421BBC3C03C0003C010800A0201B9899
:100C000000431025AF625C5C8F625C503042000292
:100C100010400009000000002484F7E28C820000EC
:100C200000431025AF625C5C8F625C503042000272
:100C30001440FFFA000000003C02080024421B841C
:100C40008C43000024630001AC4300008F630C144C
:100C50003063000F2C6200021440000C3C02400084
:100C60008F630C143C0208008C421B403063000F61
:100C7000244200013C010800AC221B402C6200020F
:100C80001040FFF7000000003C024000024218251F
:100C9000AF635C9C8F625C90304200021440FFFCAA
:100CA0000000000012600003000000000E0004C0FD
:100CB000000000008FBF00288FB300248FB20020F7
:100CC0008FB1001C8FB0001803E0000827BD003072
:100CD0008F6344503C04080024841B888C820000ED
:100CE00000031C020043102B144000073C0380004B
:100CF0008C8400048F62445000021C020083102B7D
:100D00001040FFFC3C038000AF6344448F624444C6
:100D1000004310241440FFFD000000008F6244488F
:100D200003E000083042FFFF3C0240000082202523
:100D3000AF645C388F625C30304200021440FFFCCC
:100D40000000000003E000080000000027BDFFE0F5
:100D50000080582114C00011256E00083C020800D4
:100D60008C4223F410400007240200163C010800C6
:100D7000A42223D22402002A3C0108000A000364B2
:100D8000A42223D48D670010000714023C01080040
:100D9000A42223D23C010800A42723D43C04080049
:100DA000948423D43C030800946323D295CF000697
:100DB0003C020800944223D00083202301E2C02398
:100DC0003065FFFF24A2002801C248213082FFFFC6
:100DD00014C0001A012260219582000C3042003FAD
:100DE0003C010800A42223D69582000495830006C6
:100DF0003C010800AC2023E43C010800AC2023E8BF
:100E000000021400004310253C010800AC221BC066
:100E1000952200043C010800A4221BC49523000273
:100E200001E510230043102A1040001024020001A5
:100E30003C0108000A000398AC2223F83C03080098
:100E40008C6323E83C02080094421BC40043102139
:100E5000A52200043C02080094421BC0A5820004A5
:100E60003C0208008C421BC0A58200063C02080020
:100E70008C4223F03C0D08008DAD23E43C0A0800B1
:100E8000144000E58D4A23E83C02080094421BC44C
:100E9000004A18213063FFFF0062182B2402000271
:100EA00010C2000D014350233C020800944223D697
:100EB0003042000910400008000000009582000C3C
:100EC0003042FFF6A582000C3C020800944223D673
:100ED0003042000901A268233C0208008C4223F83A
:100EE0001040004A012038213C020800944223D2DD
:100EF00000004021A520000A01E21023A5220002E3
:100F00003082FFFF0002104218400008000030212C
:100F10000040182194E200002508000100C23021A1
:100F20000103102A1440FFFB24E7000200061C0204
:100F300030C2FFFF006230210006140200C23021DF
:100F400000C0282100061027A522000A0000302139
:100F50002527000C0000402194E200002508000134
:100F600000C230212D0200041440FFFB24E70002E0
:100F70009522000200004021912300090044202313
:100F8000018038213082FFFFA4E0001000621821A8
:100F9000000210421840001000C3302100404821D8
:100FA00094E2000024E7000200C2302130E2007F1A
:100FB00014400006250800018D6300003C02007FFC
:100FC0003442FF8000625824256700080109102A76
:100FD0001440FFF3000000003082000110400005C3
:100FE00000061C02A0E0000194E2000000C23021D3
:100FF00000061C0230C2FFFF00623021000614020E
:1010000000C230210A00047D30C6FFFF2402000226
:1010100014C20081000000003C0208008C42240C35
:1010200014400007000000003C020800944223D254
:101030009523000201E210231062007700000000F7
:101040003C020800944223D201E21023A5220002B0
:101050003C0208008C42240C1040001A31E3FFFFD0
:101060008DC700103C02080094421B9600E040210E
:1010700000072C0200AA20210043102300823823FD
:101080000007240230E2FFFF00823821000710270A
:10109000A522000A3102FFFF3C040800948423D4F7
:1010A0000045302300E0282100641823006D18213A
:1010B00000C3302100061C0230C2FFFF0A00047D7D
:1010C0000062302101203821000040213082FFFFE2
:1010D0000002104218400008000030210040182192
:1010E00094E200002508000100C230210103102A0B
:1010F0001440FFFB24E7000200061C0230C2FFFF81
:10110000006230210006140200C2302100C02821F4
:1011100000061027A522000A000030212527000C18
:101120000000402194E200002508000100C23021A7
:101130002D0200041440FFFB24E700029522000268
:101140000000402191230009004420230180382120
:101150003082FFFFA4E000103C040800948423D4F4
:101160000062182100C3302100061C0230C2FFFFBC
:101170000062302100061C023C020800944223D089
:1011800000C348210044102300021FC20043102165
:1011900000021043184000100000302100402021C0
:1011A00094E2000024E7000200C2302130E2007F18
:1011B00014400006250800018D6300003C02007FFA
:1011C0003442FF8000625824256700080104102A79
:1011D0001440FFF3000000003C020800944223EC9E
:1011E00000C230213122FFFF00C2302100061C0264
:1011F00030C2FFFF006230210006140200C230211D
:1012000000C0402100061027A5820010ADC00014C8
:101210000A00049DADC000008DC7001000E0402111
:101220001140000700072C0200AA3021000614021A
:1012300030C3FFFF004330210006140200C2282102
:1012400000051027A522000A3C030800946323D45C
:101250003102FFFF01E210210043302300CD302195
:1012600000061C0230C2FFFF00623021000614029B
:1012700000C2302100C0402100061027A5820010C6
:101280003102FFFF00051C0000431025ADC2001015
:101290003C0208008C4223F4104000052DE205EBCF
:1012A0001440000225E2FFF234028870A5C2003427
:1012B0003C030800246323E88C6200002442000100
:1012C000AC6200003C0408008C8423E43C0208006B
:1012D0008C421BC03303FFFF0083202100431821F1
:1012E0000062102B3C010800AC2423E410400003F2
:1012F0002482FFFF3C010800AC2223E43C010800EB
:10130000AC231BC003E0000827BD002027BDFFB8A9
:101310003C05080024A51B96AFBF0044AFBE0040AB
:10132000AFB7003CAFB60038AFB50034AFB4003053
:10133000AFB3002CAFB20028AFB10024AFB0002093
:1013400094A900003C020800944223D03C0308000A
:101350008C631BB03C0408008C841BAC012210235E
:101360000064182AA7A9001E106000BEA7A20016DC
:1013700024BE002297B6001E24B3001A24B700161C
:101380008FC2000014400008000000008FC2FFF868
:1013900097A300168FC4FFF4004310210082202A77
:1013A000148000B00000000097D5081832A2FFFF9B
:1013B000104000A3000090210040A02100008821DF
:1013C0000E000625000000000040302114C0000778
:1013D000000000003C0208008C4223DC2442000193
:1013E0003C0108000A000596AC2223DC3C100800F2
:1013F000021180218E101BC89608000A310200409D
:10140000104000052407180C8E02000C2407188CCD
:1014100000021400ACC200183102008054400001E8
:1014200034E700103C020800005110218C421BD010
:101430003C030800007118218C631BD400021500C6
:1014400000031C0000431025ACC2001496040008E1
:101450003242FFFF008210210282102A1440000253
:1014600002B22823008028218E020000024590212C
:10147000ACC200008E02000400C020212631001002
:10148000AC82000430E2FFFFAC800008A485000EAF
:10149000AC820010240203050E0005A2A482000CF9
:1014A0003242FFFF0054102B1440FFC53242FFFFB1
:1014B0000A00058E000000008E6200008E63FFFCB3
:1014C0000043102A10400067000000008E62FFF009
:1014D000000289003C100800021180210E00062540
:1014E0008E101BC80040302114C000050000000011
:1014F0008E62082C244200010A000596AE62082C78
:101500009608000A31020040104000052407180C1C
:101510008E02000C2407188C00021400ACC20018C4
:101520003C020800005110218C421BD03C030800F3
:10153000007118218C631BD40002150000031C00ED
:1015400000431025ACC200148E63FFF4960200081D
:10155000004320233242FFFF3083FFFF004310216E
:1015600002C2102A104000030080282197A9001E03
:10157000013228238E62000030A4FFFF00441021B6
:10158000AE620000A4C5000E8E020000ACC20000D6
:101590008E0200048E63FFF400431021ACC20004ED
:1015A0008E63FFF496020008006418210062102A7E
:1015B00014400006024590218E62FFF0AE60FFF4F9
:1015C000244200010A000571AE62FFF0AE63FFF431
:1015D000ACC000083242FFFF105600033102000485
:1015E000104000062402030531020080544000012F
:1015F00034E7001034E7002024020905A4C2000CDF
:101600008EE300008EE20004146200073C02B49AEC
:101610008EE208605440000134E704003C024B6550
:101620000A00058834427654344289ABACC2001CAF
:1016300030E2FFFFACC200100E0005A200C0202166
:101640003242FFFF0056102B1440FF9B00000000A9
:101650008E6200008E63FFFC0043102A1440FF4896
:10166000000000008FBF00448FBE00408FB7003CD9
:101670008FB600388FB500348FB400308FB3002C94
:101680008FB200288FB100248FB0002003E0000843
:1016900027BD004827BDFFE8AFBF0014AFB0001062
:1016A0008F6244508F6344100A0005B1008080218E
:1016B0008F626820304220001040000300000000CC
:1016C0000E0001F0000020218F6244508F6344100F
:1016D0003042FFFF0043102B1440FFF500000000D4
:1016E0008F630C143063000F2C6200021440000B57
:1016F000000000008F630C143C0208008C421B4069
:101700003063000F244200013C010800AC221B4062
:101710002C6200021040FFF700000000AF705C1860
:101720008F625C103042000210400009000000008F
:101730008F626820304220001040FFF80000000057
:101740000E0001F0000020210A0005C40000000086
:101750008FBF00148FB0001003E0000827BD0018F1
:1017600000000000000000000000000027BDFFE8AE
:101770003C1BC000AFBF0014AFB00010AF60680CDE
:101780008F62680434420082AF6268048F63400055
:1017900024020B503C010800AC221B5424020B789D
:1017A0003C010800AC221B6434630002AF634000BC
:1017B0000E000605008080213C010800A0221B6865
:1017C000304200FF24030002144300050000000023
:1017D0003C0208008C421B540A0005F8AC5000C0C3
:1017E0003C0208008C421B54AC5000BC8F62443455
:1017F0008F6344388F6444103C010800AC221B5CAA
:101800003C010800AC231B6C3C010800AC241B58B5
:101810008FBF00148FB0001003E0000827BD001830
:101820003C0408008C8700003C03AA553463AA5589
:101830003C06C003AC8300008CC2000014430007C8
:10184000240500023C0355AA346355AAAC8300006A
:101850008CC2000050430001240500013C02080036
:10186000AC47000003E0000800A0102127BDFFF8EE
:1018700018800009000028218F63680C8F62680CB3
:101880001043FFFE0000000024A5000100A4102A60
:101890001440FFF90000000003E0000827BD000825
:1018A0008F6344503C0208008C421B5C00031C0206
:1018B0000043102B144000083C0380003C04080047
:1018C0008C841B6C8F62445000021C020083102B1E
:1018D0001040FFFC3C038000AF6344448F624444EB
:1018E000004310241440FFFD000000008F624448B4
:1018F00003E000083042FFFF3082FFFF2442E00097
:101900002C422001144000033C0240000A0006481B
:101910002402FFFF00822025AF645C388F625C30B8
:10192000304200021440FFFC0000102103E00008D8
:10193000000000008F6244503C0308008C631B5879
:101940000A0006513042FFFF8F6244503042FFFFD1
:101950000043102B1440FFFC0000000003E00008CF
:101960000000000027BDFFE0008028213C040800A3
:1019700024841AF00000302100003821AFBF001885
:10198000AFA000100E00067CAFA000140A00066095
:10199000000000008FBF001803E0000827BD0020F2
:1019A0000000000000000000000000003C020800F1
:1019B000344230003C030800346330003C0408002B
:1019C000348437FF3C010800AC221B742402004021
:1019D0003C010800AC221B783C010800AC201B70C5
:1019E000AC600000246300040083102B5040FFFD16
:1019F000AC60000003E00008000000000080482107
:101A00008FAA00103C0208008C421B703C040800A6
:101A10008C841B788FAB0014244300010044102BEE
:101A20003C010800AC231B7014400003000040215F
:101A30003C010800AC201B703C0208008C421B706B
:101A40003C0308008C631B749124000000021140C9
:101A5000004310210048102125080001A044000087
:101A6000290200081440FFF4252900013C02080067
:101A70008C421B703C0308008C631B748F64680CE1
:101A80000002114000431021AC440008AC45000C9A
:101A9000AC460010AC470014AC4A001803E0000844
:101AA000AC4B001C00000000000000004D61696E9E
:101AB00043707542000000004D61696E43707541CE
:101AC00000000000000000000000000073746B6F55
:101AD00066666C64496E000073746B6F66662A2AD2
:101AE0000000000053774576656E743000000000FA
:101AF000000000000000000000000000666174614A
:101B00006C45727200000000000000000000000040
:101B100000000000000000000000000000000000C5
:101B200000000000000000000000000000000000B5
:101B300073746B6F66666C645F76312E362E300080
:101B40000000000000000000000000000000000095
:0C1B500000000000000000000000000089
:00000001FF
 * Firmware is:
 *	Derived from proprietary unpublished source code,
 *	Copyright (C) 2000-2003 Broadcom Corporation.
 *
 *	Permission is hereby granted for the distribution of this firmware
 *	data in hexadecimal or equivalent format, provided this copyright
 *	notice is accompanying it.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  /* -*- mode: c; c-basic-offset: 8; -*-
 * vim: noexpandtab sw=8 ts=8 sts=0:
 *
 * Copyright (C) 2004, 2005 Oracle.  All rights reserved.
 *
 * This program is free software; you can redistribute it and/or
 * modify it under the terms of the GNU General Public
 * License as published by the Free Software Foundation; either
 * version 2 of the License, or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * General Public License for more details.
 *
 * You should have received a copy of the GNU General Public
 * License along with this program; if not, write to the
 * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
 * Boston, MA 021110-1307, USA.
 */

#include <linux/slab.h>
#include <linux/kernel.h>
#include <linux/module.h>
#include <linux/configfs.h>

#include "tcp.h"
#include "nodemanager.h"
#include "heartbeat.h"
#include "masklog.h"
#include "sys.h"

/* for now we operate under the assertion that there can be only one
 * cluster active at a time.  Changing this will require trickling
 * cluster references throughout where nodes are looked up */
struct o2nm_cluster *o2nm_single_cluster = NULL;

char *o2nm_fence_method_desc[O2NM_FENCE_METHODS] = {
		"reset",	/* O2NM_FENCE_RESET */
		"panic",	/* O2NM_FENCE_PANIC */
};

struct o2nm_node *o2nm_get_node_by_num(u8 node_num)
{
	struct o2nm_node *node = NULL;

	if (node_num >= O2NM_MAX_NODES || o2nm_single_cluster == NULL)
		goto out;

	read_lock(&o2nm_single_cluster->cl_nodes_lock);
	node = o2nm_single_cluster->cl_nodes[node_num];
	if (node)
		config_item_get(&node->nd_item);
	read_unlock(&o2nm_single_cluster->cl_nodes_lock);
out:
	return node;
}
EXPORT_SYMBOL_GPL(o2nm_get_node_by_num);

int o2nm_configured_node_map(unsigned long *map, unsigned bytes)
{
	struct o2nm_cluster *cluster = o2nm_single_cluster;

	BUG_ON(bytes < (sizeof(cluster->cl_nodes_bitmap)));

	if (cluster == NULL)
		return -EINVAL;

	read_lock(&cluster->cl_nodes_lock);
	memcpy(map, cluster->cl_nodes_bitmap, sizeof(cluster->cl_nodes_bitmap));
	read_unlock(&cluster->cl_nodes_lock);

	return 0;
}
EXPORT_SYMBOL_GPL(o2nm_configured_node_map);

static struct o2nm_node *o2nm_node_ip_tree_lookup(struct o2nm_cluster *cluster,
						  __be32 ip_needle,
						  struct rb_node ***ret_p,
						  struct rb_node **ret_parent)
{
	struct rb_node **p = &cluster->cl_node_ip_tree.rb_node;
	struct rb_node *parent = NULL;
	struct o2nm_node *node, *ret = NULL;

	while (*p) {
		int cmp;

		parent = *p;
		node = rb_entry(parent, struct o2nm_node, nd_ip_node);

		cmp = memcmp(&ip_needle, &node->nd_ipv4_address,
				sizeof(ip_needle));
		if (cmp < 0)
			p = &(*p)->rb_left;
		else if (cmp > 0)
			p = &(*p)->rb_right;
		else {
			ret = node;
			break;
		}
	}

	if (ret_p != NULL)
		*ret_p = p;
	if (ret_parent != NULL)
		*ret_parent = parent;

	return ret;
}

struct o2nm_node *o2nm_get_node_by_ip(__be32 addr)
{
	struct o2nm_node *node = NULL;
	struct o2nm_cluster *cluster = o2nm_single_cluster;

	if (cluster == NULL)
		goto out;

	read_lock(&cluster->cl_nodes_lock);
	node = o2nm_node_ip_tree_lookup(cluster, addr, NULL, NULL);
	if (node)
		config_item_get(&node->nd_item);
	read_unlock(&cluster->cl_nodes_lock);

out:
	return node;
}
EXPORT_SYMBOL_GPL(o2nm_get_node_by_ip);

void o2nm_node_put(struct o2nm_node *node)
{
	config_item_put(&node->nd_item);
}
EXPORT_SYMBOL_GPL(o2nm_node_put);

void o2nm_node_get(struct o2nm_node *node)
{
	config_item_get(&node->nd_item);
}
EXPORT_SYMBOL_GPL(o2nm_node_get);

u8 o2nm_this_node(void)
{
	u8 node_num = O2NM_MAX_NODES;

	if (o2nm_single_cluster && o2nm_single_cluster->cl_has_local)
		node_num = o2nm_single_cluster->cl_local_node;

	return node_num;
}
EXPORT_SYMBOL_GPL(o2nm_this_node);

/* node configfs bits */

static struct o2nm_cluster *to_o2nm_cluster(struct config_item *item)
{
	return item ?
		container_of(to_config_group(item), struct o2nm_cluster,
			     cl_group)
		: NULL;
}

static struct o2nm_node *to_o2nm_node(struct config_item *item)
{
	return item ? container_of(item, struct o2nm_node, nd_item) : NULL;
}

static void o2nm_node_release(struct config_item *item)
{
	struct o2nm_node *node = to_o2nm_node(item);
	kfree(node);
}

static ssize_t o2nm_node_num_read(struct o2nm_node *node, char *page)
{
	return sprintf(page, "%d\n", node->nd_num);
}

static struct o2nm_cluster *to_o2nm_cluster_from_node(struct o2nm_node *node)
{
	/* through the first node_set .parent
	 * mycluster/nodes/mynode == o2nm_cluster->o2nm_node_group->o2nm_node */
	return to_o2nm_cluster(node->nd_item.ci_parent->ci_parent);
}

enum {
	O2NM_NODE_ATTR_NUM = 0,
	O2NM_NODE_ATTR_PORT,
	O2NM_NODE_ATTR_ADDRESS,
	O2NM_NODE_ATTR_LOCAL,
};

static ssize_t o2nm_node_num_write(struct o2nm_node *node, const char *page,
				   size_t count)
{
	struct o2nm_cluster *cluster = to_o2nm_cluster_from_node(node);
	unsigned long tmp;
	char *p = (char *)page;

	tmp = simple_strtoul(p, &p, 0);
	if (!p || (*p && (*p != '\n')))
		return -EINVAL;

	if (tmp >= O2NM_MAX_NODES)
		return -ERANGE;

	/* once we're in the cl_nodes tree networking can look us up by
	 * node number and try to use our address and port attributes
	 * to connect to this node.. make sure that they've been set
	 * before writing the node attribute? */
	if (!test_bit(O2NM_NODE_ATTR_ADDRESS, &node->nd_set_attributes) ||
	    !test_bit(O2NM_NODE_ATTR_PORT, &node->nd_set_attributes))
		return -EINVAL; /* XXX */

	write_lock(&cluster->cl_nodes_lock);
	if (cluster->cl_nodes[tmp])
		p = NULL;
	else  {
		cluster->cl_nodes[tmp] = node;
		node->nd_num = tmp;
		set_bit(tmp, cluster->cl_nodes_bitmap);
	}
	write_unlock(&cluster->cl_nodes_lock);
	if (p == NULL)
		return -EEXIST;

	return count;
}
static ssize_t o2nm_node_ipv4_port_read(struct o2nm_node *node, char *page)
{
	return sprintf(page, "%u\n", ntohs(node->nd_ipv4_port));
}

static ssize_t o2nm_node_ipv4_port_write(struct o2nm_node *node,
					 const char *page, size_t count)
{
	unsigned long tmp;
	char *p = (char *)page;

	tmp = simple_strtoul(p, &p, 0);
	if (!p || (*p && (*p != '\n')))
		return -EINVAL;

	if (tmp == 0)
		return -EINVAL;
	if (tmp >= (u16)-1)
		return -ERANGE;

	node->nd_ipv4_port = htons(tmp);

	return count;
}

static ssize_t o2nm_node_ipv4_address_read(struct o2nm_node *node, char *page)
{
	return sprintf(page, "%pI4\n", &node->nd_ipv4_address);
}

static ssize_t o2nm_node_ipv4_address_write(struct o2nm_node *node,
					    const char *page,
					    size_t count)
{
	struct o2nm_cluster *cluster = to_o2nm_cluster_from_node(node);
	int ret, i;
	struct rb_node **p, *parent;
	unsigned int octets[4];
	__be32 ipv4_addr = 0;

	ret = sscanf(page, "%3u.%3u.%3u.%3u", &octets[3], &octets[2],
		     &octets[1], &octets[0]);
	if (ret != 4)
		return -EINVAL;

	for (i = 0; i < ARRAY_SIZE(octets); i++) {
		if (octets[i] > 255)
			return -ERANGE;
		be32_add_cpu(&ipv4_addr, octets[i] << (i * 8));
	}

	ret = 0;
	write_lock(&cluster->cl_nodes_lock);
	if (o2nm_node_ip_tree_lookup(cluster, ipv4_addr, &p, &parent))
		ret = -EEXIST;
	else {
		rb_link_node(&node->nd_ip_node, parent, p);
		rb_insert_color(&node->nd_ip_node, &cluster->cl_node_ip_tree);
	}
	write_unlock(&cluster->cl_nodes_lock);
	if (ret)
		return ret;

	memcpy(&node->nd_ipv4_address, &ipv4_addr, sizeof(ipv4_addr));

	return count;
}

static ssize_t o2nm_node_local_read(struct o2nm_node *node, char *page)
{
	return sprintf(page, "%d\n", node->nd_local);
}

static ssize_t o2nm_node_local_write(struct o2nm_node *node, const char *page,
				     size_t count)
{
	struct o2nm_cluster *cluster = to_o2nm_cluster_from_node(node);
	unsigned long tmp;
	char *p = (char *)page;
	ssize_t ret;

	tmp = simple_strtoul(p, &p, 0);
	if (!p || (*p && (*p != '\n')))
		return -EINVAL;

	tmp = !!tmp; /* boolean of whether this node wants to be local */

	/* setting local turns on networking rx for now so we require having
	 * set everything else first */
	if (!test_bit(O2NM_NODE_ATTR_ADDRESS, &node->nd_set_attributes) ||
	    !test_bit(O2NM_NODE_ATTR_NUM, &node->nd_set_attributes) ||
	    !test_bit(O2NM_NODE_ATTR_PORT, &node->nd_set_attributes))
		return -EINVAL; /* XXX */

	/* the only failure case is trying to set a new local node
	 * when a different one is already set */
	if (tmp && tmp == cluster->cl_has_local &&
	    cluster->cl_local_node != node->nd_num)
		return -EBUSY;

	/* bring up the rx thread if we're setting the new local node. */
	if (tmp && !cluster->cl_has_local) {
		ret = o2net_start_listening(node);
		if (ret)
			return ret;
	}

	if (!tmp && cluster->cl_has_local &&
	    cluster->cl_local_node == node->nd_num) {
		o2net_stop_listening(node);
		cluster->cl_local_node = O2NM_INVALID_NODE_NUM;
	}

	node->nd_local = tmp;
	if (node->nd_local) {
		cluster->cl_has_local = tmp;
		cluster->cl_local_node = node->nd_num;
	}

	return count;
}

struct o2nm_node_attribute {
	struct configfs_attribute attr;
	ssize_t (*show)(struct o2nm_node *, char *);
	ssize_t (*store)(struct o2nm_node *, const char *, size_t);
};

static struct o2nm_node_attribute o2nm_node_attr_num = {
	.attr	= { .ca_owner = THIS_MODULE,
		    .ca_name = "num",
		    .ca_mode = S_IRUGO | S_IWUSR },
	.show	= o2nm_node_num_read,
	.store	= o2nm_node_num_write,
};

static struct o2nm_node_attribute o2nm_node_attr_ipv4_port = {
	.attr	= { .ca_owner = THIS_MODULE,
		    .ca_name = "ipv4_port",
		    .ca_mode = S_IRUGO | S_IWUSR },
	.show	= o2nm_node_ipv4_port_read,
	.store	= o2nm_node_ipv4_port_write,
};

static struct o2nm_node_attribute o2nm_node_attr_ipv4_address = {
	.attr	= { .ca_owner = THIS_MODULE,
		    .ca_name = "ipv4_address",
		    .ca_mode = S_IRUGO | S_IWUSR },
	.show	= o2nm_node_ipv4_address_read,
	.store	= o2nm_node_ipv4_address_write,
};

static struct o2nm_node_attribute o2nm_node_attr_local = {
	.attr	= { .ca_owner = THIS_MODULE,
		    .ca_name = "local",
		    .ca_mode = S_IRUGO | S_IWUSR },
	.show	= o2nm_node_local_read,
	.store	= o2nm_node_local_write,
};

static struct configfs_attribute *o2nm_node_attrs[] = {
	[O2NM_NODE_ATTR_NUM] = &o2nm_node_attr_num.attr,
	[O2NM_NODE_ATTR_PORT] = &o2nm_node_attr_ipv4_port.attr,
	[O2NM_NODE_ATTR_ADDRESS] = &o2nm_node_attr_ipv4_address.attr,
	[O2NM_NODE_ATTR_LOCAL] = &o2nm_node_attr_local.attr,
	NULL,
};

static int o2nm_attr_index(struct configfs_attribute *attr)
{
	int i;
	for (i = 0; i < ARRAY_SIZE(o2nm_node_attrs); i++) {
		if (attr == o2nm_node_attrs[i])
			return i;
	}
	BUG();
	return 0;
}

static ssize_t o2nm_node_show(struct config_item *item,
			      struct configfs_attribute *attr,
			      char *page)
{
	struct o2nm_node *node = to_o2nm_node(item);
	struct o2nm_node_attribute *o2nm_node_attr =
		container_of(attr, struct o2nm_node_attribute, attr);
	ssize_t ret = 0;

	if (o2nm_node_attr->show)
		ret = o2nm_node_attr->show(node, page);
	return ret;
}

static ssize_t o2nm_node_store(struct config_item *item,
			       struct configfs_attribute *attr,
			       const char *page, size_t count)
{
	struct o2nm_node *node = to_o2nm_node(item);
	struct o2nm_node_attribute *o2nm_node_attr =
		container_of(attr, struct o2nm_node_attribute, attr);
	ssize_t ret;
	int attr_index = o2nm_attr_index(attr);

	if (o2nm_node_attr->store == NULL) {
		ret = -EINVAL;
		goto out;
	}

	if (test_bit(attr_index, &node->nd_set_attributes))
		return -EBUSY;

	ret = o2nm_node_attr->store(node, page, count);
	if (ret < count)
		goto out;

	set_bit(attr_index, &node->nd_set_attributes);
out:
	return ret;
}

static struct configfs_item_operations o2nm_node_item_ops = {
	.release		= o2nm_node_release,
	.show_attribute		= o2nm_node_show,
	.store_attribute	= o2nm_node_store,
};

static struct config_item_type o2nm_node_type = {
	.ct_item_ops	= &o2nm_node_item_ops,
	.ct_attrs	= o2nm_node_attrs,
	.ct_owner	= THIS_MODULE,
};

/* node set */

struct o2nm_node_group {
	struct config_group ns_group;
	/* some stuff? */
};

#if 0
static struct o2nm_node_group *to_o2nm_node_group(struct config_group *group)
{
	return group ?
		container_of(group, struct o2nm_node_group, ns_group)
		: NULL;
}
#endif

struct o2nm_cluster_attribute {
	struct configfs_attribute attr;
	ssize_t (*show)(struct o2nm_cluster *, char *);
	ssize_t (*store)(struct o2nm_cluster *, const char *, size_t);
};

static ssize_t o2nm_cluster_attr_write(const char *page, ssize_t count,
                                       unsigned int *val)
{
	unsigned long tmp;
	char *p = (char *)page;

	tmp = simple_strtoul(p, &p, 0);
	if (!p || (*p && (*p != '\n')))
		return -EINVAL;

	if (tmp == 0)
		return -EINVAL;
	if (tmp >= (u32)-1)
		return -ERANGE;

	*val = tmp;

	return count;
}

static ssize_t o2nm_cluster_attr_idle_timeout_ms_read(
	struct o2nm_cluster *cluster, char *page)
{
	return sprintf(page, "%u\n", cluster->cl_idle_timeout_ms);
}

static ssize_t o2nm_cluster_attr_idle_timeout_ms_write(
	struct o2nm_cluster *cluster, const char *page, size_t count)
{
	ssize_t ret;
	unsigned int val;

	ret =  o2nm_cluster_attr_write(page, count, &val);

	if (ret > 0) {
		if (cluster->cl_idle_timeout_ms != val
			&& o2net_num_connected_peers()) {
			mlog(ML_NOTICE,
			     "o2net: cannot change idle timeout after "
			     "the first peer has agreed to it."
			     "  %d connected peers\n",
			     o2net_num_connected_peers());
			ret = -EINVAL;
		} else if (val <= cluster->cl_keepalive_delay_ms) {
			mlog(ML_NOTICE, "o2net: idle timeout must be larger "
			     "than keepalive delay\n");
			ret = -EINVAL;
		} else {
			cluster->cl_idle_timeout_ms = val;
		}
	}

	return ret;
}

static ssize_t o2nm_cluster_attr_keepalive_delay_ms_read(
	struct o2nm_cluster *cluster, char *page)
{
	return sprintf(page, "%u\n", cluster->cl_keepalive_delay_ms);
}

static ssize_t o2nm_cluster_attr_keepalive_delay_ms_write(
	struct o2nm_cluster *cluster, const char *page, size_t count)
{
	ssize_t ret;
	unsigned int val;

	ret =  o2nm_cluster_attr_write(page, count, &val);

	if (ret > 0) {
		if (cluster->cl_keepalive_delay_ms != val
		    && o2net_num_connected_peers()) {
			mlog(ML_NOTICE,
			     "o2net: cannot change keepalive delay after"
			     " the first peer has agreed to it."
			     "  %d connected peers\n",
			     o2net_num_connected_peers());
			ret = -EINVAL;
		} else if (val >= cluster->cl_idle_timeout_ms) {
			mlog(ML_NOTICE, "o2net: keepalive delay must be "
			     "smaller than idle timeout\n");
			ret = -EINVAL;
		} else {
			cluster->cl_keepalive_delay_ms = val;
		}
	}

	return ret;
}

static ssize_t o2nm_cluster_attr_reconnect_delay_ms_read(
	struct o2nm_cluster *cluster, char *page)
{
	return sprintf(page, "%u\n", cluster->cl_reconnect_delay_ms);
}

static ssize_t o2nm_cluster_attr_reconnect_delay_ms_write(
	struct o2nm_cluster *cluster, const char *page, size_t count)
{
	return o2nm_cluster_attr_write(page, count,
	                               &cluster->cl_reconnect_delay_ms);
}

static ssize_t o2nm_cluster_attr_fence_method_read(
	struct o2nm_cluster *cluster, char *page)
{
	ssize_t ret = 0;

	if (cluster)
		ret = sprintf(page, "%s\n",
			      o2nm_fence_method_desc[cluster->cl_fence_method]);
	return ret;
}

static ssize_t o2nm_cluster_attr_fence_method_write(
	struct o2nm_cluster *cluster, const char *page, size_t count)
{
	unsigned int i;

	if (page[count - 1] != '\n')
		goto bail;

	for (i = 0; i < O2NM_FENCE_METHODS; ++i) {
		if (count != strlen(o2nm_fence_method_desc[i]) + 1)
			continue;
		if (strncasecmp(page, o2nm_fence_method_desc[i], count - 1))
			continue;
		if (cluster->cl_fence_method != i) {
			printk(KERN_INFO "ocfs2: Changing fence method to %s\n",
			       o2nm_fence_method_desc[i]);
			cluster->cl_fence_method = i;
		}
		return count;
	}

bail:
	return -EINVAL;
}

static struct o2nm_cluster_attribute o2nm_cluster_attr_idle_timeout_ms = {
	.attr	= { .ca_owner = THIS_MODULE,
		    .ca_name = "idle_timeout_ms",
		    .ca_mode = S_IRUGO | S_IWUSR },
	.show	= o2nm_cluster_attr_idle_timeout_ms_read,
	.store	= o2nm_cluster_attr_idle_timeout_ms_write,
};

static struct o2nm_cluster_attribute o2nm_cluster_attr_keepalive_delay_ms = {
	.attr	= { .ca_owner = THIS_MODULE,
		    .ca_name = "keepalive_delay_ms",
		    .ca_mode = S_IRUGO | S_IWUSR },
	.show	= o2nm_cluster_attr_keepalive_delay_ms_read,
	.store	= o2nm_cluster_attr_keepalive_delay_ms_write,
};

static struct o2nm_cluster_attribute o2nm_cluster_attr_reconnect_delay_ms = {
	.attr	= { .ca_owner = THIS_MODULE,
		    .ca_name = "reconnect_delay_ms",
		    .ca_mode = S_IRUGO | S_IWUSR },
	.show	= o2nm_cluster_attr_reconnect_delay_ms_read,
	.store	= o2nm_cluster_attr_reconnect_delay_ms_write,
};

static struct o2nm_cluster_attribute o2nm_cluster_attr_fence_method = {
	.attr	= { .ca_owner = THIS_MODULE,
		    .ca_name = "fence_method",
		    .ca_mode = S_IRUGO | S_IWUSR },
	.show	= o2nm_cluster_attr_fence_method_read,
	.store	= o2nm_cluster_attr_fence_method_write,
};

static struct configfs_attribute *o2nm_cluster_attrs[] = {
	&o2nm_cluster_attr_idle_timeout_ms.attr,
	&o2nm_cluster_attr_keepalive_delay_ms.attr,
	&o2nm_cluster_attr_reconnect_delay_ms.attr,
	&o2nm_cluster_attr_fence_method.attr,
	NULL,
};
static ssize_t o2nm_cluster_show(struct config_item *item,
                                 struct configfs_attribute *attr,
                                 char *page)
{
	struct o2nm_cluster *cluster = to_o2nm_cluster(item);
	struct o2nm_cluster_attribute *o2nm_cluster_attr =
		container_of(attr, struct o2nm_cluster_attribute, attr);
	ssize_t ret = 0;

	if (o2nm_cluster_attr->show)
		ret = o2nm_cluster_attr->show(cluster, page);
	return ret;
}

static ssize_t o2nm_cluster_store(struct config_item *item,
                                  struct configfs_attribute *attr,
                                  const char *page, size_t count)
{
	struct o2nm_cluster *cluster = to_o2nm_cluster(item);
	struct o2nm_cluster_attribute *o2nm_cluster_attr =
		container_of(attr, struct o2nm_cluster_attribute, attr);
	ssize_t ret;

	if (o2nm_cluster_attr->store == NULL) {
		ret = -EINVAL;
		goto out;
	}

	ret = o2nm_cluster_attr->store(cluster, page, count);
	if (ret < count)
		goto out;
out:
	return ret;
}

static struct config_item *o2nm_node_group_make_item(struct config_group *group,
						     const char *name)
{
	struct o2nm_node *node = NULL;

	if (strlen(name) > O2NM_MAX_NAME_LEN)
		return ERR_PTR(-ENAMETOOLONG);

	node = kzalloc(sizeof(struct o2nm_node), GFP_KERNEL);
	if (node == NULL)
		return ERR_PTR(-ENOMEM);

	strcpy(node->nd_name, name); /* use item.ci_namebuf instead? */
	config_item_init_type_name(&node->nd_item, name, &o2nm_node_type);
	spin_lock_init(&node->nd_lock);

	mlog(ML_CLUSTER, "o2nm: Registering node %s\n", name);

	return &node->nd_item;
}

static void o2nm_node_group_drop_item(struct config_group *group,
				      struct config_item *item)
{
	struct o2nm_node *node = to_o2nm_node(item);
	struct o2nm_cluster *cluster = to_o2nm_cluster(group->cg_item.ci_parent);

	o2net_disconnect_node(node);

	if (cluster->cl_has_local &&
	    (cluster->cl_local_node == node->nd_num)) {
		cluster->cl_has_local = 0;
		cluster->cl_local_node = O2NM_INVALID_NODE_NUM;
		o2net_stop_listening(node);
	}

	/* XXX call into net to stop this node from trading messages */

	write_lock(&cluster->cl_nodes_lock);

	/* XXX sloppy */
	if (node->nd_ipv4_address)
		rb_erase(&node->nd_ip_node, &cluster->cl_node_ip_tree);

	/* nd_num might be 0 if the node number hasn't been set.. */
	if (cluster->cl_nodes[node->nd_num] == node) {
		cluster->cl_nodes[node->nd_num] = NULL;
		clear_bit(node->nd_num, cluster->cl_nodes_bitmap);
	}
	write_unlock(&cluster->cl_nodes_lock);

	mlog(ML_CLUSTER, "o2nm: Unregistered node %s\n",
	     config_item_name(&node->nd_item));

	config_item_put(item);
}

static struct configfs_group_operations o2nm_node_group_group_ops = {
	.make_item	= o2nm_node_group_make_item,
	.drop_item	= o2nm_node_group_drop_item,
};

static struct config_item_type o2nm_node_group_type = {
	.ct_group_ops	= &o2nm_node_group_group_ops,
	.ct_owner	= THIS_MODULE,
};

/* cluster */

static void o2nm_cluster_release(struct config_item *item)
{
	struct o2nm_cluster *cluster = to_o2nm_cluster(item);

	kfree(cluster->cl_group.default_groups);
	kfree(cluster);
}

static struct configfs_item_operations o2nm_cluster_item_ops = {
	.release	= o2nm_cluster_release,
	.show_attribute		= o2nm_cluster_show,
	.store_attribute	= o2nm_cluster_store,
};

static struct config_item_type o2nm_cluster_type = {
	.ct_item_ops	= &o2nm_cluster_item_ops,
	.ct_attrs	= o2nm_cluster_attrs,
	.ct_owner	= THIS_MODULE,
};

/* cluster set */

struct o2nm_cluster_group {
	struct configfs_subsystem cs_subsys;
	/* some stuff? */
};

#if 0
static struct o2nm_cluster_group *to_o2nm_cluster_group(struct config_group *group)
{
	return group ?
		container_of(to_configfs_subsystem(group), struct o2nm_cluster_group, cs_subsys)
	       : NULL;
}
#endif

static struct config_group *o2nm_cluster_group_make_group(struct config_group *group,
							  const char *name)
{
	struct o2nm_cluster *cluster = NULL;
	struct o2nm_node_group *ns = NULL;
	struct config_group *o2hb_group = NULL, *ret = NULL;
	void *defs = NULL;

	/* this runs under the parent dir's i_mutex; there can be only
	 * one caller in here at a time */
	if (o2nm_single_cluster)
		return ERR_PTR(-ENOSPC);

	cluster = kzalloc(sizeof(struct o2nm_cluster), GFP_KERNEL);
	ns = kzalloc(sizeof(struct o2nm_node_group), GFP_KERNEL);
	defs = kcalloc(3, sizeof(struct config_group *), GFP_KERNEL);
	o2hb_group = o2hb_alloc_hb_set();
	if (cluster == NULL || ns == NULL || o2hb_group == NULL || defs == NULL)
		goto out;

	config_group_init_type_name(&cluster->cl_group, name,
				    &o2nm_cluster_type);
	config_group_init_type_name(&ns->ns_group, "node",
				    &o2nm_node_group_type);

	cluster->cl_group.default_groups = defs;
	cluster->cl_group.default_groups[0] = &ns->ns_group;
	cluster->cl_group.default_groups[1] = o2hb_group;
	cluster->cl_group.default_groups[2] = NULL;
	rwlock_init(&cluster->cl_nodes_lock);
	cluster->cl_node_ip_tree = RB_ROOT;
	cluster->cl_reconnect_delay_ms = O2NET_RECONNECT_DELAY_MS_DEFAULT;
	cluster->cl_idle_timeout_ms    = O2NET_IDLE_TIMEOUT_MS_DEFAULT;
	cluster->cl_keepalive_delay_ms = O2NET_KEEPALIVE_DELAY_MS_DEFAULT;
	cluster->cl_fence_method       = O2NM_FENCE_RESET;

	ret = &cluster->cl_group;
	o2nm_single_cluster = cluster;

out:
	if (ret == NULL) {
		kfree(cluster);
		kfree(ns);
		o2hb_free_hb_set(o2hb_group);
		kfree(defs);
		ret = ERR_PTR(-ENOMEM);
	}

	return ret;
}

static void o2nm_cluster_group_drop_item(struct config_group *group, struct config_item *item)
{
	struct o2nm_cluster *cluster = to_o2nm_cluster(item);
	int i;
	struct config_item *killme;

	BUG_ON(o2nm_single_cluster != cluster);
	o2nm_single_cluster = NULL;

	for (i = 0; cluster->cl_group.default_groups[i]; i++) {
		killme = &cluster->cl_group.default_groups[i]->cg_item;
		cluster->cl_group.default_groups[i] = NULL;
		config_item_put(killme);
	}

	config_item_put(item);
}

static struct configfs_group_operations o2nm_cluster_group_group_ops = {
	.make_group	= o2nm_cluster_group_make_group,
	.drop_item	= o2nm_cluster_group_drop_item,
};

static struct config_item_type o2nm_cluster_group_type = {
	.ct_group_ops	= &o2nm_cluster_group_group_ops,
	.ct_owner	= THIS_MODULE,
};

static struct o2nm_cluster_group o2nm_cluster_group = {
	.cs_subsys = {
		.su_group = {
			.cg_item = {
				.ci_namebuf = "cluster",
				.ci_type = &o2nm_cluster_group_type,
			},
		},
	},
};

int o2nm_depend_item(struct config_item *item)
{
	return configfs_depend_item(&o2nm_cluster_group.cs_subsys, item);
}

void o2nm_undepend_item(struct config_item *item)
{
	configfs_undepend_item(&o2nm_cluster_group.cs_subsys, item);
}

int o2nm_depend_this_node(void)
{
	int ret = 0;
	struct o2nm_node *local_node;

	local_node = o2nm_get_node_by_num(o2nm_this_node());
	if (!local_node) {
		ret = -EINVAL;
		goto out;
	}

	ret = o2nm_depend_item(&local_node->nd_item);
	o2nm_node_put(local_node);

out:
	return ret;
}

void o2nm_undepend_this_node(void)
{
	struct o2nm_node *local_node;

	local_node = o2nm_get_node_by_num(o2nm_this_node());
	BUG_ON(!local_node);

	o2nm_undepend_item(&local_node->nd_item);
	o2nm_node_put(local_node);
}


static void __exit exit_o2nm(void)
{
	/* XXX sync with hb callbacks and shut down hb? */
	o2net_unregister_hb_callbacks();
	configfs_unregister_subsystem(&o2nm_cluster_group.cs_subsys);
	o2cb_sys_shutdown();

	o2net_exit();
	o2hb_exit();
}

static int __init init_o2nm(void)
{
	int ret = -1;

	ret = o2hb_init();
	if (ret)
		goto out;

	ret = o2net_init();
	if (ret)
		goto out_o2hb;

	ret = o2net_register_hb_callbacks();
	if (ret)
		goto out_o2net;

	config_group_init(&o2nm_cluster_group.cs_subsys.su_group);
	mutex_init(&o2nm_cluster_group.cs_subsys.su_mutex);
	ret = configfs_register_subsystem(&o2nm_cluster_group.cs_subsys);
	if (ret) {
		printk(KERN_ERR "nodemanager: Registration returned %d\n", ret);
		goto out_callbacks;
	}

	ret = o2cb_sys_init();
	if (!ret)
		goto out;

	configfs_unregister_subsystem(&o2nm_cluster_group.cs_subsys);
out_callbacks:
	o2net_unregister_hb_callbacks();
out_o2net:
	o2net_exit();
out_o2hb:
	o2hb_exit();
out:
	return ret;
}

MODULE_AUTHOR("Oracle");
MODULE_LICENSE("GPL");
MODULE_DESCRIPTION("OCFS2 cluster management");

module_init(init_o2nm)
module_exit(exit_o2nm)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     /*
 * leds-regulator.h - platform data structure for regulator driven LEDs.
 *
 * Copyright (C) 2009 Antonio Ospite <ospite@studenti.unina.it>
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License version 2 as
 * published by the Free Software Foundation.
 *
 */

#ifndef __LINUX_LEDS_REGULATOR_H
#define __LINUX_LEDS_REGULATOR_H

/*
 * Use "vled" as supply id when declaring the regulator consumer:
 *
 * static struct regulator_consumer_supply pcap_regulator_VVIB_consumers [] = {
 * 	{ .dev_name = "leds-regulator.0", .supply = "vled" },
 * };
 *
 * If you have several regulator driven LEDs, you can append a numerical id to
 * .dev_name as done above, and use the same id when declaring the platform
 * device:
 *
 * static struct led_regulator_platform_data a780_vibrator_data = {
 * 	.name   = "a780::vibrator",
 * };
 *
 * static struct platform_device a780_vibrator = {
 * 	.name = "leds-regulator",
 * 	.id   = 0,
 * 	.dev  = {
 * 		.platform_data = &a780_vibrator_data,
 * 	},
 * };
 */

#include <linux/leds.h>

struct led_regulator_platform_data {
	char *name;                     /* LED name as expected by LED class */
	enum led_brightness brightness; /* initial brightness value */
};

#endif /* __LINUX_LEDS_REGULATOR_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           #ifndef _NET_IP6_TUNNEL_H
#define _NET_IP6_TUNNEL_H

#include <linux/ipv6.h>
#include <linux/netdevice.h>
#include <linux/if_tunnel.h>
#include <linux/ip6_tunnel.h>

#define IP6TUNNEL_ERR_TIMEO (30*HZ)

/* capable of sending packets */
#define IP6_TNL_F_CAP_XMIT 0x10000
/* capable of receiving packets */
#define IP6_TNL_F_CAP_RCV 0x20000
/* determine capability on a per-packet basis */
#define IP6_TNL_F_CAP_PER_PACKET 0x40000

struct __ip6_tnl_parm {
	char name[IFNAMSIZ];	/* name of tunnel device */
	int link;		/* ifindex of underlying L2 interface */
	__u8 proto;		/* tunnel protocol */
	__u8 encap_limit;	/* encapsulation limit for tunnel */
	__u8 hop_limit;		/* hop limit for tunnel */
	__be32 flowinfo;	/* traffic class and flowlabel for tunnel */
	__u32 flags;		/* tunnel flags */
	struct in6_addr laddr;	/* local tunnel end-point address */
	struct in6_addr raddr;	/* remote tunnel end-point address */

	__be16			i_flags;
	__be16			o_flags;
	__be32			i_key;
	__be32			o_key;
};

/* IPv6 tunnel */
struct ip6_tnl {
	struct ip6_tnl __rcu *next;	/* next tunnel in list */
	struct net_device *dev;	/* virtual device associated with tunnel */
	struct net *net;	/* netns for packet i/o */
	struct __ip6_tnl_parm parms;	/* tunnel configuration parameters */
	struct flowi fl;	/* flowi template for xmit */
	struct dst_entry *dst_cache;    /* cached dst */
	u32 dst_cookie;

	int err_count;
	unsigned long err_time;

	/* These fields used only by GRE */
	__u32 i_seqno;	/* The last seen seqno	*/
	__u32 o_seqno;	/* The last output seqno */
	int hlen;       /* Precalculated GRE header length */
	int mlink;
};

/* Tunnel encapsulation limit destination sub-option */

struct ipv6_tlv_tnl_enc_lim {
	__u8 type;		/* type-code for option         */
	__u8 length;		/* option length                */
	__u8 encap_limit;	/* tunnel encapsulation limit   */
} __packed;

struct dst_entry *ip6_tnl_dst_check(struct ip6_tnl *t);
void ip6_tnl_dst_reset(struct ip6_tnl *t);
void ip6_tnl_dst_store(struct ip6_tnl *t, struct dst_entry *dst);
int ip6_tnl_rcv_ctl(struct ip6_tnl *t, const struct in6_addr *laddr,
		const struct in6_addr *raddr);
int ip6_tnl_xmit_ctl(struct ip6_tnl *t);
__u16 ip6_tnl_parse_tlv_enc_lim(struct sk_buff *skb, __u8 *raw);
__u32 ip6_tnl_get_cap(struct ip6_tnl *t, const struct in6_addr *laddr,
			     const struct in6_addr *raddr);

static inline void ip6tunnel_xmit(struct sk_buff *skb, struct net_device *dev)
{
	struct net_device_stats *stats = &dev->stats;
	int pkt_len, err;

	pkt_len = skb->len;
	err = ip6_local_out(skb);

	if (net_xmit_eval(err) == 0) {
		struct pcpu_sw_netstats *tstats = get_cpu_ptr(dev->tstats);
		u64_stats_update_begin(&tstats->syncp);
		tstats->tx_bytes += pkt_len;
		tstats->tx_packets++;
		u64_stats_update_end(&tstats->syncp);
		put_cpu_ptr(tstats);
	} else {
		stats->tx_errors++;
		stats->tx_aborted_errors++;
	}
}
#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   /*
 * kernel/power/main.c - PM subsystem core functionality.
 *
 * Copyright (c) 2003 Patrick Mochel
 * Copyright (c) 2003 Open Source Development Lab
 *
 * This file is released under the GPLv2
 *
 */

#include <linux/export.h>
#include <linux/kobject.h>
#include <linux/string.h>
#include <linux/resume-trace.h>
#include <linux/workqueue.h>
#include <linux/debugfs.h>
#include <linux/seq_file.h>

#include "power.h"

#define HIB_PM_DEBUG 1
#define _TAG_HIB_M "HIB/PM"
#if (HIB_PM_DEBUG)
#undef hib_log
#define hib_log(fmt, ...)  pr_warn("[%s][%s]" fmt, _TAG_HIB_M, __func__, ##__VA_ARGS__)
#else
#define hib_log(fmt, ...)
#endif
#undef hib_warn
#define hib_warn(fmt, ...) pr_warn("[%s][%s]" fmt, _TAG_HIB_M, __func__, ##__VA_ARGS__)

DEFINE_MUTEX(pm_mutex);
EXPORT_SYMBOL_GPL(pm_mutex);

#ifdef CONFIG_PM_SLEEP

/* Routines for PM-transition notifications */

static BLOCKING_NOTIFIER_HEAD(pm_chain_head);

int register_pm_notifier(struct notifier_block *nb)
{
	return blocking_notifier_chain_register(&pm_chain_head, nb);
}
EXPORT_SYMBOL_GPL(register_pm_notifier);

int unregister_pm_notifier(struct notifier_block *nb)
{
	return blocking_notifier_chain_unregister(&pm_chain_head, nb);
}
EXPORT_SYMBOL_GPL(unregister_pm_notifier);

int pm_notifier_call_chain(unsigned long val)
{
	int ret = blocking_notifier_call_chain(&pm_chain_head, val, NULL);

	return notifier_to_errno(ret);
}
EXPORT_SYMBOL_GPL(pm_notifier_call_chain);

/* If set, devices may be suspended and resumed asynchronously. */
int pm_async_enabled = 1;

static ssize_t pm_async_show(struct kobject *kobj, struct kobj_attribute *attr,
			     char *buf)
{
	return sprintf(buf, "%d\n", pm_async_enabled);
}

static ssize_t pm_async_store(struct kobject *kobj, struct kobj_attribute *attr,
			      const char *buf, size_t n)
{
	unsigned long val;

	if (kstrtoul(buf, 10, &val))
		return -EINVAL;

	if (val > 1)
		return -EINVAL;

	pm_async_enabled = val;
	return n;
}

power_attr(pm_async);

#ifdef CONFIG_PM_DEBUG
int pm_test_level = TEST_NONE;

static const char * const pm_tests[__TEST_AFTER_LAST] = {
	[TEST_NONE] = "none",
	[TEST_CORE] = "core",
	[TEST_CPUS] = "processors",
	[TEST_PLATFORM] = "platform",
	[TEST_DEVICES] = "devices",
	[TEST_FREEZER] = "freezer",
};

static ssize_t pm_test_show(struct kobject *kobj, struct kobj_attribute *attr,
				char *buf)
{
	char *s = buf;
	int level;

	for (level = TEST_FIRST; level <= TEST_MAX; level++)
		if (pm_tests[level]) {
			if (level == pm_test_level)
				s += sprintf(s, "[%s] ", pm_tests[level]);
			else
				s += sprintf(s, "%s ", pm_tests[level]);
		}

	if (s != buf)
		/* convert the last space to a newline */
		*(s-1) = '\n';

	return (s - buf);
}

static ssize_t pm_test_store(struct kobject *kobj, struct kobj_attribute *attr,
				const char *buf, size_t n)
{
	const char * const *s;
	int level;
	char *p;
	int len;
	int error = -EINVAL;

	p = memchr(buf, '\n', n);
	len = p ? p - buf : n;

	lock_system_sleep();

	level = TEST_FIRST;
	for (s = &pm_tests[level]; level <= TEST_MAX; s++, level++)
		if (*s && len == strlen(*s) && !strncmp(buf, *s, len)) {
			pm_test_level = level;
			error = 0;
			break;
		}

	unlock_system_sleep();

	return error ? error : n;
}

power_attr(pm_test);
#endif /* CONFIG_PM_DEBUG */

#ifdef CONFIG_DEBUG_FS
static char *suspend_step_name(enum suspend_stat_step step)
{
	switch (step) {
	case SUSPEND_FREEZE:
		return "freeze";
	case SUSPEND_PREPARE:
		return "prepare";
	case SUSPEND_SUSPEND:
		return "suspend";
	case SUSPEND_SUSPEND_NOIRQ:
		return "suspend_noirq";
	case SUSPEND_RESUME_NOIRQ:
		return "resume_noirq";
	case SUSPEND_RESUME:
		return "resume";
	default:
		return "";
	}
}

static int suspend_stats_show(struct seq_file *s, void *unused)
{
	int i, index, last_dev, last_errno, last_step;

	last_dev = suspend_stats.last_failed_dev + REC_FAILED_NUM - 1;
	last_dev %= REC_FAILED_NUM;
	last_errno = suspend_stats.last_failed_errno + REC_FAILED_NUM - 1;
	last_errno %= REC_FAILED_NUM;
	last_step = suspend_stats.last_failed_step + REC_FAILED_NUM - 1;
	last_step %= REC_FAILED_NUM;
	seq_printf(s, "%s: %d\n%s: %d\n%s: %d\n%s: %d\n%s: %d\n"
			"%s: %d\n%s: %d\n%s: %d\n%s: %d\n%s: %d\n",
			"success", suspend_stats.success,
			"fail", suspend_stats.fail,
			"failed_freeze", suspend_stats.failed_freeze,
			"failed_prepare", suspend_stats.failed_prepare,
			"failed_suspend", suspend_stats.failed_suspend,
			"failed_suspend_late",
				suspend_stats.failed_suspend_late,
			"failed_suspend_noirq",
				suspend_stats.failed_suspend_noirq,
			"failed_resume", suspend_stats.failed_resume,
			"failed_resume_early",
				suspend_stats.failed_resume_early,
			"failed_resume_noirq",
				suspend_stats.failed_resume_noirq);
	seq_printf(s,	"failures:\n  last_failed_dev:\t%-s\n",
			suspend_stats.failed_devs[last_dev]);
	for (i = 1; i < REC_FAILED_NUM; i++) {
		index = last_dev + REC_FAILED_NUM - i;
		index %= REC_FAILED_NUM;
		seq_printf(s, "\t\t\t%-s\n",
			suspend_stats.failed_devs[index]);
	}
	seq_printf(s,	"  last_failed_errno:\t%-d\n",
			suspend_stats.errno[last_errno]);
	for (i = 1; i < REC_FAILED_NUM; i++) {
		index = last_errno + REC_FAILED_NUM - i;
		index %= REC_FAILED_NUM;
		seq_printf(s, "\t\t\t%-d\n",
			suspend_stats.errno[index]);
	}
	seq_printf(s,	"  last_failed_step:\t%-s\n",
			suspend_step_name(
				suspend_stats.failed_steps[last_step]));
	for (i = 1; i < REC_FAILED_NUM; i++) {
		index = last_step + REC_FAILED_NUM - i;
		index %= REC_FAILED_NUM;
		seq_printf(s, "\t\t\t%-s\n",
			suspend_step_name(
				suspend_stats.failed_steps[index]));
	}

	return 0;
}

static int suspend_stats_open(struct inode *inode, struct file *file)
{
	return single_open(file, suspend_stats_show, NULL);
}

static const struct file_operations suspend_stats_operations = {
	.open           = suspend_stats_open,
	.read           = seq_read,
	.llseek         = seq_lseek,
	.release        = single_release,
};

static int __init pm_debugfs_init(void)
{
	debugfs_create_file("suspend_stats", S_IFREG | S_IRUGO,
			NULL, NULL, &suspend_stats_operations);
	return 0;
}

late_initcall(pm_debugfs_init);
#endif /* CONFIG_DEBUG_FS */

#endif /* CONFIG_PM_SLEEP */

#ifdef CONFIG_PM_SLEEP_DEBUG
/*
 * pm_print_times: print time taken by devices to suspend and resume.
 *
 * show() returns whether printing of suspend and resume times is enabled.
 * store() accepts 0 or 1.  0 disables printing and 1 enables it.
 */
bool pm_print_times_enabled;

static ssize_t pm_print_times_show(struct kobject *kobj,
				   struct kobj_attribute *attr, char *buf)
{
	return sprintf(buf, "%d\n", pm_print_times_enabled);
}

static ssize_t pm_print_times_store(struct kobject *kobj,
				    struct kobj_attribute *attr,
				    const char *buf, size_t n)
{
	unsigned long val;

	if (kstrtoul(buf, 10, &val))
		return -EINVAL;

	if (val > 1)
		return -EINVAL;

	pm_print_times_enabled = !!val;
	return n;
}

power_attr(pm_print_times);

static inline void pm_print_times_init(void)
{
	pm_print_times_enabled = !!initcall_debug;
}
#else /* !CONFIG_PP_SLEEP_DEBUG */
static inline void pm_print_times_init(void) {}
#endif /* CONFIG_PM_SLEEP_DEBUG */

struct kobject *power_kobj;
EXPORT_SYMBOL_GPL(power_kobj);

/**
 * state - control system sleep states.
 *
 * show() returns available sleep state labels, which may be "mem", "standby",
 * "freeze" and "disk" (hibernation).  See Documentation/power/states.txt for a
 * description of what they mean.
 *
 * store() accepts one of those strings, translates it into the proper
 * enumerated value, and initiates a suspend transition.
 */
static ssize_t state_show(struct kobject *kobj, struct kobj_attribute *attr,
			  char *buf)
{
	char *s = buf;
#ifdef CONFIG_SUSPEND
	suspend_state_t i;

	for (i = PM_SUSPEND_MIN; i < PM_SUSPEND_MAX; i++)
		if (pm_states[i])
			s += sprintf(s,"%s ", pm_states[i]);

#endif
	if (hibernation_available())
		s += sprintf(s, "disk ");
	if (s != buf)
		/* convert the last space to a newline */
		*(s-1) = '\n';
	return (s - buf);
}

static suspend_state_t decode_state(const char *buf, size_t n)
{
#ifdef CONFIG_SUSPEND
	suspend_state_t state;
#endif
	char *p;
	int len;

	p = memchr(buf, '\n', n);
	len = p ? p - buf : n;

	/* Check hibernation first. */
	if (len == 4 && !strncmp(buf, "disk", len))
		return PM_SUSPEND_MAX;

#ifdef CONFIG_SUSPEND
	for (state = PM_SUSPEND_MIN; state < PM_SUSPEND_MAX; state++) {
		const char *label = pm_states[state];

		if (label && len == strlen(label) && !strncmp(buf, label, len))
			return state;
	}
#endif

	return PM_SUSPEND_ON;
}

static ssize_t state_store(struct kobject *kobj, struct kobj_attribute *attr,
			   const char *buf, size_t n)
{
	suspend_state_t state;
	int error;

#ifdef CONFIG_MTK_HIBERNATION
	char *p;
	int len;
#endif

	error = pm_autosleep_lock();
	if (error)
		return error;

	if (pm_autosleep_state() > PM_SUSPEND_ON) {
		error = -EBUSY;
		goto out;
	}

	state = decode_state(buf, n);

#ifdef CONFIG_MTK_HIBERNATION
	p = memchr(buf, '\n', n);
	len = p ? p - buf : n;
	if (len == 8 && !strncmp(buf, "hibabort", len)) {
		hib_log("abort hibernation...\n");
		error = mtk_hibernate_abort();
		goto out;
	}
#endif

	pr_warn("[%s]: state = (%d)\n", __func__, state);

	if (state < PM_SUSPEND_MAX) {
		error = pm_suspend(state);
		pr_warn("[%s]: pm_suspend() return (%d)\n", __func__, error);
	} else if (state == PM_SUSPEND_MAX) {
#ifdef CONFIG_MTK_HIBERNATION
		hib_log("trigger hibernation...\n");
		if (!pre_hibernate()) {
			error = 0;
			error = mtk_hibernate();
		}
#else /* !CONFIG_MTK_HIBERNATION */
		error = hibernate();
#endif /* CONFIG_MTK_HIBERNATION */
	} else {
		error = -EINVAL;
	}

 out:
	pm_autosleep_unlock();
	return error ? error : n;
}

power_attr(state);

#ifdef CONFIG_PM_SLEEP
/*
 * The 'wakeup_count' attribute, along with the functions defined in
 * drivers/base/power/wakeup.c, provides a means by which wakeup events can be
 * handled in a non-racy way.
 *
 * If a wakeup event occurs when the system is in a sleep state, it simply is
 * woken up.  In turn, if an event that would wake the system up from a sleep
 * state occurs when it is undergoing a transition to that sleep state, the
 * transition should be aborted.  Moreover, if such an event occurs when the
 * system is in the working state, an attempt to start a transition to the
 * given sleep state should fail during certain period after the detection of
 * the event.  Using the 'state' attribute alone is not sufficient to satisfy
 * these requirements, because a wakeup event may occur exactly when 'state'
 * is being written to and may be delivered to user space right before it is
 * frozen, so the event will remain only partially processed until the system is
 * woken up by another event.  In particular, it won't cause the transition to
 * a sleep state to be aborted.
 *
 * This difficulty may be overcome if user space uses 'wakeup_count' before
 * writing to 'state'.  It first should read from 'wakeup_count' and store
 * the read value.  Then, after carrying out its own preparations for the system
 * transition to a sleep state, it should write the stored value to
 * 'wakeup_count'.  If that fails, at least one wakeup event has occurred since
 * 'wakeup_count' was read and 'state' should not be written to.  Otherwise, it
 * is allowed to write to 'state', but the transition will be aborted if there
 * are any wakeup events detected after 'wakeup_count' was written to.
 */

static ssize_t wakeup_count_show(struct kobject *kobj,
				struct kobj_attribute *attr,
				char *buf)
{
	unsigned int val;

	return pm_get_wakeup_count(&val, true) ?
		sprintf(buf, "%u\n", val) : -EINTR;
}

static ssize_t wakeup_count_store(struct kobject *kobj,
				struct kobj_attribute *attr,
				const char *buf, size_t n)
{
	unsigned int val;
	int error;

	error = pm_autosleep_lock();
	if (error)
		return error;

	if (pm_autosleep_state() > PM_SUSPEND_ON) {
		error = -EBUSY;
		goto out;
	}

	error = -EINVAL;
	if (sscanf(buf, "%u", &val) == 1) {
		if (pm_save_wakeup_count(val))
			error = n;
		else
			pm_print_active_wakeup_sources();
	}

 out:
	pm_autosleep_unlock();
	return error;
}

power_attr(wakeup_count);

#ifdef CONFIG_PM_AUTOSLEEP
static ssize_t autosleep_show(struct kobject *kobj,
			      struct kobj_attribute *attr,
			      char *buf)
{
	suspend_state_t state = pm_autosleep_state();

	if (state == PM_SUSPEND_ON)
		return sprintf(buf, "off\n");

#ifdef CONFIG_SUSPEND
	if (state < PM_SUSPEND_MAX)
		return sprintf(buf, "%s\n", pm_states[state] ?
					pm_states[state] : "error");
#endif
#ifdef CONFIG_HIBERNATION
	return sprintf(buf, "disk\n");
#else
	return sprintf(buf, "error");
#endif
}

static ssize_t autosleep_store(struct kobject *kobj,
			       struct kobj_attribute *attr,
			       const char *buf, size_t n)
{
	suspend_state_t state = decode_state(buf, n);
	int error;

	if (state == PM_SUSPEND_ON
	    && strcmp(buf, "off") && strcmp(buf, "off\n"))
		return -EINVAL;

	error = pm_autosleep_set_state(state);
	return error ? error : n;
}

power_attr(autosleep);
#endif /* CONFIG_PM_AUTOSLEEP */

#ifdef CONFIG_PM_WAKELOCKS
static ssize_t wake_lock_show(struct kobject *kobj,
			      struct kobj_attribute *attr,
			      char *buf)
{
	return pm_show_wakelocks(buf, true);
}

static ssize_t wake_lock_store(struct kobject *kobj,
			       struct kobj_attribute *attr,
			       const char *buf, size_t n)
{
	int error = pm_wake_lock(buf);
	return error ? error : n;
}

power_attr(wake_lock);

static ssize_t wake_unlock_show(struct kobject *kobj,
				struct kobj_attribute *attr,
				char *buf)
{
	return pm_show_wakelocks(buf, false);
}

static ssize_t wake_unlock_store(struct kobject *kobj,
				 struct kobj_attribute *attr,
				 const char *buf, size_t n)
{
	int error = pm_wake_unlock(buf);
	return error ? error : n;
}

power_attr(wake_unlock);

#endif /* CONFIG_PM_WAKELOCKS */
#endif /* CONFIG_PM_SLEEP */

#ifdef CONFIG_PM_TRACE
int pm_trace_enabled;

static ssize_t pm_trace_show(struct kobject *kobj, struct kobj_attribute *attr,
			     char *buf)
{
	return sprintf(buf, "%d\n", pm_trace_enabled);
}

static ssize_t
pm_trace_store(struct kobject *kobj, struct kobj_attribute *attr,
	       const char *buf, size_t n)
{
	int val;

	if (sscanf(buf, "%d", &val) == 1) {
		pm_trace_enabled = !!val;
		if (pm_trace_enabled) {
			pr_warn("PM: Enabling pm_trace changes system date and time during resume.\n"
				"PM: Correct system time has to be restored manually after resume.\n");
		}
		return n;
	}
	return -EINVAL;
}

power_attr(pm_trace);

static ssize_t pm_trace_dev_match_show(struct kobject *kobj,
				       struct kobj_attribute *attr,
				       char *buf)
{
	return show_trace_dev_match(buf, PAGE_SIZE);
}

static ssize_t
pm_trace_dev_match_store(struct kobject *kobj, struct kobj_attribute *attr,
			 const char *buf, size_t n)
{
	return -EINVAL;
}

power_attr(pm_trace_dev_match);

#endif /* CONFIG_PM_TRACE */

#ifdef CONFIG_FREEZER
static ssize_t pm_freeze_timeout_show(struct kobject *kobj,
				      struct kobj_attribute *attr, char *buf)
{
	return sprintf(buf, "%u\n", freeze_timeout_msecs);
}

static ssize_t pm_freeze_timeout_store(struct kobject *kobj,
				       struct kobj_attribute *attr,
				       const char *buf, size_t n)
{
	unsigned long val;

	if (kstrtoul(buf, 10, &val))
		return -EINVAL;

	freeze_timeout_msecs = val;
	return n;
}

power_attr(pm_freeze_timeout);

#endif	/* CONFIG_FREEZER*/

static struct attribute * g[] = {
	&state_attr.attr,
#ifdef CONFIG_PM_TRACE
	&pm_trace_attr.attr,
	&pm_trace_dev_match_attr.attr,
#endif
#ifdef CONFIG_PM_SLEEP
	&pm_async_attr.attr,
	&wakeup_count_attr.attr,
#ifdef CONFIG_PM_AUTOSLEEP
	&autosleep_attr.attr,
#endif
#ifdef CONFIG_PM_WAKELOCKS
	&wake_lock_attr.attr,
	&wake_unlock_attr.attr,
#endif
#ifdef CONFIG_PM_DEBUG
	&pm_test_attr.attr,
#endif
#ifdef CONFIG_PM_SLEEP_DEBUG
	&pm_print_times_attr.attr,
#endif
#endif
#ifdef CONFIG_FREEZER
	&pm_freeze_timeout_attr.attr,
#endif
	NULL,
};

static struct attribute_group attr_group = {
	.attrs = g,
};

struct workqueue_struct *pm_wq;
EXPORT_SYMBOL_GPL(pm_wq);

static int __init pm_start_workqueue(void)
{
	pm_wq = alloc_workqueue("pm", WQ_FREEZABLE, 0);

	return pm_wq ? 0 : -ENOMEM;
}

static int __init pm_init(void)
{
	int error = pm_start_workqueue();
	if (error)
		return error;
	hibernate_image_size_init();
	hibernate_reserved_size_init();
	power_kobj = kobject_create_and_add("power", NULL);
	if (!power_kobj)
		return -ENOMEM;
	error = sysfs_create_group(power_kobj, &attr_group);
	if (error)
		return error;
	pm_print_times_init();
	return pm_autosleep_init();
}

core_initcall(pm_init);
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         /*
 * xt_LED.c - netfilter target to make LEDs blink upon packet matches
 *
 * Copyright (C) 2008 Adam Nielsen <a.nielsen@shikadi.net>
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; version 2 of the License.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
 * 02110-1301 USA.
 *
 */
#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
#include <linux/module.h>
#include <linux/skbuff.h>
#include <linux/netfilter/x_tables.h>
#include <linux/slab.h>
#include <linux/leds.h>
#include <linux/mutex.h>

#include <linux/netfilter/xt_LED.h>

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Adam Nielsen <a.nielsen@shikadi.net>");
MODULE_DESCRIPTION("Xtables: trigger LED devices on packet match");
MODULE_ALIAS("ipt_LED");
MODULE_ALIAS("ip6t_LED");

static LIST_HEAD(xt_led_triggers);
static DEFINE_MUTEX(xt_led_mutex);

/*
 * This is declared in here (the kernel module) only, to avoid having these
 * dependencies in userspace code.  This is what xt_led_info.internal_data
 * points to.
 */
struct xt_led_info_internal {
	struct list_head list;
	int refcnt;
	char *trigger_id;
	struct led_trigger netfilter_led_trigger;
	struct timer_list timer;
};

#define XT_LED_BLINK_DELAY 50 /* ms */

static unsigned int
led_tg(struct sk_buff *skb, const struct xt_action_param *par)
{
	const struct xt_led_info *ledinfo = par->targinfo;
	struct xt_led_info_internal *ledinternal = ledinfo->internal_data;
	unsigned long led_delay = XT_LED_BLINK_DELAY;

	/*
	 * If "always blink" is enabled, and there's still some time until the
	 * LED will switch off, briefly switch it off now.
	 */
	if ((ledinfo->delay > 0) && ledinfo->always_blink &&
	    timer_pending(&ledinternal->timer))
		led_trigger_blink_oneshot(&ledinternal->netfilter_led_trigger,
					  &led_delay, &led_delay, 1);
	else
		led_trigger_event(&ledinternal->netfilter_led_trigger, LED_FULL);

	/* If there's a positive delay, start/update the timer */
	if (ledinfo->delay > 0) {
		mod_timer(&ledinternal->timer,
			  jiffies + msecs_to_jiffies(ledinfo->delay));

	/* Otherwise if there was no delay given, blink as fast as possible */
	} else if (ledinfo->delay == 0) {
		led_trigger_event(&ledinternal->netfilter_led_trigger, LED_OFF);
	}

	/* else the delay is negative, which means switch on and stay on */

	return XT_CONTINUE;
}

static void led_timeout_callback(unsigned long data)
{
	struct xt_led_info_internal *ledinternal = (struct xt_led_info_internal *)data;

	led_trigger_event(&ledinternal->netfilter_led_trigger, LED_OFF);
}

static struct xt_led_info_internal *led_trigger_lookup(const char *name)
{
	struct xt_led_info_internal *ledinternal;

	list_for_each_entry(ledinternal, &xt_led_triggers, list) {
		if (!strcmp(name, ledinternal->netfilter_led_trigger.name)) {
			return ledinternal;
		}
	}
	return NULL;
}

static int led_tg_check(const struct xt_tgchk_param *par)
{
	struct xt_led_info *ledinfo = par->targinfo;
	struct xt_led_info_internal *ledinternal;
	int err;

	if (ledinfo->id[0] == '\0') {
		pr_info("No 'id' parameter given.\n");
		return -EINVAL;
	}

	mutex_lock(&xt_led_mutex);

	ledinternal = led_trigger_lookup(ledinfo->id);
	if (ledinternal) {
		ledinternal->refcnt++;
		goto out;
	}

	err = -ENOMEM;
	ledinternal = kzalloc(sizeof(struct xt_led_info_internal), GFP_KERNEL);
	if (!ledinternal)
		goto exit_mutex_only;

	ledinternal->trigger_id = kstrdup(ledinfo->id, GFP_KERNEL);
	if (!ledinternal->trigger_id)
		goto exit_internal_alloc;

	ledinternal->refcnt = 1;
	ledinternal->netfilter_led_trigger.name = ledinternal->trigger_id;

	err = led_trigger_register(&ledinternal->netfilter_led_trigger);
	if (err) {
		pr_err("Trigger name is already in use.\n");
		goto exit_alloc;
	}

	/* Since the letinternal timer can be shared between multiple targets,
	 * always set it up, even if the current target does not need it
	 */
	setup_timer(&ledinternal->timer, led_timeout_callback,
		    (unsigned long)ledinternal);

	list_add_tail(&ledinternal->list, &xt_led_triggers);

out:
	mutex_unlock(&xt_led_mutex);

	ledinfo->internal_data = ledinternal;

	return 0;

exit_alloc:
	kfree(ledinternal->trigger_id);

exit_internal_alloc:
	kfree(ledinternal);

exit_mutex_only:
	mutex_unlock(&xt_led_mutex);

	return err;
}

static void led_tg_destroy(const struct xt_tgdtor_param *par)
{
	const struct xt_led_info *ledinfo = par->targinfo;
	struct xt_led_info_internal *ledinternal = ledinfo->internal_data;

	mutex_lock(&xt_led_mutex);

	if (--ledinternal->refcnt) {
		mutex_unlock(&xt_led_mutex);
		return;
	}

	list_del(&ledinternal->list);

	del_timer_sync(&ledinternal->timer);

	led_trigger_unregister(&ledinternal->netfilter_led_trigger);

	mutex_unlock(&xt_led_mutex);

	kfree(ledinternal->trigger_id);
	kfree(ledinternal);
}

static struct xt_target led_tg_reg __read_mostly = {
	.name		= "LED",
	.revision	= 0,
	.family		= NFPROTO_UNSPEC,
	.target		= led_tg,
	.targetsize	= sizeof(struct xt_led_info),
	.checkentry	= led_tg_check,
	.destroy	= led_tg_destroy,
	.me		= THIS_MODULE,
};

static int __init led_tg_init(void)
{
	return xt_register_target(&led_tg_reg);
}

static void __exit led_tg_exit(void)
{
	xt_unregister_target(&led_tg_reg);
}

module_init(led_tg_init);
module_exit(led_tg_exit);
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               /*
 *  Routines for control of the TEA6330T circuit via i2c bus
 *  Sound fader control circuit for car radios by Philips Semiconductors
 *  Copyright (c) by Jaroslav Kysela <perex@perex.cz>
 *
 *
 *   This program is free software; you can redistribute it and/or modify
 *   it under the terms of the GNU General Public License as published by
 *   the Free Software Foundation; either version 2 of the License, or
 *   (at your option) any later version.
 *
 *   This program is distributed in the hope that it will be useful,
 *   but WITHOUT ANY WARRANTY; without even the implied warranty of
 *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *   GNU General Public License for more details.
 *
 *   You should have received a copy of the GNU General Public License
 *   along with this program; if not, write to the Free Software
 *   Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
 *
 */

#include <linux/init.h>
#include <linux/slab.h>
#include <linux/module.h>
#include <sound/core.h>
#include <sound/control.h>
#include <sound/tea6330t.h>

MODULE_AUTHOR("Jaroslav Kysela <perex@perex.cz>");
MODULE_DESCRIPTION("Routines for control of the TEA6330T circuit via i2c bus");
MODULE_LICENSE("GPL");

#define TEA6330T_ADDR			(0x80>>1) /* fixed address */

#define TEA6330T_SADDR_VOLUME_LEFT	0x00	/* volume left */
#define TEA6330T_SADDR_VOLUME_RIGHT	0x01	/* volume right */
#define TEA6330T_SADDR_BASS		0x02	/* bass control */
#define TEA6330T_SADDR_TREBLE		0x03	/* treble control */
#define TEA6330T_SADDR_FADER		0x04	/* fader control */
#define   TEA6330T_MFN			0x20	/* mute control for selected channels */
#define   TEA6330T_FCH			0x10	/* select fader channels - front or rear */
#define TEA6330T_SADDR_AUDIO_SWITCH	0x05	/* audio switch */
#define   TEA6330T_GMU			0x80	/* mute control, general mute */
#define   TEA6330T_EQN			0x40	/* equalizer switchover (0=equalizer-on) */


struct tea6330t {
	struct snd_i2c_device *device;
	struct snd_i2c_bus *bus;
	int equalizer;
	int fader;
	unsigned char regs[8];
	unsigned char mleft, mright;
	unsigned char bass, treble;
	unsigned char max_bass, max_treble;
};


int snd_tea6330t_detect(struct snd_i2c_bus *bus, int equalizer)
{
	int res;

	snd_i2c_lock(bus);
	res = snd_i2c_probeaddr(bus, TEA6330T_ADDR);
	snd_i2c_unlock(bus);
	return res;
}

#if 0
static void snd_tea6330t_set(struct tea6330t *tea,
			     unsigned char addr, unsigned char value)
{
#if 0
	printk(KERN_DEBUG "set - 0x%x/0x%x\n", addr, value);
#endif
	snd_i2c_write(tea->bus, TEA6330T_ADDR, addr, value, 1);
}
#endif

#define TEA6330T_MASTER_VOLUME(xname, xindex) \
{ .iface = SNDRV_CTL_ELEM_IFACE_MIXER, .name = xname, .index = xindex, \
  .info = snd_tea6330t_info_master_volume, \
  .get = snd_tea6330t_get_master_volume, .put = snd_tea6330t_put_master_volume }

static int snd_tea6330t_info_master_volume(struct snd_kcontrol *kcontrol,
					   struct snd_ctl_elem_info *uinfo)
{
	uinfo->type = SNDRV_CTL_ELEM_TYPE_INTEGER;
	uinfo->count = 2;
	uinfo->value.integer.min = 0;
	uinfo->value.integer.max = 43;
	return 0;
}

static int snd_tea6330t_get_master_volume(struct snd_kcontrol *kcontrol,
					  struct snd_ctl_elem_value *ucontrol)
{
	struct tea6330t *tea = snd_kcontrol_chip(kcontrol);
	
	snd_i2c_lock(tea->bus);
	ucontrol->value.integer.value[0] = tea->mleft - 0x14;
	ucontrol->value.integer.value[1] = tea->mright - 0x14;
	snd_i2c_unlock(tea->bus);
	return 0;
}

static int snd_tea6330t_put_master_volume(struct snd_kcontrol *kcontrol,
					  struct snd_ctl_elem_value *ucontrol)
{
	struct tea6330t *tea = snd_kcontrol_chip(kcontrol);
	int change, count, err;
	unsigned char bytes[3];
	unsigned char val1, val2;
	
	val1 = (ucontrol->value.integer.value[0] % 44) + 0x14;
	val2 = (ucontrol->value.integer.value[1] % 44) + 0x14;
	snd_i2c_lock(tea->bus);
	change = val1 != tea->mleft || val2 != tea->mright;
	tea->mleft = val1;
	tea->mright = val2;
	count = 0;
	if (tea->regs[TEA6330T_SADDR_VOLUME_LEFT] != 0) {
		bytes[count++] = TEA6330T_SADDR_VOLUME_LEFT;
		bytes[count++] = tea->regs[TEA6330T_SADDR_VOLUME_LEFT] = tea->mleft;
	}
	if (tea->regs[TEA6330T_SADDR_VOLUME_RIGHT] != 0) {
		if (count == 0)
			bytes[count++] = TEA6330T_SADDR_VOLUME_RIGHT;
		bytes[count++] = tea->regs[TEA6330T_SADDR_VOLUME_RIGHT] = tea->mright;
	}
	if (count > 0) {
		if ((err = snd_i2c_sendbytes(tea->device, bytes, count)) < 0)
			change = err;
	}
	snd_i2c_unlock(tea->bus);
	return change;
}

#define TEA6330T_MASTER_SWITCH(xname, xindex) \
{ .iface = SNDRV_CTL_ELEM_IFACE_MIXER, .name = xname, .index = xindex, \
  .info = snd_tea6330t_info_master_switch, \
  .get = snd_tea6330t_get_master_switch, .put = snd_tea6330t_put_master_switch }

#define snd_tea6330t_info_master_switch		snd_ctl_boolean_stereo_info

static int snd_tea6330t_get_master_switch(struct snd_kcontrol *kcontrol,
					  struct snd_ctl_elem_value *ucontrol)
{
	struct tea6330t *tea = snd_kcontrol_chip(kcontrol);
	
	snd_i2c_lock(tea->bus);
	ucontrol->value.integer.value[0] = tea->regs[TEA6330T_SADDR_VOLUME_LEFT] == 0 ? 0 : 1;
	ucontrol->value.integer.value[1] = tea->regs[TEA6330T_SADDR_VOLUME_RIGHT] == 0 ? 0 : 1;
	snd_i2c_unlock(tea->bus);
	return 0;
}

static int snd_tea6330t_put_master_switch(struct snd_kcontrol *kcontrol,
					  struct snd_ctl_elem_value *ucontrol)
{
	struct tea6330t *tea = snd_kcontrol_chip(kcontrol);
	int change, err;
	unsigned char bytes[3];
	unsigned char oval1, oval2, val1, val2;
	
	val1 = ucontrol->value.integer.value[0] & 1;
	val2 = ucontrol->value.integer.value[1] & 1;
	snd_i2c_lock(tea->bus);
	oval1 = tea->regs[TEA6330T_SADDR_VOLUME_LEFT] == 0 ? 0 : 1;
	oval2 = tea->regs[TEA6330T_SADDR_VOLUME_RIGHT] == 0 ? 0 : 1;
	change = val1 != oval1 || val2 != oval2;
	tea->regs[TEA6330T_SADDR_VOLUME_LEFT] = val1 ? tea->mleft : 0;
	tea->regs[TEA6330T_SADDR_VOLUME_RIGHT] = val2 ? tea->mright : 0;
	bytes[0] = TEA6330T_SADDR_VOLUME_LEFT;
	bytes[1] = tea->regs[TEA6330T_SADDR_VOLUME_LEFT];
	bytes[2] = tea->regs[TEA6330T_SADDR_VOLUME_RIGHT];
	if ((err = snd_i2c_sendbytes(tea->device, bytes, 3)) < 0)
		change = err;
	snd_i2c_unlock(tea->bus);
	return change;
}

#define TEA6330T_BASS(xname, xindex) \
{ .iface = SNDRV_CTL_ELEM_IFACE_MIXER, .name = xname, .index = xindex, \
  .info = snd_tea6330t_info_bass, \
  .get = snd_tea6330t_get_bass, .put = snd_tea6330t_put_bass }

static int snd_tea6330t_info_bass(struct snd_kcontrol *kcontrol,
				  struct snd_ctl_elem_info *uinfo)
{
	struct tea6330t *tea = snd_kcontrol_chip(kcontrol);

	uinfo->type = SNDRV_CTL_ELEM_TYPE_INTEGER;
	uinfo->count = 1;
	uinfo->value.integer.min = 0;
	uinfo->value.integer.max = tea->max_bass;
	return 0;
}

static int snd_tea6330t_get_bass(struct snd_kcontrol *kcontrol,
				 struct snd_ctl_elem_value *ucontrol)
{
	struct tea6330t *tea = snd_kcontrol_chip(kcontrol);
	
	ucontrol->value.integer.value[0] = tea->bass;
	return 0;
}

static int snd_tea6330t_put_bass(struct snd_kcontrol *kcontrol,
				 struct snd_ctl_elem_value *ucontrol)
{
	struct tea6330t *tea = snd_kcontrol_chip(kcontrol);
	int change, err;
	unsigned char bytes[2];
	unsigned char val1;
	
	val1 = ucontrol->value.integer.value[0] % (tea->max_bass + 1);
	snd_i2c_lock(tea->bus);
	tea->bass = val1;
	val1 += tea->equalizer ? 7 : 3;
	change = tea->regs[TEA6330T_SADDR_BASS] != val1;
	bytes[0] = TEA6330T_SADDR_BASS;
	bytes[1] = tea->regs[TEA6330T_SADDR_BASS] = val1;
	if ((err = snd_i2c_sendbytes(tea->device, bytes, 2)) < 0)
		change = err;
	snd_i2c_unlock(tea->bus);
	return change;
}

#define TEA6330T_TREBLE(xname, xindex) \
{ .iface = SNDRV_CTL_ELEM_IFACE_MIXER, .name = xname, .index = xindex, \
  .info = snd_tea6330t_info_treble, \
  .get = snd_tea6330t_get_treble, .put = snd_tea6330t_put_treble }

static int snd_tea6330t_info_treble(struct snd_kcontrol *kcontrol,
				    struct snd_ctl_elem_info *uinfo)
{
	struct tea6330t *tea = snd_kcontrol_chip(kcontrol);

	uinfo->type = SNDRV_CTL_ELEM_TYPE_INTEGER;
	uinfo->count = 1;
	uinfo->value.integer.min = 0;
	uinfo->value.integer.max = tea->max_treble;
	return 0;
}

static int snd_tea6330t_get_treble(struct snd_kcontrol *kcontrol,
				   struct snd_ctl_elem_value *ucontrol)
{
	struct tea6330t *tea = snd_kcontrol_chip(kcontrol);
	
	ucontrol->value.integer.value[0] = tea->treble;
	return 0;
}

static int snd_tea6330t_put_treble(struct snd_kcontrol *kcontrol,
				   struct snd_ctl_elem_value *ucontrol)
{
	struct tea6330t *tea = snd_kcontrol_chip(kcontrol);
	int change, err;
	unsigned char bytes[2];
	unsigned char val1;
	
	val1 = ucontrol->value.integer.value[0] % (tea->max_treble + 1);
	snd_i2c_lock(tea->bus);
	tea->treble = val1;
	val1 += 3;
	change = tea->regs[TEA6330T_SADDR_TREBLE] != val1;
	bytes[0] = TEA6330T_SADDR_TREBLE;
	bytes[1] = tea->regs[TEA6330T_SADDR_TREBLE] = val1;
	if ((err = snd_i2c_sendbytes(tea->device, bytes, 2)) < 0)
		change = err;
	snd_i2c_unlock(tea->bus);
	return change;
}

static struct snd_kcontrol_new snd_tea6330t_controls[] = {
TEA6330T_MASTER_SWITCH("Master Playback Switch", 0),
TEA6330T_MASTER_VOLUME("Master Playback Volume", 0),
TEA6330T_BASS("Tone Control - Bass", 0),
TEA6330T_TREBLE("Tone Control - Treble", 0)
};

static void snd_tea6330_free(struct snd_i2c_device *device)
{
	kfree(device->private_data);
}
                                        
int snd_tea6330t_update_mixer(struct snd_card *card,
			      struct snd_i2c_bus *bus,
			      int equalizer, int fader)
{
	struct snd_i2c_device *device;
	struct tea6330t *tea;
	struct snd_kcontrol_new *knew;
	unsigned int idx;
	int err = -ENOMEM;
	u8 default_treble, default_bass;
	unsigned char bytes[7];

	tea = kzalloc(sizeof(*tea), GFP_KERNEL);
	if (tea == NULL)
		return -ENOMEM;
	if ((err = snd_i2c_device_create(bus, "TEA6330T", TEA6330T_ADDR, &device)) < 0) {
		kfree(tea);
		return err;
	}
	tea->device = device;
	tea->bus = bus;
	tea->equalizer = equalizer;
	tea->fader = fader;
	device->private_data = tea;
	device->private_free = snd_tea6330_free;

	snd_i2c_lock(bus);

	/* turn fader off and handle equalizer */
	tea->regs[TEA6330T_SADDR_FADER] = 0x3f;
	tea->regs[TEA6330T_SADDR_AUDIO_SWITCH] = equalizer ? 0 : TEA6330T_EQN;
	/* initialize mixer */
	if (!tea->equalizer) {
		tea->max_bass = 9;
		tea->max_treble = 8;
		default_bass = 3 + 4;
		tea->bass = 4;
		default_treble = 3 + 4;
		tea->treble = 4;
	} else {
		tea->max_bass = 5;
		tea->max_treble = 0;
		default_bass = 7 + 4;
		tea->bass = 4;
		default_treble = 3;
		tea->treble = 0;
	}
	tea->mleft = tea->mright = 0x14;
	tea->regs[TEA6330T_SADDR_BASS] = default_bass;
	tea->regs[TEA6330T_SADDR_TREBLE] = default_treble;

	/* compose I2C message and put the hardware to initial state */
	bytes[0] = TEA6330T_SADDR_VOLUME_LEFT;
	for (idx = 0; idx < 6; idx++)
		bytes[idx+1] = tea->regs[idx];
	if ((err = snd_i2c_sendbytes(device, bytes, 7)) < 0)
		goto __error;

	strcat(card->mixername, ",TEA6330T");
	if ((err = snd_component_add(card, "TEA6330T")) < 0)
		goto __error;

	for (idx = 0; idx < ARRAY_SIZE(snd_tea6330t_controls); idx++) {
		knew = &snd_tea6330t_controls[idx];
		if (tea->treble == 0 && !strcmp(knew->name, "Tone Control - Treble"))
			continue;
		if ((err = snd_ctl_add(card, snd_ctl_new1(knew, tea))) < 0)
			goto __error;
	}

	snd_i2c_unlock(bus);
	return 0;
	
      __error:
      	snd_i2c_unlock(bus);
      	snd_i2c_device_free(device);
      	return err;
}

EXPORT_SYMBOL(snd_tea6330t_detect);
EXPORT_SYMBOL(snd_tea6330t_update_mixer);

/*
 *  INIT part
 */

static int __init alsa_tea6330t_init(void)
{
	return 0;
}

static void __exit alsa_tea6330t_exit(void)
{
}

module_init(alsa_tea6330t_init)
module_exit(alsa_tea6330t_exit)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   /* Copyright (c) 2011-2013, The Linux Foundation. All rights reserved.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License version 2 and
 * only version 2 as published by the Free Software Foundation.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 */


#ifndef _AUDDRV_GPIO_H_
#define _AUDDRV_GPIO_H_

/*****************************************************************************
 *                     C O M P I L E R   F L A G S
 *****************************************************************************/


/*****************************************************************************
 *                E X T E R N A L   R E F E R E N C E S
 *****************************************************************************/

#include "mt_soc_afe_common.h"
#include "mt_soc_afe_def.h"

/*****************************************************************************
 *                         D A T A   T Y P E S
 *****************************************************************************/


/*****************************************************************************
 *                         M A C R O
 *****************************************************************************/


/*****************************************************************************
 *                 FUNCTION       D E F I N I T I O N
 *****************************************************************************/
#if !defined(CONFIG_MTK_LEGACY)
#include <linux/gpio.h>
#else
#include <mt-plat/mt_gpio.h>
#endif

#if !defined(CONFIG_MTK_LEGACY)
void AudDrv_GPIO_probe(void *dev);
int AudDrv_GPIO_PMIC_Select(int bEnable);
int AudDrv_GPIO_I2S_Select(int bEnable);
int AudDrv_GPIO_EXTAMP_Select(int bEnable);

#endif


#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               /* SPDX-License-Identifier: GPL-2.0 WITH Linux-syscall-note */
#ifndef _LINUX_PERSONALITY_H
#define _LINUX_PERSONALITY_H


/*
 * Flags for bug emulation.
 *
 * These occupy the top three bytes.
 */
enum {
	UNAME26	=               0x0020000,
	ADDR_NO_RANDOMIZE = 	0x0040000,	/* disable randomization of VA space */
	FDPIC_FUNCPTRS =	0x0080000,	/* userspace function ptrs point to descriptors
						 * (signal handling)
						 */
	MMAP_PAGE_ZERO =	0x0100000,
	ADDR_COMPAT_LAYOUT =	0x0200000,
	READ_IMPLIES_EXEC =	0x0400000,
	ADDR_LIMIT_32BIT =	0x0800000,
	SHORT_INODE =		0x1000000,
	WHOLE_SECONDS =		0x2000000,
	STICKY_TIMEOUTS	=	0x4000000,
	ADDR_LIMIT_3GB = 	0x8000000,
};

/*
 * Security-relevant compatibility flags that must be
 * cleared upon setuid or setgid exec:
 */
#define PER_CLEAR_ON_SETID (READ_IMPLIES_EXEC  | \
			    ADDR_NO_RANDOMIZE  | \
			    ADDR_COMPAT_LAYOUT | \
			    MMAP_PAGE_ZERO)

/*
 * Personality types.
 *
 * These go in the low byte.  Avoid using the top bit, it will
 * conflict with error returns.
 */
enum {
	PER_LINUX =		0x0000,
	PER_LINUX_32BIT =	0x0000 | ADDR_LIMIT_32BIT,
	PER_LINUX_FDPIC =	0x0000 | FDPIC_FUNCPTRS,
	PER_SVR4 =		0x0001 | STICKY_TIMEOUTS | MMAP_PAGE_ZERO,
	PER_SVR3 =		0x0002 | STICKY_TIMEOUTS | SHORT_INODE,
	PER_SCOSVR3 =		0x0003 | STICKY_TIMEOUTS |
					 WHOLE_SECONDS | SHORT_INODE,
	PER_OSR5 =		0x0003 | STICKY_TIMEOUTS | WHOLE_SECONDS,
	PER_WYSEV386 =		0x0004 | STICKY_TIMEOUTS | SHORT_INODE,
	PER_ISCR4 =		0x0005 | STICKY_TIMEOUTS,
	PER_BSD =		0x0006,
	PER_SUNOS =		0x0006 | STICKY_TIMEOUTS,
	PER_XENIX =		0x0007 | STICKY_TIMEOUTS | SHORT_INODE,
	PER_LINUX32 =		0x0008,
	PER_LINUX32_3GB =	0x0008 | ADDR_